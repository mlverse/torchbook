<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11 Generative adversarial networks | Applied deep learning with torch from R</title>
  <meta name="description" content="tbd" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="11 Generative adversarial networks | Applied deep learning with torch from R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="tbd" />
  <meta property="og:image" content="tbdcover.png" />
  <meta property="og:description" content="tbd" />
  <meta name="github-repo" content="tbd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11 Generative adversarial networks | Applied deep learning with torch from R" />
  
  <meta name="twitter:description" content="tbd" />
  <meta name="twitter:image" content="tbdcover.png" />

<meta name="author" content="tbd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="generative-intro.html"/>
<link rel="next" href="vaes.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>I Using Torch</b></span></li>
<li class="chapter" data-level="" data-path="using-torch-intro.html"><a href="using-torch-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="2" data-path="simple-net-R.html"><a href="simple-net-R.html"><i class="fa fa-check"></i><b>2</b> A simple neural network in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#whats-in-a-network"><i class="fa fa-check"></i><b>2.1</b> What’s in a network?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="simple-net-R.html"><a href="simple-net-R.html#gradient-descent"><i class="fa fa-check"></i><b>2.1.1</b> Gradient descent</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-net-R.html"><a href="simple-net-R.html#from-linear-regression-to-a-simple-network"><i class="fa fa-check"></i><b>2.1.2</b> From linear regression to a simple network</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#a-simple-network"><i class="fa fa-check"></i><b>2.2</b> A simple network</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#simulate-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulate data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#initialize-weights-and-biases"><i class="fa fa-check"></i><b>2.2.2</b> Initialize weights and biases</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>2.2.3</b> Training loop</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-net-R.html"><a href="simple-net-R.html#complete-code"><i class="fa fa-check"></i><b>2.2.4</b> Complete code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html"><i class="fa fa-check"></i><b>3</b> Modifying the simple network to use torch tensors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#tensors"><i class="fa fa-check"></i><b>3.1</b> Tensors</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#creation"><i class="fa fa-check"></i><b>3.1.1</b> Creation</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#conversion-to-built-in-r-data-types"><i class="fa fa-check"></i><b>3.1.2</b> Conversion to built-in R data types</a></li>
<li class="chapter" data-level="3.1.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#indexing-and-slicing-tensors"><i class="fa fa-check"></i><b>3.1.3</b> Indexing and slicing tensors</a></li>
<li class="chapter" data-level="3.1.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#reshaping-tensors"><i class="fa fa-check"></i><b>3.1.4</b> Reshaping tensors</a></li>
<li class="chapter" data-level="3.1.5" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#operations-on-tensors"><i class="fa fa-check"></i><b>3.1.5</b> Operations on tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#running-on-gpu"><i class="fa fa-check"></i><b>3.2</b> Running on GPU</a></li>
<li class="chapter" data-level="3.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#broadcasting"><i class="fa fa-check"></i><b>3.3</b> Broadcasting</a></li>
<li class="chapter" data-level="3.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#simple-neural-network-using-torch-tensors"><i class="fa fa-check"></i><b>3.4</b> Simple neural network using <code>torch</code> tensors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html"><i class="fa fa-check"></i><b>4</b> Using autograd</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#automatic-differentiation-with-autograd"><i class="fa fa-check"></i><b>4.1</b> Automatic differentiation with <em>autograd</em></a></li>
<li class="chapter" data-level="4.2" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#the-simple-network-now-using-autograd"><i class="fa fa-check"></i><b>4.2</b> The simple network, now using <em>autograd</em></a></li>
<li class="chapter" data-level="4.3" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#outlook"><i class="fa fa-check"></i><b>4.3</b> Outlook</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-net-modules.html"><a href="simple-net-modules.html"><i class="fa fa-check"></i><b>5</b> Using torch modules</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#modules"><i class="fa fa-check"></i><b>5.1</b> Modules</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#layers-as-modules"><i class="fa fa-check"></i><b>5.1.1</b> Layers as modules</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#models-as-modules"><i class="fa fa-check"></i><b>5.1.2</b> Models as modules</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#simple-network-using-modules"><i class="fa fa-check"></i><b>5.2</b> Simple network using modules</a></li>
<li class="chapter" data-level="5.3" data-path="simple-net-modules.html"><a href="simple-net-modules.html#appendix-python-code"><i class="fa fa-check"></i><b>5.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-net-optim.html"><a href="simple-net-optim.html"><i class="fa fa-check"></i><b>6</b> Using <code>torch</code> optimizers</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple-net-optim.html"><a href="simple-net-optim.html#torch-optimizers"><i class="fa fa-check"></i><b>6.1</b> Torch optimizers</a></li>
<li class="chapter" data-level="6.2" data-path="simple-net-optim.html"><a href="simple-net-optim.html#simple-net-with-optim"><i class="fa fa-check"></i><b>6.2</b> Simple net with <code>optim</code></a></li>
<li class="chapter" data-level="6.3" data-path="simple-net-modules.html"><a href="simple-net-modules.html#appendix-python-code"><i class="fa fa-check"></i><b>6.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="part"><span><b>II Image Recognition</b></span></li>
<li class="chapter" data-level="" data-path="image-recognition-intro.html"><a href="image-recognition-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="7" data-path="image-classification.html"><a href="image-classification.html"><i class="fa fa-check"></i><b>7</b> Classifying images</a>
<ul>
<li class="chapter" data-level="7.1" data-path="image-classification.html"><a href="image-classification.html#data-loading-and-transformation"><i class="fa fa-check"></i><b>7.1</b> Data loading and transformation</a></li>
<li class="chapter" data-level="7.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>7.2</b> Model</a></li>
<li class="chapter" data-level="7.3" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>7.3</b> Training</a></li>
<li class="chapter" data-level="7.4" data-path="image-classification.html"><a href="image-classification.html#performance-on-the-test-set"><i class="fa fa-check"></i><b>7.4</b> Performance on the test set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unet.html"><a href="unet.html"><i class="fa fa-check"></i><b>8</b> Brain Image Segmentation with U-Net</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unet.html"><a href="unet.html#image-segmentation-in-a-nutshell"><i class="fa fa-check"></i><b>8.1</b> Image segmentation in a nutshell</a></li>
<li class="chapter" data-level="8.2" data-path="unet.html"><a href="unet.html#u-net"><i class="fa fa-check"></i><b>8.2</b> U-Net</a></li>
<li class="chapter" data-level="8.3" data-path="unet.html"><a href="unet.html#example-application-mri-images"><i class="fa fa-check"></i><b>8.3</b> Example application: MRI images</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="unet.html"><a href="unet.html#preprocessing"><i class="fa fa-check"></i><b>8.3.1</b> Preprocessing</a></li>
<li class="chapter" data-level="8.3.2" data-path="unet.html"><a href="unet.html#u-net-model"><i class="fa fa-check"></i><b>8.3.2</b> U-Net model</a></li>
<li class="chapter" data-level="8.3.3" data-path="unet.html"><a href="unet.html#loss"><i class="fa fa-check"></i><b>8.3.3</b> Loss</a></li>
<li class="chapter" data-level="8.3.4" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>8.3.4</b> Training</a></li>
<li class="chapter" data-level="8.3.5" data-path="unet.html"><a href="unet.html#predictions"><i class="fa fa-check"></i><b>8.3.5</b> Predictions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Natural language processing</b></span></li>
<li class="chapter" data-level="" data-path="NLP-intro.html"><a href="NLP-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="9" data-path="seq2seq-att.html"><a href="seq2seq-att.html"><i class="fa fa-check"></i><b>9</b> Sequence-to-sequence models with attention</a>
<ul>
<li class="chapter" data-level="9.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#why-attention"><i class="fa fa-check"></i><b>9.1</b> Why attention?</a></li>
<li class="chapter" data-level="9.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#preprocessing-with-torchtext"><i class="fa fa-check"></i><b>9.2</b> Preprocessing with <code>torchtext</code></a></li>
<li class="chapter" data-level="9.3" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>9.3</b> Model</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>9.3.1</b> Encoder</a></li>
<li class="chapter" data-level="9.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#attention-module"><i class="fa fa-check"></i><b>9.3.2</b> Attention module</a></li>
<li class="chapter" data-level="9.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>9.3.3</b> Decoder</a></li>
<li class="chapter" data-level="9.3.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#seq2seq-module"><i class="fa fa-check"></i><b>9.3.4</b> Seq2seq module</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#training-and-evaluation"><i class="fa fa-check"></i><b>9.4</b> Training and evaluation</a></li>
<li class="chapter" data-level="9.5" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>9.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="transformer.html"><a href="transformer.html"><i class="fa fa-check"></i><b>10</b> Torch transformer modules</a>
<ul>
<li class="chapter" data-level="10.1" data-path="transformer.html"><a href="transformer.html#attention-is-all-you-need"><i class="fa fa-check"></i><b>10.1</b> “Attention is all you need”</a></li>
<li class="chapter" data-level="10.2" data-path="transformer.html"><a href="transformer.html#implementation-building-blocks"><i class="fa fa-check"></i><b>10.2</b> Implementation: building blocks</a></li>
<li class="chapter" data-level="10.3" data-path="transformer.html"><a href="transformer.html#a-transformer-for-natural-language-translation"><i class="fa fa-check"></i><b>10.3</b> A Transformer for natural language translation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="transformer.html"><a href="transformer.html#load-data"><i class="fa fa-check"></i><b>10.3.1</b> Load data</a></li>
<li class="chapter" data-level="10.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>10.3.2</b> Encoder</a></li>
<li class="chapter" data-level="10.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>10.3.3</b> Decoder</a></li>
<li class="chapter" data-level="10.3.4" data-path="transformer.html"><a href="transformer.html#overall-model"><i class="fa fa-check"></i><b>10.3.4</b> Overall model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
</ul></li>
<li class="part"><span><b>IV Deep learning for tabular data</b></span></li>
<li class="chapter" data-level="" data-path="tabular-intro.html"><a href="tabular-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V Time series</b></span></li>
<li class="chapter" data-level="" data-path="timeseries-intro.html"><a href="timeseries-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VI Generative deep learning</b></span></li>
<li class="chapter" data-level="" data-path="generative-intro.html"><a href="generative-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="11" data-path="gans.html"><a href="gans.html"><i class="fa fa-check"></i><b>11</b> Generative adversarial networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>11.1</b> Dataset</a></li>
<li class="chapter" data-level="11.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>11.2</b> Model</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="gans.html"><a href="gans.html#generator"><i class="fa fa-check"></i><b>11.2.1</b> Generator</a></li>
<li class="chapter" data-level="11.2.2" data-path="gans.html"><a href="gans.html#discriminator"><i class="fa fa-check"></i><b>11.2.2</b> Discriminator</a></li>
<li class="chapter" data-level="11.2.3" data-path="gans.html"><a href="gans.html#optimizers-and-loss-function"><i class="fa fa-check"></i><b>11.2.3</b> Optimizers and loss function</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>11.3</b> Training loop</a></li>
<li class="chapter" data-level="11.4" data-path="gans.html"><a href="gans.html#artifacts"><i class="fa fa-check"></i><b>11.4</b> Artifacts</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="vaes.html"><a href="vaes.html"><i class="fa fa-check"></i><b>12</b> Variational autoencoders</a>
<ul>
<li class="chapter" data-level="12.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>12.1</b> Dataset</a></li>
<li class="chapter" data-level="12.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>12.2</b> Model</a></li>
<li class="chapter" data-level="12.3" data-path="vaes.html"><a href="vaes.html#training-the-vae"><i class="fa fa-check"></i><b>12.3</b> Training the VAE</a></li>
<li class="chapter" data-level="12.4" data-path="vaes.html"><a href="vaes.html#latent-space"><i class="fa fa-check"></i><b>12.4</b> Latent space</a></li>
</ul></li>
<li class="part"><span><b>VII Deep learning on graphs</b></span></li>
<li class="chapter" data-level="" data-path="graph-intro.html"><a href="graph-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VIII Probabilistic deep learning</b></span></li>
<li class="chapter" data-level="" data-path="probabilistic-intro.html"><a href="probabilistic-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>IX Private and secure deep learning</b></span></li>
<li class="chapter" data-level="" data-path="private-secure-intro.html"><a href="private-secure-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>X Research topics</b></span></li>
<li class="chapter" data-level="" data-path="research-intro.html"><a href="research-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied deep learning with torch from R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gans" class="section level1" number="11">
<h1><span class="header-section-number">11</span> Generative adversarial networks</h1>
<p><em>Generative Adversarial Networks</em> (GANs) are one of the most successful, as of this writing, unsupervised (or self-supervised,
rather) deep learning architectures . In GANs, there is no well-defined loss function; instead, the setup is fundamentally
game-theoretic: Two actors, the <em>generator</em> and the <em>discriminator</em>, each try to minimize their loss; the outcome should be
some artifact – image, text, what have you – that resembles the training data but does not copy them.</p>
<p>In theory, this is a highly fascinating approach; in practice, it can be a challenge to set parameters in a way that good
results are achieved. The architecture and settings presented here follow those reported in the original DCGAN article
<span class="citation">(Goodfellow et al. <a href="#ref-goodfellow2014generative" role="doc-biblioref">2014</a>)</span>. In the meantime, a lot of research has been done; minor changes to loss functions, optimizers
and/or parameters may make an important difference.</p>
<div id="dataset" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Dataset</h2>
<p>For this task, we use <a href="https://github.com/rois-codh/kmnist">Kuzushiji-MNIST</a> <span class="citation">(Clanuwat et al. <a href="#ref-clanuwat2018deep" role="doc-biblioref">2018</a>)</span>, one of the more recent MNIST
drop-ins. Kuzushiji-MNIST contains 70,000 grayscale images, of size 28x28 px just like MNIST, and also like MNIST, divided
into 10 classes.</p>
<p>We can use <code>torch</code> for loading it. With an unsupervised learning task such as this one, we only need the training set:</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="gans.html#cb251-1"></a><span class="kw">library</span>(torch)</span>
<span id="cb251-2"><a href="gans.html#cb251-2"></a></span>
<span id="cb251-3"><a href="gans.html#cb251-3"></a>batch_size &lt;-<span class="st"> </span><span class="dv">128</span></span>
<span id="cb251-4"><a href="gans.html#cb251-4"></a></span>
<span id="cb251-5"><a href="gans.html#cb251-5"></a>kmnist &lt;-<span class="st"> </span><span class="kw">kmnist_dataset</span>(</span>
<span id="cb251-6"><a href="gans.html#cb251-6"></a>    dir,</span>
<span id="cb251-7"><a href="gans.html#cb251-7"></a>    <span class="dt">download =</span> <span class="ot">TRUE</span>,</span>
<span id="cb251-8"><a href="gans.html#cb251-8"></a>    <span class="dt">transform =</span> <span class="cf">function</span>(x) {</span>
<span id="cb251-9"><a href="gans.html#cb251-9"></a>        x &lt;-<span class="st"> </span>x<span class="op">$</span><span class="kw">to</span>(<span class="dt">dtype =</span> <span class="kw">torch_float</span>())<span class="op">/</span><span class="dv">256</span></span>
<span id="cb251-10"><a href="gans.html#cb251-10"></a>        x[newaxis,..]</span>
<span id="cb251-11"><a href="gans.html#cb251-11"></a>    }</span>
<span id="cb251-12"><a href="gans.html#cb251-12"></a>)</span>
<span id="cb251-13"><a href="gans.html#cb251-13"></a>dl &lt;-<span class="st"> </span><span class="kw">dataloader</span>(kmnist, <span class="dt">batch_size =</span> batch_size, <span class="dt">shuffle =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p>Let’s view a few of those. Here are the initial 16 images, taken from the very first batch:</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="gans.html#cb252-1"></a>images &lt;-<span class="st"> </span>dl<span class="op">$</span><span class="kw">.iter</span>()<span class="op">$</span><span class="kw">.next</span>()[[<span class="dv">1</span>]][<span class="dv">1</span><span class="op">:</span><span class="dv">16</span>, <span class="dv">1</span>, , ] </span>
<span id="cb252-2"><a href="gans.html#cb252-2"></a>images &lt;-<span class="st"> </span><span class="kw">normalize</span>(images) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_array</span>()</span>
<span id="cb252-3"><a href="gans.html#cb252-3"></a>images <span class="op">%&gt;%</span></span>
<span id="cb252-4"><a href="gans.html#cb252-4"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">array_tree</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb252-5"><a href="gans.html#cb252-5"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">map</span>(as.raster) <span class="op">%&gt;%</span></span>
<span id="cb252-6"><a href="gans.html#cb252-6"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">iwalk</span>(<span class="op">~</span>{<span class="kw">plot</span>(.x)})</span></code></pre></div>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="gans.html#cb253-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/gan_real.png&quot;</span>)</span></code></pre></div>
</div>
<div id="model" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Model</h2>
<p>The model, in the abstract sense, consists of the interplay of two models, in the concrete sense – two <code>torch</code> <em>modules</em>. The
<em>generator</em> produces fake artifacts – fake Kuzushiji digits, in our case – in the hope of getting better and better at it;
the <em>discriminator</em> is tasked with telling actual from fake images. (Its task should, if all goes well, get more difficult
over time.)</p>
<p>Let’s start with the generator.</p>
<div id="generator" class="section level3" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Generator</h3>
<p>The generator is given a random noise vector (1d), and has to produce images (2d, of a given resolution). Its main mode of
action is repeated application of <em>transposed convolutions</em> that upsample from a resolution of <code>1x1</code> to the required
resolution of <code>28x28</code>.</p>
<p>Following the DCGAN paper, the generator’s <code>nn_conv_transpose2d</code> and <code>nn_batch_norm2d</code> layers are initialized according to a
normal distribution with mean 0 and standard deviation 0.02.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="gans.html#cb254-1"></a>device &lt;-<span class="st"> </span><span class="cf">if</span> (<span class="kw">cuda_is_available</span>()) <span class="kw">torch_device</span>(<span class="st">&quot;cuda:0&quot;</span>) <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb254-2"><a href="gans.html#cb254-2"></a></span>
<span id="cb254-3"><a href="gans.html#cb254-3"></a>latent_input_size &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb254-4"><a href="gans.html#cb254-4"></a>image_size &lt;-<span class="st"> </span><span class="dv">28</span></span>
<span id="cb254-5"><a href="gans.html#cb254-5"></a></span>
<span id="cb254-6"><a href="gans.html#cb254-6"></a>generator &lt;-<span class="st"> </span><span class="kw">nn_module</span>(</span>
<span id="cb254-7"><a href="gans.html#cb254-7"></a>    <span class="st">&quot;generator&quot;</span>,</span>
<span id="cb254-8"><a href="gans.html#cb254-8"></a>    <span class="dt">initialize =</span> <span class="cf">function</span>() {</span>
<span id="cb254-9"><a href="gans.html#cb254-9"></a>        self<span class="op">$</span>main =<span class="st"> </span><span class="kw">nn_sequential</span>(</span>
<span id="cb254-10"><a href="gans.html#cb254-10"></a>            <span class="co"># nn_conv_transpose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=TRUE, dilation=1, padding_mode=&#39;zeros&#39;)</span></span>
<span id="cb254-11"><a href="gans.html#cb254-11"></a>            <span class="co"># h_out = (h_in - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1</span></span>
<span id="cb254-12"><a href="gans.html#cb254-12"></a>            <span class="co"># (1 - 1) * 1 - 2 * 0 + 1 * (4 -1 ) + 0 + 1</span></span>
<span id="cb254-13"><a href="gans.html#cb254-13"></a>            <span class="co"># 4 x 4</span></span>
<span id="cb254-14"><a href="gans.html#cb254-14"></a>            <span class="kw">nn_conv_transpose2d</span>(latent_input_size, image_size <span class="op">*</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb254-15"><a href="gans.html#cb254-15"></a>            <span class="kw">nn_batch_norm2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">4</span>),</span>
<span id="cb254-16"><a href="gans.html#cb254-16"></a>            <span class="kw">nn_relu</span>(),</span>
<span id="cb254-17"><a href="gans.html#cb254-17"></a>            <span class="co"># 8 * 8</span></span>
<span id="cb254-18"><a href="gans.html#cb254-18"></a>            <span class="kw">nn_conv_transpose2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">4</span>, image_size <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb254-19"><a href="gans.html#cb254-19"></a>            <span class="kw">nn_batch_norm2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">2</span>),</span>
<span id="cb254-20"><a href="gans.html#cb254-20"></a>            <span class="kw">nn_relu</span>(),</span>
<span id="cb254-21"><a href="gans.html#cb254-21"></a>            <span class="co"># 16 x 16</span></span>
<span id="cb254-22"><a href="gans.html#cb254-22"></a>            <span class="kw">nn_conv_transpose2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, image_size, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb254-23"><a href="gans.html#cb254-23"></a>            <span class="kw">nn_batch_norm2d</span>(image_size),</span>
<span id="cb254-24"><a href="gans.html#cb254-24"></a>            <span class="kw">nn_relu</span>(),</span>
<span id="cb254-25"><a href="gans.html#cb254-25"></a>            <span class="co"># 28 x 28</span></span>
<span id="cb254-26"><a href="gans.html#cb254-26"></a>            <span class="kw">nn_conv_transpose2d</span>(image_size, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb254-27"><a href="gans.html#cb254-27"></a>            <span class="kw">nn_tanh</span>()</span>
<span id="cb254-28"><a href="gans.html#cb254-28"></a>        )</span>
<span id="cb254-29"><a href="gans.html#cb254-29"></a>    },</span>
<span id="cb254-30"><a href="gans.html#cb254-30"></a>    <span class="dt">forward =</span> <span class="cf">function</span>(x) {</span>
<span id="cb254-31"><a href="gans.html#cb254-31"></a>        self<span class="op">$</span><span class="kw">main</span>(x)</span>
<span id="cb254-32"><a href="gans.html#cb254-32"></a>    }</span>
<span id="cb254-33"><a href="gans.html#cb254-33"></a>)</span>
<span id="cb254-34"><a href="gans.html#cb254-34"></a></span>
<span id="cb254-35"><a href="gans.html#cb254-35"></a>gen &lt;-<span class="st"> </span><span class="kw">generator</span>()</span>
<span id="cb254-36"><a href="gans.html#cb254-36"></a></span>
<span id="cb254-37"><a href="gans.html#cb254-37"></a>init_weights &lt;-<span class="st"> </span><span class="cf">function</span>(m) {</span>
<span id="cb254-38"><a href="gans.html#cb254-38"></a>    <span class="cf">if</span> (<span class="kw">grepl</span>(<span class="st">&quot;conv&quot;</span>, m<span class="op">$</span>.classes[[<span class="dv">1</span>]])) {</span>
<span id="cb254-39"><a href="gans.html#cb254-39"></a>        <span class="kw">nn_init_normal_</span>(m<span class="op">$</span>weight<span class="op">$</span><span class="kw">data</span>(), <span class="fl">0.0</span>, <span class="fl">0.02</span>)</span>
<span id="cb254-40"><a href="gans.html#cb254-40"></a>    } <span class="cf">else</span> <span class="cf">if</span> (<span class="kw">grepl</span>(<span class="st">&quot;batch_norm&quot;</span>, m<span class="op">$</span>.classes[[<span class="dv">1</span>]])) {</span>
<span id="cb254-41"><a href="gans.html#cb254-41"></a>        <span class="kw">nn_init_normal_</span>(m<span class="op">$</span>weight<span class="op">$</span><span class="kw">data</span>(), <span class="fl">1.0</span>, <span class="fl">0.02</span>)</span>
<span id="cb254-42"><a href="gans.html#cb254-42"></a>        <span class="kw">nn_init_constant_</span>(m<span class="op">$</span>bias<span class="op">$</span><span class="kw">data</span>(), <span class="dv">0</span>)</span>
<span id="cb254-43"><a href="gans.html#cb254-43"></a>    }</span>
<span id="cb254-44"><a href="gans.html#cb254-44"></a>}</span>
<span id="cb254-45"><a href="gans.html#cb254-45"></a></span>
<span id="cb254-46"><a href="gans.html#cb254-46"></a>gen[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">apply</span>(init_weights)</span>
<span id="cb254-47"><a href="gans.html#cb254-47"></a></span>
<span id="cb254-48"><a href="gans.html#cb254-48"></a>disc<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> device)</span></code></pre></div>
</div>
<div id="discriminator" class="section level3" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Discriminator</h3>
<p>The discriminator is a pretty conventional convnet. Its layers’ weights are initialized in the same way as the generator’s.</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="gans.html#cb255-1"></a>discriminator &lt;-<span class="st"> </span><span class="kw">nn_module</span>(</span>
<span id="cb255-2"><a href="gans.html#cb255-2"></a>    <span class="st">&quot;discriminator&quot;</span>,</span>
<span id="cb255-3"><a href="gans.html#cb255-3"></a>    <span class="dt">initialize =</span> <span class="cf">function</span>() {</span>
<span id="cb255-4"><a href="gans.html#cb255-4"></a>        self<span class="op">$</span>main =<span class="st"> </span><span class="kw">nn_sequential</span>(</span>
<span id="cb255-5"><a href="gans.html#cb255-5"></a>            <span class="co"># 14 x 14</span></span>
<span id="cb255-6"><a href="gans.html#cb255-6"></a>            <span class="kw">nn_conv2d</span>(<span class="dv">1</span>, image_size, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb255-7"><a href="gans.html#cb255-7"></a>            <span class="kw">nn_leaky_relu</span>(<span class="fl">0.2</span>, <span class="dt">inplace =</span> <span class="ot">TRUE</span>),</span>
<span id="cb255-8"><a href="gans.html#cb255-8"></a>            <span class="co"># 7 x 7</span></span>
<span id="cb255-9"><a href="gans.html#cb255-9"></a>            <span class="kw">nn_conv2d</span>(image_size, image_size <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>,  <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb255-10"><a href="gans.html#cb255-10"></a>            <span class="kw">nn_batch_norm2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">2</span>),</span>
<span id="cb255-11"><a href="gans.html#cb255-11"></a>            <span class="kw">nn_leaky_relu</span>(<span class="fl">0.2</span>, <span class="dt">inplace =</span> <span class="ot">TRUE</span>),</span>
<span id="cb255-12"><a href="gans.html#cb255-12"></a>            <span class="co"># 3 x 3</span></span>
<span id="cb255-13"><a href="gans.html#cb255-13"></a>            <span class="kw">nn_conv2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, image_size <span class="op">*</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>,  <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb255-14"><a href="gans.html#cb255-14"></a>            <span class="kw">nn_batch_norm2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">4</span>),</span>
<span id="cb255-15"><a href="gans.html#cb255-15"></a>            <span class="kw">nn_leaky_relu</span>(<span class="fl">0.2</span>, <span class="dt">inplace =</span> <span class="ot">TRUE</span>),</span>
<span id="cb255-16"><a href="gans.html#cb255-16"></a>            <span class="co"># 1 x 1</span></span>
<span id="cb255-17"><a href="gans.html#cb255-17"></a>            <span class="kw">nn_conv2d</span>(image_size <span class="op">*</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>,  <span class="dt">bias =</span> <span class="ot">FALSE</span>),</span>
<span id="cb255-18"><a href="gans.html#cb255-18"></a>            <span class="kw">nn_sigmoid</span>()</span>
<span id="cb255-19"><a href="gans.html#cb255-19"></a>        )</span>
<span id="cb255-20"><a href="gans.html#cb255-20"></a>    },</span>
<span id="cb255-21"><a href="gans.html#cb255-21"></a>    <span class="dt">forward =</span> <span class="cf">function</span>(x) {</span>
<span id="cb255-22"><a href="gans.html#cb255-22"></a>        self<span class="op">$</span><span class="kw">main</span>(x)</span>
<span id="cb255-23"><a href="gans.html#cb255-23"></a>    }</span>
<span id="cb255-24"><a href="gans.html#cb255-24"></a>)</span>
<span id="cb255-25"><a href="gans.html#cb255-25"></a></span>
<span id="cb255-26"><a href="gans.html#cb255-26"></a>disc &lt;-<span class="st"> </span><span class="kw">discriminator</span>()</span>
<span id="cb255-27"><a href="gans.html#cb255-27"></a></span>
<span id="cb255-28"><a href="gans.html#cb255-28"></a>disc[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">apply</span>(init_weights)</span>
<span id="cb255-29"><a href="gans.html#cb255-29"></a></span>
<span id="cb255-30"><a href="gans.html#cb255-30"></a>disc<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> device)</span></code></pre></div>
</div>
<div id="optimizers-and-loss-function" class="section level3" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Optimizers and loss function</h3>
<p>While generator and discriminator each need to account for their own losses, mathematically both use the same calculation,
namely, binary crossentropy:</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="gans.html#cb256-1"></a>criterion &lt;-<span class="st"> </span><span class="kw">nn_bce_loss</span>()</span></code></pre></div>
<p>They each have their own optimizer:</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="gans.html#cb257-1"></a>learning_rate &lt;-<span class="st"> </span><span class="fl">0.0002</span></span>
<span id="cb257-2"><a href="gans.html#cb257-2"></a></span>
<span id="cb257-3"><a href="gans.html#cb257-3"></a>disc_optimizer &lt;-<span class="st"> </span><span class="kw">optim_adam</span>(disc<span class="op">$</span>parameters, <span class="dt">lr =</span> learning_rate, <span class="dt">betas =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.999</span>))</span>
<span id="cb257-4"><a href="gans.html#cb257-4"></a>gen_optimizer &lt;-<span class="st"> </span><span class="kw">optim_adam</span>(gen<span class="op">$</span>parameters, <span class="dt">lr =</span> learning_rate, <span class="dt">betas =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.999</span>))</span></code></pre></div>
</div>
</div>
<div id="training-loop" class="section level2" number="11.3">
<h2><span class="header-section-number">11.3</span> Training loop</h2>
<p>Each epoch, the training loop consists of three parts.</p>
<p>First, the discriminator is trained. This, logically, is a two-step procedure (with no time dependencies between steps). In
step 1, it is given the real images, together with labels (fabricated on the fly) that say “these are real images”. Binary
cross entropy will be minimized when all those images are, in fact, classified as real by the discriminator. In stage 2, first
the generator is asked to generate some images, and then the discriminator is asked to rate them. Again, binary cross entropy
is calculated, but this time, it will be minimal if all images are characterized as fake. Once gradients have been obtained
for both computations, the discriminator’s weights are updated.</p>
<p>Then it’s the generator’s turn – although in an indirect way. We pass the newly generated fakes to the <em>discriminator</em> again;
only this time, the desired verdict is “no fake”, so the labels are set to “real”. The binary cross entropy loss then reflects
the <em>generator’s</em> performance, not that of the discriminator.</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="gans.html#cb258-1"></a>fixed_noise &lt;-<span class="st"> </span><span class="kw">torch_randn</span>(<span class="kw">c</span>(<span class="dv">64</span>, latent_input_size, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">device =</span> device)</span>
<span id="cb258-2"><a href="gans.html#cb258-2"></a>num_epochs &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb258-3"><a href="gans.html#cb258-3"></a></span>
<span id="cb258-4"><a href="gans.html#cb258-4"></a>img_list &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">mode =</span> <span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> num_epochs <span class="op">*</span><span class="st"> </span><span class="kw">trunc</span>(dl<span class="op">$</span><span class="kw">.iter</span>()<span class="op">$</span><span class="kw">.length</span>()<span class="op">/</span><span class="dv">50</span>))</span>
<span id="cb258-5"><a href="gans.html#cb258-5"></a>gen_losses &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb258-6"><a href="gans.html#cb258-6"></a>disc_losses &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb258-7"><a href="gans.html#cb258-7"></a></span>
<span id="cb258-8"><a href="gans.html#cb258-8"></a>img_num &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb258-9"><a href="gans.html#cb258-9"></a><span class="cf">for</span> (epoch <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>num_epochs) {</span>
<span id="cb258-10"><a href="gans.html#cb258-10"></a></span>
<span id="cb258-11"><a href="gans.html#cb258-11"></a>    batchnum &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb258-12"><a href="gans.html#cb258-12"></a>    <span class="cf">for</span> (b <span class="cf">in</span> <span class="kw">enumerate</span>(dl)) {</span>
<span id="cb258-13"><a href="gans.html#cb258-13"></a></span>
<span id="cb258-14"><a href="gans.html#cb258-14"></a>        batchnum &lt;-<span class="st"> </span>batchnum <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb258-15"><a href="gans.html#cb258-15"></a></span>
<span id="cb258-16"><a href="gans.html#cb258-16"></a>        y_real &lt;-<span class="st"> </span><span class="kw">torch_ones</span>(b[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">size</span>()[<span class="dv">1</span>], <span class="dt">device =</span> device)</span>
<span id="cb258-17"><a href="gans.html#cb258-17"></a>        y_fake &lt;-<span class="st"> </span><span class="kw">torch_zeros</span>(b[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">size</span>()[<span class="dv">1</span>], <span class="dt">device =</span> device)</span>
<span id="cb258-18"><a href="gans.html#cb258-18"></a></span>
<span id="cb258-19"><a href="gans.html#cb258-19"></a>        noise &lt;-<span class="st"> </span><span class="kw">torch_randn</span>(b[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">size</span>()[<span class="dv">1</span>], latent_input_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">device =</span> device)</span>
<span id="cb258-20"><a href="gans.html#cb258-20"></a>        fake &lt;-<span class="st"> </span><span class="kw">gen</span>(noise)</span>
<span id="cb258-21"><a href="gans.html#cb258-21"></a>        img &lt;-<span class="st"> </span>b[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> device)</span>
<span id="cb258-22"><a href="gans.html#cb258-22"></a></span>
<span id="cb258-23"><a href="gans.html#cb258-23"></a>        <span class="co"># update discriminator</span></span>
<span id="cb258-24"><a href="gans.html#cb258-24"></a>        disc_loss &lt;-<span class="st"> </span><span class="kw">criterion</span>(<span class="kw">disc</span>(img), y_real) <span class="op">+</span><span class="st"> </span><span class="kw">criterion</span>(<span class="kw">disc</span>(fake<span class="op">$</span><span class="kw">detach</span>()), y_fake)</span>
<span id="cb258-25"><a href="gans.html#cb258-25"></a></span>
<span id="cb258-26"><a href="gans.html#cb258-26"></a>        disc_optimizer<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb258-27"><a href="gans.html#cb258-27"></a>        disc_loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb258-28"><a href="gans.html#cb258-28"></a>        disc_optimizer<span class="op">$</span><span class="kw">step</span>()</span>
<span id="cb258-29"><a href="gans.html#cb258-29"></a></span>
<span id="cb258-30"><a href="gans.html#cb258-30"></a>        <span class="co"># update generator</span></span>
<span id="cb258-31"><a href="gans.html#cb258-31"></a>        gen_loss &lt;-<span class="st"> </span><span class="kw">criterion</span>(<span class="kw">disc</span>(fake), y_real)</span>
<span id="cb258-32"><a href="gans.html#cb258-32"></a></span>
<span id="cb258-33"><a href="gans.html#cb258-33"></a>        gen_optimizer<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb258-34"><a href="gans.html#cb258-34"></a>        gen_loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb258-35"><a href="gans.html#cb258-35"></a>        gen_optimizer<span class="op">$</span><span class="kw">step</span>()</span>
<span id="cb258-36"><a href="gans.html#cb258-36"></a></span>
<span id="cb258-37"><a href="gans.html#cb258-37"></a>        disc_losses &lt;-<span class="st"> </span><span class="kw">c</span>(disc_losses, disc_loss<span class="op">$</span><span class="kw">cpu</span>()<span class="op">$</span><span class="kw">item</span>())</span>
<span id="cb258-38"><a href="gans.html#cb258-38"></a>        gen_losses &lt;-<span class="st"> </span><span class="kw">c</span>(gen_losses, gen_loss<span class="op">$</span><span class="kw">cpu</span>()<span class="op">$</span><span class="kw">item</span>())</span>
<span id="cb258-39"><a href="gans.html#cb258-39"></a></span>
<span id="cb258-40"><a href="gans.html#cb258-40"></a>        <span class="cf">if</span> (batchnum <span class="op">%%</span><span class="st"> </span><span class="dv">50</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb258-41"><a href="gans.html#cb258-41"></a>            img_num &lt;-<span class="st"> </span>img_num <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb258-42"><a href="gans.html#cb258-42"></a>            <span class="kw">cat</span>(<span class="st">&quot;Epoch: &quot;</span>, epoch,</span>
<span id="cb258-43"><a href="gans.html#cb258-43"></a>                <span class="st">&quot;    batch: &quot;</span>, batchnum,</span>
<span id="cb258-44"><a href="gans.html#cb258-44"></a>                <span class="st">&quot;    disc loss: &quot;</span>, <span class="kw">as.numeric</span>(disc_loss<span class="op">$</span><span class="kw">cpu</span>()),</span>
<span id="cb258-45"><a href="gans.html#cb258-45"></a>                <span class="st">&quot;    gen loss: &quot;</span>, <span class="kw">as.numeric</span>(gen_loss<span class="op">$</span><span class="kw">cpu</span>()),</span>
<span id="cb258-46"><a href="gans.html#cb258-46"></a>                <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb258-47"><a href="gans.html#cb258-47"></a>            <span class="kw">with_no_grad</span>({</span>
<span id="cb258-48"><a href="gans.html#cb258-48"></a>                generated &lt;-<span class="st"> </span><span class="kw">gen</span>(fixed_noise)</span>
<span id="cb258-49"><a href="gans.html#cb258-49"></a>                grid &lt;-<span class="st"> </span><span class="kw">vision_make_grid</span>(generated)</span>
<span id="cb258-50"><a href="gans.html#cb258-50"></a>                img_list[[img_num]] &lt;-<span class="st"> </span><span class="kw">as_array</span>(grid<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cpu&quot;</span>))</span>
<span id="cb258-51"><a href="gans.html#cb258-51"></a>            })</span>
<span id="cb258-52"><a href="gans.html#cb258-52"></a>        }</span>
<span id="cb258-53"><a href="gans.html#cb258-53"></a></span>
<span id="cb258-54"><a href="gans.html#cb258-54"></a>    }</span>
<span id="cb258-55"><a href="gans.html#cb258-55"></a>}</span></code></pre></div>
</div>
<div id="artifacts" class="section level2" number="11.4">
<h2><span class="header-section-number">11.4</span> Artifacts</h2>
<p>Now let’s see a few samples of generated images, spread out over training time:</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="gans.html#cb259-1"></a>index &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(img_list), <span class="dt">length.out =</span> <span class="dv">16</span>)</span>
<span id="cb259-2"><a href="gans.html#cb259-2"></a>images &lt;-<span class="st"> </span>img_list[index]</span>
<span id="cb259-3"><a href="gans.html#cb259-3"></a></span>
<span id="cb259-4"><a href="gans.html#cb259-4"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">mar =</span> <span class="kw">rep</span>(<span class="fl">0.2</span>, <span class="dv">4</span>))</span>
<span id="cb259-5"><a href="gans.html#cb259-5"></a>rasterize &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</span>
<span id="cb259-6"><a href="gans.html#cb259-6"></a>    <span class="kw">as.raster</span>(x[<span class="dv">1</span>, , ])</span>
<span id="cb259-7"><a href="gans.html#cb259-7"></a>}</span>
<span id="cb259-8"><a href="gans.html#cb259-8"></a>images <span class="op">%&gt;%</span></span>
<span id="cb259-9"><a href="gans.html#cb259-9"></a><span class="st">    </span>purrr<span class="op">::</span><span class="kw">map</span>(rasterize) <span class="op">%&gt;%</span></span>
<span id="cb259-10"><a href="gans.html#cb259-10"></a><span class="st">    </span>purrr<span class="op">::</span><span class="kw">iwalk</span>(<span class="op">~</span>{<span class="kw">plot</span>(.x)})</span></code></pre></div>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="gans.html#cb260-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/gan_over_time.png&quot;</span>)</span></code></pre></div>
<p>To my (untrained) eyes, the final results look pretty good! Let’s generate a fresh batch:</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="gans.html#cb261-1"></a>new &lt;-<span class="st"> </span><span class="kw">gen</span>(fixed_noise)<span class="op">$</span><span class="kw">cpu</span>()<span class="op">$</span><span class="kw">detach</span>()[<span class="dv">1</span><span class="op">:</span><span class="dv">16</span>, , , ]</span>
<span id="cb261-2"><a href="gans.html#cb261-2"></a></span>
<span id="cb261-3"><a href="gans.html#cb261-3"></a>new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">normalize</span>() <span class="op">%&gt;%</span></span>
<span id="cb261-4"><a href="gans.html#cb261-4"></a><span class="st">  </span><span class="kw">as_array</span>() <span class="op">%&gt;%</span></span>
<span id="cb261-5"><a href="gans.html#cb261-5"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">array_tree</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb261-6"><a href="gans.html#cb261-6"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">map</span>(rasterize) <span class="op">%&gt;%</span></span>
<span id="cb261-7"><a href="gans.html#cb261-7"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">iwalk</span>(<span class="op">~</span>{<span class="kw">plot</span>(.x)})</span></code></pre></div>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="gans.html#cb262-1"></a><span class="co"># knitr::include_graphics(&quot;images/gan_over_time.png&quot;)</span></span></code></pre></div>
<p>We can also inspect how the respective losses developed over time:</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="gans.html#cb263-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb263-2"><a href="gans.html#cb263-2"></a><span class="kw">library</span>(tidyr)</span>
<span id="cb263-3"><a href="gans.html#cb263-3"></a></span>
<span id="cb263-4"><a href="gans.html#cb263-4"></a>iterations &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(disc_losses)</span>
<span id="cb263-5"><a href="gans.html#cb263-5"></a></span>
<span id="cb263-6"><a href="gans.html#cb263-6"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">iteration =</span> iterations, <span class="dt">discriminator =</span> disc_losses, <span class="dt">generator =</span> gen_losses)</span>
<span id="cb263-7"><a href="gans.html#cb263-7"></a>df <span class="op">%&gt;%</span></span>
<span id="cb263-8"><a href="gans.html#cb263-8"></a><span class="st">  </span><span class="kw">gather</span>(module, loss, discriminator, generator) <span class="op">%&gt;%</span></span>
<span id="cb263-9"><a href="gans.html#cb263-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> iteration, <span class="dt">y =</span> loss, <span class="dt">colour =</span> module)) <span class="op">+</span></span>
<span id="cb263-10"><a href="gans.html#cb263-10"></a><span class="st">  </span><span class="kw">geom_line</span>()</span></code></pre></div>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="gans.html#cb264-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/gan_losses.png&quot;</span>)</span></code></pre></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-clanuwat2018deep">
<p>Clanuwat, Tarin, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and David Ha. 2018. “Deep Learning for Classical Japanese Literature.” December 3, 2018. <a href="http://arxiv.org/abs/cs.CV/1812.01718">http://arxiv.org/abs/cs.CV/1812.01718</a>.</p>
</div>
<div id="ref-goodfellow2014generative">
<p>Goodfellow, Ian J., Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Networks.” <a href="http://arxiv.org/abs/1406.2661">http://arxiv.org/abs/1406.2661</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generative-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="vaes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
