<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11 Generative adversarial networks | Applied deep learning with torch from R</title>
  <meta name="description" content="tbd" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="11 Generative adversarial networks | Applied deep learning with torch from R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="tbd" />
  <meta property="og:image" content="tbdcover.png" />
  <meta property="og:description" content="tbd" />
  <meta name="github-repo" content="tbd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11 Generative adversarial networks | Applied deep learning with torch from R" />
  
  <meta name="twitter:description" content="tbd" />
  <meta name="twitter:image" content="tbdcover.png" />

<meta name="author" content="tbd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="generative-intro.html"/>
<link rel="next" href="vaes.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>I Using Torch</b></span></li>
<li class="chapter" data-level="" data-path="using-torch-intro.html"><a href="using-torch-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="2" data-path="simple-net-R.html"><a href="simple-net-R.html"><i class="fa fa-check"></i><b>2</b> A simple neural network in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#whats-in-a-network"><i class="fa fa-check"></i><b>2.1</b> What’s in a network?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="simple-net-R.html"><a href="simple-net-R.html#gradient-descent"><i class="fa fa-check"></i><b>2.1.1</b> Gradient descent</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-net-R.html"><a href="simple-net-R.html#from-linear-regression-to-a-simple-network"><i class="fa fa-check"></i><b>2.1.2</b> From linear regression to a simple network</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#a-simple-network"><i class="fa fa-check"></i><b>2.2</b> A simple network</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#simulate-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulate data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#initialize-weights-and-biases"><i class="fa fa-check"></i><b>2.2.2</b> Initialize weights and biases</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>2.2.3</b> Training loop</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-net-R.html"><a href="simple-net-R.html#complete-code"><i class="fa fa-check"></i><b>2.2.4</b> Complete code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>2.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html"><i class="fa fa-check"></i><b>3</b> Modifying the simple network to use torch tensors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#simple-network-torchified-step-1"><i class="fa fa-check"></i><b>3.1</b> Simple network torchified, step 1</a></li>
<li class="chapter" data-level="3.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#more-on-tensors"><i class="fa fa-check"></i><b>3.2</b> More on tensors</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#creating-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Creating tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#conversion-from-and-to-r"><i class="fa fa-check"></i><b>3.2.2</b> Conversion from and to R</a></li>
<li class="chapter" data-level="3.2.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#indexing-and-slicing-tensors"><i class="fa fa-check"></i><b>3.2.3</b> Indexing and slicing tensors</a></li>
<li class="chapter" data-level="3.2.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#reshaping-tensors"><i class="fa fa-check"></i><b>3.2.4</b> Reshaping tensors</a></li>
<li class="chapter" data-level="3.2.5" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#operations-on-tensors"><i class="fa fa-check"></i><b>3.2.5</b> Operations on tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#broadcasting"><i class="fa fa-check"></i><b>3.3</b> Broadcasting</a></li>
<li class="chapter" data-level="3.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#running-on-gpu"><i class="fa fa-check"></i><b>3.4</b> Running on GPU</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html"><i class="fa fa-check"></i><b>4</b> Using autograd</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#automatic-differentiation-with-autograd"><i class="fa fa-check"></i><b>4.1</b> Automatic differentiation with autograd</a></li>
<li class="chapter" data-level="4.2" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#the-simple-network-now-using-autograd"><i class="fa fa-check"></i><b>4.2</b> The simple network, now using autograd</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-net-modules.html"><a href="simple-net-modules.html"><i class="fa fa-check"></i><b>5</b> Using torch modules</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#modules"><i class="fa fa-check"></i><b>5.1</b> Modules</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#layers-as-modules"><i class="fa fa-check"></i><b>5.1.1</b> Layers as modules</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#models-as-modules"><i class="fa fa-check"></i><b>5.1.2</b> Models as modules</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#simple-network-using-modules"><i class="fa fa-check"></i><b>5.2</b> Simple network using modules</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-net-optim.html"><a href="simple-net-optim.html"><i class="fa fa-check"></i><b>6</b> Using torch optimizers</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple-net-optim.html"><a href="simple-net-optim.html#torch-optimizers"><i class="fa fa-check"></i><b>6.1</b> Torch optimizers</a></li>
<li class="chapter" data-level="6.2" data-path="simple-net-optim.html"><a href="simple-net-optim.html#simple-net-with-torch.optim"><i class="fa fa-check"></i><b>6.2</b> Simple net with <code>torch.optim</code></a></li>
</ul></li>
<li class="part"><span><b>II Image Recognition</b></span></li>
<li class="chapter" data-level="" data-path="image-recognition-intro.html"><a href="image-recognition-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="7" data-path="image-classification.html"><a href="image-classification.html"><i class="fa fa-check"></i><b>7</b> Classifying images</a>
<ul>
<li class="chapter" data-level="7.1" data-path="image-classification.html"><a href="image-classification.html#data-loading-and-transformation"><i class="fa fa-check"></i><b>7.1</b> Data loading and transformation</a></li>
<li class="chapter" data-level="7.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>7.2</b> Model</a></li>
<li class="chapter" data-level="7.3" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>7.3</b> Training</a></li>
<li class="chapter" data-level="7.4" data-path="image-classification.html"><a href="image-classification.html#performance-on-the-test-set"><i class="fa fa-check"></i><b>7.4</b> Performance on the test set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unet.html"><a href="unet.html"><i class="fa fa-check"></i><b>8</b> Brain Image Segmentation with U-Net</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unet.html"><a href="unet.html#image-segmentation-in-a-nutshell"><i class="fa fa-check"></i><b>8.1</b> Image segmentation in a nutshell</a></li>
<li class="chapter" data-level="8.2" data-path="unet.html"><a href="unet.html#u-net"><i class="fa fa-check"></i><b>8.2</b> U-Net</a></li>
<li class="chapter" data-level="8.3" data-path="unet.html"><a href="unet.html#example-application-mri-images"><i class="fa fa-check"></i><b>8.3</b> Example application: MRI images</a></li>
<li class="chapter" data-level="8.4" data-path="unet.html"><a href="unet.html#preprocessing"><i class="fa fa-check"></i><b>8.4</b> Preprocessing</a></li>
<li class="chapter" data-level="8.5" data-path="unet.html"><a href="unet.html#u-net-model"><i class="fa fa-check"></i><b>8.5</b> U-Net model</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="unet.html"><a href="unet.html#heading"><i class="fa fa-check"></i><b>8.5.1</b> heading</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Natural language processing</b></span></li>
<li class="chapter" data-level="" data-path="NLP-intro.html"><a href="NLP-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="9" data-path="seq2seq-att.html"><a href="seq2seq-att.html"><i class="fa fa-check"></i><b>9</b> Sequence-to-sequence models with attention</a>
<ul>
<li class="chapter" data-level="9.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#why-attention"><i class="fa fa-check"></i><b>9.1</b> Why attention?</a></li>
<li class="chapter" data-level="9.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#preprocessing-with-torchtext"><i class="fa fa-check"></i><b>9.2</b> Preprocessing with <code>torchtext</code></a></li>
<li class="chapter" data-level="9.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#model-1"><i class="fa fa-check"></i><b>9.3</b> Model</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>9.3.1</b> Encoder</a></li>
<li class="chapter" data-level="9.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#attention-module"><i class="fa fa-check"></i><b>9.3.2</b> Attention module</a></li>
<li class="chapter" data-level="9.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>9.3.3</b> Decoder</a></li>
<li class="chapter" data-level="9.3.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#seq2seq-module"><i class="fa fa-check"></i><b>9.3.4</b> Seq2seq module</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#training-and-evaluation"><i class="fa fa-check"></i><b>9.4</b> Training and evaluation</a></li>
<li class="chapter" data-level="9.5" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>9.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="transformer.html"><a href="transformer.html"><i class="fa fa-check"></i><b>10</b> Torch transformer modules</a>
<ul>
<li class="chapter" data-level="10.1" data-path="transformer.html"><a href="transformer.html#attention-is-all-you-need"><i class="fa fa-check"></i><b>10.1</b> “Attention is all you need”</a></li>
<li class="chapter" data-level="10.2" data-path="transformer.html"><a href="transformer.html#implementation-building-blocks"><i class="fa fa-check"></i><b>10.2</b> Implementation: building blocks</a></li>
<li class="chapter" data-level="10.3" data-path="transformer.html"><a href="transformer.html#a-transformer-for-natural-language-translation"><i class="fa fa-check"></i><b>10.3</b> A Transformer for natural language translation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="transformer.html"><a href="transformer.html#load-data"><i class="fa fa-check"></i><b>10.3.1</b> Load data</a></li>
<li class="chapter" data-level="10.3.2" data-path="transformer.html"><a href="transformer.html#encoder-1"><i class="fa fa-check"></i><b>10.3.2</b> Encoder</a></li>
<li class="chapter" data-level="10.3.3" data-path="transformer.html"><a href="transformer.html#decoder-1"><i class="fa fa-check"></i><b>10.3.3</b> Decoder</a></li>
<li class="chapter" data-level="10.3.4" data-path="transformer.html"><a href="transformer.html#overall-model"><i class="fa fa-check"></i><b>10.3.4</b> Overall model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="transformer.html"><a href="transformer.html#results-1"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
</ul></li>
<li class="part"><span><b>IV Deep learning for tabular data</b></span></li>
<li class="chapter" data-level="" data-path="tabular-intro.html"><a href="tabular-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V Generative deep learning</b></span></li>
<li class="chapter" data-level="" data-path="generative-intro.html"><a href="generative-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="11" data-path="gans.html"><a href="gans.html"><i class="fa fa-check"></i><b>11</b> Generative adversarial networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>11.1</b> Dataset</a></li>
<li class="chapter" data-level="11.2" data-path="gans.html"><a href="gans.html#model-2"><i class="fa fa-check"></i><b>11.2</b> Model</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="gans.html"><a href="gans.html#generator"><i class="fa fa-check"></i><b>11.2.1</b> Generator</a></li>
<li class="chapter" data-level="11.2.2" data-path="gans.html"><a href="gans.html#discriminator"><i class="fa fa-check"></i><b>11.2.2</b> Discriminator</a></li>
<li class="chapter" data-level="11.2.3" data-path="gans.html"><a href="gans.html#optimizers-and-loss-function"><i class="fa fa-check"></i><b>11.2.3</b> Optimizers and loss function</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="gans.html"><a href="gans.html#training-loop-1"><i class="fa fa-check"></i><b>11.3</b> Training loop</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="vaes.html"><a href="vaes.html"><i class="fa fa-check"></i><b>12</b> Variational autoencoders</a>
<ul>
<li class="chapter" data-level="12.1" data-path="vaes.html"><a href="vaes.html#dataset-1"><i class="fa fa-check"></i><b>12.1</b> Dataset</a></li>
<li class="chapter" data-level="12.2" data-path="vaes.html"><a href="vaes.html#model-3"><i class="fa fa-check"></i><b>12.2</b> Model</a></li>
<li class="chapter" data-level="12.3" data-path="vaes.html"><a href="vaes.html#training-the-vae"><i class="fa fa-check"></i><b>12.3</b> Training the VAE</a></li>
<li class="chapter" data-level="12.4" data-path="vaes.html"><a href="vaes.html#latent-space"><i class="fa fa-check"></i><b>12.4</b> Latent space</a></li>
</ul></li>
<li class="part"><span><b>VI Deep learning on graphs</b></span></li>
<li class="chapter" data-level="" data-path="graph-intro.html"><a href="graph-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VII Probabilistic deep learning</b></span></li>
<li class="chapter" data-level="" data-path="probabilistic-intro.html"><a href="probabilistic-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VIII Private and secure deep learning</b></span></li>
<li class="chapter" data-level="" data-path="private-secure-intro.html"><a href="private-secure-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>IX Research topics</b></span></li>
<li class="chapter" data-level="" data-path="research-intro.html"><a href="research-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied deep learning with torch from R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gans" class="section level1" number="11">
<h1><span class="header-section-number">11</span> Generative adversarial networks</h1>
<p><em>Generative Adversarial Networks</em> (GANs) are one of the most successful, as of this writing, unsupervised (or self-supervised,
rather) deep learning architectures . In GANs, there is no well-defined loss function; instead, the setup is fundamentally
game-theoretic: Two actors, the <em>generator</em> and the <em>discriminator</em>, each try to minimize their loss; the outcome should be
some artifact – image, text, what have you – that resembles the training data but does not copy them.</p>
<p>In theory, this is a highly fascinating approach; in practice, it can be a challenge to set parameters in a way that good
results are achieved. The architecture and settings presented here follow those reported in the original DCGAN article
<span class="citation">(Goodfellow et al. <a href="#ref-goodfellow2014generative" role="doc-biblioref">2014</a>)</span>. In the meantime, a lot of research has been done; minor changes to loss functions, optimizers
and/or parameters may make an important difference.</p>
<div id="dataset" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Dataset</h2>
<p>For this task, we use <a href="https://github.com/rois-codh/kmnist">Kuzushiji-MNIST</a> <span class="citation">(Clanuwat et al. <a href="#ref-clanuwat2018deep" role="doc-biblioref">2018</a>)</span>, one of the more recent MNIST
drop-ins. Kuzushiji-MNIST contains 70,000 grayscale images, of size 28x28 px just like MNIST, and also like MNIST, divided
into 10 classes.</p>
<p>We can use torch for loading it. With an unsupervised learning task such as this one, we only need the training set:</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb167-1"><a href="gans.html#cb167-1"></a><span class="im">import</span> torch</span>
<span id="cb167-2"><a href="gans.html#cb167-2"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb167-3"><a href="gans.html#cb167-3"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb167-4"><a href="gans.html#cb167-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb167-5"><a href="gans.html#cb167-5"></a><span class="im">import</span> torchvision</span>
<span id="cb167-6"><a href="gans.html#cb167-6"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms, datasets, utils</span>
<span id="cb167-7"><a href="gans.html#cb167-7"></a><span class="im">import</span> os</span>
<span id="cb167-8"><a href="gans.html#cb167-8"></a></span>
<span id="cb167-9"><a href="gans.html#cb167-9"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb167-10"><a href="gans.html#cb167-10"></a></span>
<span id="cb167-11"><a href="gans.html#cb167-11"></a>kmnist <span class="op">=</span> torchvision.datasets.KMNIST(<span class="st">&quot;data/kmnist&quot;</span>, train <span class="op">=</span> <span class="va">True</span>, transform <span class="op">=</span> transform, download <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb167-12"><a href="gans.html#cb167-12"></a></span>
<span id="cb167-13"><a href="gans.html#cb167-13"></a>dataloader <span class="op">=</span> torch.utils.data.DataLoader(kmnist, batch_size<span class="op">=</span><span class="dv">128</span>, shuffle <span class="op">=</span> <span class="va">True</span>, num_workers <span class="op">=</span> <span class="dv">8</span>)</span></code></pre></div>
<p>Let’s view a few of those. Here are the first 128 images:</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb168-1"><a href="gans.html#cb168-1"></a>images <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader))[<span class="dv">0</span>].cpu()</span>
<span id="cb168-2"><a href="gans.html#cb168-2"></a>images.device</span></code></pre></div>
<p>… of which, let’s plot the first 16:</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="gans.html#cb169-1"></a><span class="kw">library</span>(reticulate)</span>
<span id="cb169-2"><a href="gans.html#cb169-2"></a><span class="kw">library</span>(dplyr)</span>
<span id="cb169-3"><a href="gans.html#cb169-3"></a></span>
<span id="cb169-4"><a href="gans.html#cb169-4"></a>index &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">16</span></span>
<span id="cb169-5"><a href="gans.html#cb169-5"></a>images &lt;-<span class="st"> </span>py<span class="op">$</span>images<span class="op">$</span><span class="kw">numpy</span>()[index,,,] </span>
<span id="cb169-6"><a href="gans.html#cb169-6"></a></span>
<span id="cb169-7"><a href="gans.html#cb169-7"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">mar =</span> <span class="kw">rep</span>(<span class="fl">0.2</span>, <span class="dv">4</span>))</span>
<span id="cb169-8"><a href="gans.html#cb169-8"></a>images <span class="op">%&gt;%</span></span>
<span id="cb169-9"><a href="gans.html#cb169-9"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">array_tree</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb169-10"><a href="gans.html#cb169-10"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">map</span>(as.raster) <span class="op">%&gt;%</span></span>
<span id="cb169-11"><a href="gans.html#cb169-11"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">iwalk</span>(<span class="op">~</span>{<span class="kw">plot</span>(.x)})</span></code></pre></div>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="gans.html#cb170-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/gan_real.png&quot;</span>)</span></code></pre></div>
</div>
<div id="model-2" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Model</h2>
<p>The model, in the abstract sense, consists of the interplay of two models, in the concrete sense – two torch <em>modules</em>. The
<em>generator</em> produces fake artifacts – fake Kuzushiji digits, in our case – in the hope of getting better and better at it;
the <em>discriminator</em> is tasked with telling actual from fake images. (Its task should, if all goes well, get more difficult
over time.)</p>
<p>Let’s start with the generator.</p>
<div id="generator" class="section level3" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Generator</h3>
<p>The generator is given a random noise vector (1d), and has to produce images (2d, of a given resolution). Its main tool is
repeated application of <em>transposed convolutions</em> that upsample from a resolution of 1x1 to the required resolution of 28x28.</p>
<p>Following the DCGAN paper, the generator’s <code>ConvTranspose2d</code> and <code>BatchNorm2d</code> layers are initialized according to a normal
distribution with mean 0 and standard deviation 0.02.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="gans.html#cb171-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda:0&quot;</span> <span class="cf">if</span> torch.cuda.is_available()  <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb171-2"><a href="gans.html#cb171-2"></a></span>
<span id="cb171-3"><a href="gans.html#cb171-3"></a><span class="co"># size of generator input</span></span>
<span id="cb171-4"><a href="gans.html#cb171-4"></a>latent_input_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb171-5"><a href="gans.html#cb171-5"></a></span>
<span id="cb171-6"><a href="gans.html#cb171-6"></a>image_size <span class="op">=</span> <span class="dv">28</span></span>
<span id="cb171-7"><a href="gans.html#cb171-7"></a></span>
<span id="cb171-8"><a href="gans.html#cb171-8"></a><span class="kw">class</span> Generator(nn.Module):</span>
<span id="cb171-9"><a href="gans.html#cb171-9"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb171-10"><a href="gans.html#cb171-10"></a>        <span class="bu">super</span>(Generator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb171-11"><a href="gans.html#cb171-11"></a>        <span class="va">self</span>.main <span class="op">=</span> nn.Sequential(</span>
<span id="cb171-12"><a href="gans.html#cb171-12"></a>            <span class="co"># h_out = (h_in - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1</span></span>
<span id="cb171-13"><a href="gans.html#cb171-13"></a>            <span class="co"># h_out = (  1  - 1) *   1    - 2 *    0    +     1    * (      4     - 1) +        0       + 1</span></span>
<span id="cb171-14"><a href="gans.html#cb171-14"></a>            <span class="co"># 4 x 4</span></span>
<span id="cb171-15"><a href="gans.html#cb171-15"></a>            nn.ConvTranspose2d(latent_input_size, image_size <span class="op">*</span> <span class="dv">4</span>, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">1</span>, padding <span class="op">=</span> <span class="dv">0</span>, bias <span class="op">=</span> <span class="va">False</span>),</span>
<span id="cb171-16"><a href="gans.html#cb171-16"></a>            nn.BatchNorm2d(image_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb171-17"><a href="gans.html#cb171-17"></a>            nn.ReLU(<span class="va">True</span>),</span>
<span id="cb171-18"><a href="gans.html#cb171-18"></a>            <span class="co"># 8 * 8</span></span>
<span id="cb171-19"><a href="gans.html#cb171-19"></a>            nn.ConvTranspose2d(image_size <span class="op">*</span> <span class="dv">4</span>, image_size <span class="op">*</span> <span class="dv">2</span>, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">2</span>, padding <span class="op">=</span> <span class="dv">1</span>, bias <span class="op">=</span> <span class="va">False</span>),</span>
<span id="cb171-20"><a href="gans.html#cb171-20"></a>            nn.BatchNorm2d(image_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb171-21"><a href="gans.html#cb171-21"></a>            nn.ReLU(<span class="va">True</span>),</span>
<span id="cb171-22"><a href="gans.html#cb171-22"></a>            <span class="co"># 16 x 16</span></span>
<span id="cb171-23"><a href="gans.html#cb171-23"></a>            nn.ConvTranspose2d(image_size <span class="op">*</span> <span class="dv">2</span>, image_size, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">2</span>, padding <span class="op">=</span> <span class="dv">2</span>, bias <span class="op">=</span> <span class="va">False</span>),</span>
<span id="cb171-24"><a href="gans.html#cb171-24"></a>            nn.BatchNorm2d(image_size),</span>
<span id="cb171-25"><a href="gans.html#cb171-25"></a>            nn.ReLU(<span class="va">True</span>),</span>
<span id="cb171-26"><a href="gans.html#cb171-26"></a>            <span class="co"># 28 x 28</span></span>
<span id="cb171-27"><a href="gans.html#cb171-27"></a>            nn.ConvTranspose2d(image_size, <span class="dv">1</span>, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">2</span>, padding <span class="op">=</span> <span class="dv">1</span>, bias <span class="op">=</span> <span class="va">False</span>),</span>
<span id="cb171-28"><a href="gans.html#cb171-28"></a>            nn.Tanh()</span>
<span id="cb171-29"><a href="gans.html#cb171-29"></a>        )</span>
<span id="cb171-30"><a href="gans.html#cb171-30"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb171-31"><a href="gans.html#cb171-31"></a>        <span class="cf">return</span> <span class="va">self</span>.main(<span class="bu">input</span>)</span>
<span id="cb171-32"><a href="gans.html#cb171-32"></a></span>
<span id="cb171-33"><a href="gans.html#cb171-33"></a>generator <span class="op">=</span> Generator().to(device)</span>
<span id="cb171-34"><a href="gans.html#cb171-34"></a></span>
<span id="cb171-35"><a href="gans.html#cb171-35"></a><span class="kw">def</span> weights_init(m):</span>
<span id="cb171-36"><a href="gans.html#cb171-36"></a>    classname <span class="op">=</span> m.__class__.<span class="va">__name__</span></span>
<span id="cb171-37"><a href="gans.html#cb171-37"></a>    <span class="cf">if</span> classname.find(<span class="st">&#39;Conv&#39;</span>) <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb171-38"><a href="gans.html#cb171-38"></a>        nn.init.normal_(m.weight.data, <span class="fl">0.0</span>, <span class="fl">0.02</span>)</span>
<span id="cb171-39"><a href="gans.html#cb171-39"></a>    <span class="cf">elif</span> classname.find(<span class="st">&#39;BatchNorm&#39;</span>) <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb171-40"><a href="gans.html#cb171-40"></a>        nn.init.normal_(m.weight.data, <span class="fl">1.0</span>, <span class="fl">0.02</span>)</span>
<span id="cb171-41"><a href="gans.html#cb171-41"></a>        nn.init.constant_(m.bias.data, <span class="dv">0</span>)</span>
<span id="cb171-42"><a href="gans.html#cb171-42"></a>        </span>
<span id="cb171-43"><a href="gans.html#cb171-43"></a>generator.<span class="bu">apply</span>(weights_init)</span></code></pre></div>
</div>
<div id="discriminator" class="section level3" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Discriminator</h3>
<p>The discriminator is a pretty conventional convnet. Its layers’ weights are initialized in the same way as the generator’s.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="gans.html#cb172-1"></a><span class="kw">class</span> Discriminator(nn.Module):</span>
<span id="cb172-2"><a href="gans.html#cb172-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb172-3"><a href="gans.html#cb172-3"></a>        <span class="bu">super</span>(Discriminator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb172-4"><a href="gans.html#cb172-4"></a>        <span class="va">self</span>.main <span class="op">=</span> nn.Sequential(</span>
<span id="cb172-5"><a href="gans.html#cb172-5"></a>            <span class="co"># 14 x 14</span></span>
<span id="cb172-6"><a href="gans.html#cb172-6"></a>            nn.Conv2d(<span class="dv">1</span>, image_size, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb172-7"><a href="gans.html#cb172-7"></a>            nn.LeakyReLU(<span class="fl">0.2</span>, inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb172-8"><a href="gans.html#cb172-8"></a>            <span class="co"># 7 x 7</span></span>
<span id="cb172-9"><a href="gans.html#cb172-9"></a>            nn.Conv2d(image_size, image_size <span class="op">*</span> <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb172-10"><a href="gans.html#cb172-10"></a>            nn.BatchNorm2d(image_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb172-11"><a href="gans.html#cb172-11"></a>            nn.LeakyReLU(<span class="fl">0.2</span>, inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb172-12"><a href="gans.html#cb172-12"></a>            <span class="co"># 3 x 3</span></span>
<span id="cb172-13"><a href="gans.html#cb172-13"></a>            nn.Conv2d(image_size <span class="op">*</span> <span class="dv">2</span>, image_size <span class="op">*</span> <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb172-14"><a href="gans.html#cb172-14"></a>            nn.BatchNorm2d(image_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb172-15"><a href="gans.html#cb172-15"></a>            nn.LeakyReLU(<span class="fl">0.2</span>, inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb172-16"><a href="gans.html#cb172-16"></a>            <span class="co"># 1 x 1</span></span>
<span id="cb172-17"><a href="gans.html#cb172-17"></a>            nn.Conv2d(image_size <span class="op">*</span> <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb172-18"><a href="gans.html#cb172-18"></a>            nn.Sigmoid()</span>
<span id="cb172-19"><a href="gans.html#cb172-19"></a>        )</span>
<span id="cb172-20"><a href="gans.html#cb172-20"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb172-21"><a href="gans.html#cb172-21"></a>        <span class="cf">return</span> <span class="va">self</span>.main(<span class="bu">input</span>)</span>
<span id="cb172-22"><a href="gans.html#cb172-22"></a></span>
<span id="cb172-23"><a href="gans.html#cb172-23"></a></span>
<span id="cb172-24"><a href="gans.html#cb172-24"></a>discriminator <span class="op">=</span> Discriminator().to(device)</span>
<span id="cb172-25"><a href="gans.html#cb172-25"></a></span>
<span id="cb172-26"><a href="gans.html#cb172-26"></a>discriminator.<span class="bu">apply</span>(weights_init)</span></code></pre></div>
</div>
<div id="optimizers-and-loss-function" class="section level3" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Optimizers and loss function</h3>
<p>While generator and discriminator have each their own losses, mathematically both use the same calculation, namely, binary
crossentropy:</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb173-1"><a href="gans.html#cb173-1"></a>criterion <span class="op">=</span> nn.BCELoss()</span></code></pre></div>
<p>They each have their own optimizer:</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb174-1"><a href="gans.html#cb174-1"></a>lr <span class="op">=</span> <span class="fl">0.0002</span></span>
<span id="cb174-2"><a href="gans.html#cb174-2"></a>beta1 <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb174-3"><a href="gans.html#cb174-3"></a></span>
<span id="cb174-4"><a href="gans.html#cb174-4"></a>disc_optimizer <span class="op">=</span> optim.Adam(discriminator.parameters(), lr <span class="op">=</span> lr, betas <span class="op">=</span> (beta1, <span class="fl">0.999</span>))</span>
<span id="cb174-5"><a href="gans.html#cb174-5"></a>gen_optimizer <span class="op">=</span> optim.Adam(generator.parameters(), lr <span class="op">=</span> lr, betas <span class="op">=</span> (beta1, <span class="fl">0.999</span>))</span></code></pre></div>
</div>
</div>
<div id="training-loop-1" class="section level2" number="11.3">
<h2><span class="header-section-number">11.3</span> Training loop</h2>
<p>In every epoch, the training loop consists of three parts.</p>
<p>First, the discriminator is trained. This is a two-stage procedure: - In stage (1), it is given the real images, together with
labels (fabricated on the fly) that say “these are real images”. Binary cross entropy will be minimized when all those images
are, in fact, classified as real by the discriminator. - In stage (2), first the generator is asked to generate some images,
and then the discriminator is asked to rate them. Again, binary cross entropy is calculated, but this time, it will be minimal
if all images are characterized as fake.</p>
<p>Once gradients have been obtained in both computations, the discriminator’s weights are updated. Then it’s the generator’s
turn. We pass the newly generated fakes to the discriminator again; only this time, the desired verdict is “no fake”, so the
labels are set to “real”. The binary cross entropy loss then reflects the generator’s performance, not that of the
discriminator.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="gans.html#cb175-1"></a><span class="co"># random noise - input for generator</span></span>
<span id="cb175-2"><a href="gans.html#cb175-2"></a>fixed_noise <span class="op">=</span> torch.randn(<span class="dv">64</span>, latent_input_size, <span class="dv">1</span>, <span class="dv">1</span>, device <span class="op">=</span> device)</span>
<span id="cb175-3"><a href="gans.html#cb175-3"></a></span>
<span id="cb175-4"><a href="gans.html#cb175-4"></a>real_label <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb175-5"><a href="gans.html#cb175-5"></a>fake_label <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb175-6"><a href="gans.html#cb175-6"></a></span>
<span id="cb175-7"><a href="gans.html#cb175-7"></a>img_list <span class="op">=</span> []</span>
<span id="cb175-8"><a href="gans.html#cb175-8"></a>generator_losses <span class="op">=</span> []</span>
<span id="cb175-9"><a href="gans.html#cb175-9"></a>discriminator_losses <span class="op">=</span> []</span>
<span id="cb175-10"><a href="gans.html#cb175-10"></a>discriminator_outputs_fake <span class="op">=</span> []</span>
<span id="cb175-11"><a href="gans.html#cb175-11"></a>discriminator_outputs_real <span class="op">=</span> []</span>
<span id="cb175-12"><a href="gans.html#cb175-12"></a></span>
<span id="cb175-13"><a href="gans.html#cb175-13"></a>num_epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb175-14"><a href="gans.html#cb175-14"></a></span>
<span id="cb175-15"><a href="gans.html#cb175-15"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb175-16"><a href="gans.html#cb175-16"></a></span>
<span id="cb175-17"><a href="gans.html#cb175-17"></a>    <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader, <span class="dv">0</span>):</span>
<span id="cb175-18"><a href="gans.html#cb175-18"></a>    </span>
<span id="cb175-19"><a href="gans.html#cb175-19"></a>        <span class="co"># (1) Train discriminator</span></span>
<span id="cb175-20"><a href="gans.html#cb175-20"></a>        </span>
<span id="cb175-21"><a href="gans.html#cb175-21"></a>        <span class="co">## Train with all-real batch</span></span>
<span id="cb175-22"><a href="gans.html#cb175-22"></a></span>
<span id="cb175-23"><a href="gans.html#cb175-23"></a>        discriminator.zero_grad()</span>
<span id="cb175-24"><a href="gans.html#cb175-24"></a>        real_cpu <span class="op">=</span> data[<span class="dv">0</span>].to(device)</span>
<span id="cb175-25"><a href="gans.html#cb175-25"></a>        b_size <span class="op">=</span> real_cpu.size(<span class="dv">0</span>)</span>
<span id="cb175-26"><a href="gans.html#cb175-26"></a>        label <span class="op">=</span> torch.full((b_size,), real_label, device<span class="op">=</span>device)</span>
<span id="cb175-27"><a href="gans.html#cb175-27"></a>        output <span class="op">=</span> discriminator(real_cpu).view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb175-28"><a href="gans.html#cb175-28"></a>        discriminator_loss_real <span class="op">=</span> criterion(output, label)</span>
<span id="cb175-29"><a href="gans.html#cb175-29"></a>        discriminator_loss_real.backward()</span>
<span id="cb175-30"><a href="gans.html#cb175-30"></a>        discriminator_output_real <span class="op">=</span> output.mean().item()</span>
<span id="cb175-31"><a href="gans.html#cb175-31"></a>        </span>
<span id="cb175-32"><a href="gans.html#cb175-32"></a>        <span class="co">## Train with all-fake batch</span></span>
<span id="cb175-33"><a href="gans.html#cb175-33"></a></span>
<span id="cb175-34"><a href="gans.html#cb175-34"></a>        noise <span class="op">=</span> torch.randn(b_size, latent_input_size, <span class="dv">1</span>, <span class="dv">1</span>, device<span class="op">=</span>device)</span>
<span id="cb175-35"><a href="gans.html#cb175-35"></a>        fake <span class="op">=</span> generator(noise)</span>
<span id="cb175-36"><a href="gans.html#cb175-36"></a>        label.fill_(fake_label)</span>
<span id="cb175-37"><a href="gans.html#cb175-37"></a>        output <span class="op">=</span> discriminator(fake.detach()).view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb175-38"><a href="gans.html#cb175-38"></a>        discriminator_loss_fake <span class="op">=</span> criterion(output, label)</span>
<span id="cb175-39"><a href="gans.html#cb175-39"></a>        discriminator_loss_fake.backward()</span>
<span id="cb175-40"><a href="gans.html#cb175-40"></a>    </span>
<span id="cb175-41"><a href="gans.html#cb175-41"></a>        <span class="co"># Update discriminator weights</span></span>
<span id="cb175-42"><a href="gans.html#cb175-42"></a>    </span>
<span id="cb175-43"><a href="gans.html#cb175-43"></a>        discriminator_loss <span class="op">=</span> discriminator_loss_real <span class="op">+</span> discriminator_loss_fake    </span>
<span id="cb175-44"><a href="gans.html#cb175-44"></a>        disc_optimizer.step()</span>
<span id="cb175-45"><a href="gans.html#cb175-45"></a></span>
<span id="cb175-46"><a href="gans.html#cb175-46"></a>        <span class="co"># (2) Train generator</span></span>
<span id="cb175-47"><a href="gans.html#cb175-47"></a></span>
<span id="cb175-48"><a href="gans.html#cb175-48"></a>        generator.zero_grad()</span>
<span id="cb175-49"><a href="gans.html#cb175-49"></a>        label.fill_(real_label)  </span>
<span id="cb175-50"><a href="gans.html#cb175-50"></a>        output <span class="op">=</span> discriminator(fake).view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb175-51"><a href="gans.html#cb175-51"></a>        generator_loss <span class="op">=</span> criterion(output, label)</span>
<span id="cb175-52"><a href="gans.html#cb175-52"></a>        generator_loss.backward()</span>
<span id="cb175-53"><a href="gans.html#cb175-53"></a>        discriminator_output_fake <span class="op">=</span> output.mean().item()</span>
<span id="cb175-54"><a href="gans.html#cb175-54"></a></span>
<span id="cb175-55"><a href="gans.html#cb175-55"></a>        <span class="co"># Update generator weights</span></span>
<span id="cb175-56"><a href="gans.html#cb175-56"></a>        gen_optimizer.step()</span>
<span id="cb175-57"><a href="gans.html#cb175-57"></a></span>
<span id="cb175-58"><a href="gans.html#cb175-58"></a>        <span class="co"># Output training stats</span></span>
<span id="cb175-59"><a href="gans.html#cb175-59"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">50</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb175-60"><a href="gans.html#cb175-60"></a>            <span class="bu">print</span>(<span class="st">&#39;[</span><span class="sc">%d</span><span class="st">/</span><span class="sc">%d</span><span class="st">][</span><span class="sc">%d</span><span class="st">/</span><span class="sc">%d</span><span class="st">]</span><span class="ch">\t</span><span class="st">Loss_D: </span><span class="sc">%.4f</span><span class="ch">\t</span><span class="st">Loss_G: </span><span class="sc">%.4f</span><span class="ch">\t</span><span class="st">D(x): </span><span class="sc">%.4f</span><span class="ch">\t</span><span class="st">D(G(z)): </span><span class="sc">%.4f</span><span class="st"> &#39;</span></span>
<span id="cb175-61"><a href="gans.html#cb175-61"></a>                  <span class="op">%</span> (epoch, num_epochs, i, <span class="bu">len</span>(dataloader),</span>
<span id="cb175-62"><a href="gans.html#cb175-62"></a>                     discriminator_loss.item(), generator_loss.item(), discriminator_output_real, discriminator_output_fake))</span>
<span id="cb175-63"><a href="gans.html#cb175-63"></a>            generator_losses.append(generator_loss.item())</span>
<span id="cb175-64"><a href="gans.html#cb175-64"></a>            discriminator_losses.append(discriminator_loss.item())</span>
<span id="cb175-65"><a href="gans.html#cb175-65"></a>            discriminator_outputs_fake.append(discriminator_output_fake)</span>
<span id="cb175-66"><a href="gans.html#cb175-66"></a>            discriminator_outputs_real.append(discriminator_output_real)</span>
<span id="cb175-67"><a href="gans.html#cb175-67"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb175-68"><a href="gans.html#cb175-68"></a>              fake <span class="op">=</span> generator(fixed_noise).detach().cpu()</span>
<span id="cb175-69"><a href="gans.html#cb175-69"></a>              img_list.append(utils.make_grid(fake, padding<span class="op">=</span><span class="dv">2</span>, normalize<span class="op">=</span><span class="va">True</span>))</span></code></pre></div>
<p>Now let’s see samples of generated images, spread out over training time:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="gans.html#cb176-1"></a>index &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(py<span class="op">$</span>img_list), <span class="dt">length.out =</span> <span class="dv">16</span>)</span>
<span id="cb176-2"><a href="gans.html#cb176-2"></a><span class="co"># these have 3 channels! (probably due to torchvision.utils.make_grid)</span></span>
<span id="cb176-3"><a href="gans.html#cb176-3"></a><span class="co"># size is 3 x 242 x 242</span></span>
<span id="cb176-4"><a href="gans.html#cb176-4"></a>images &lt;-<span class="st"> </span>py<span class="op">$</span>img_list[index]</span>
<span id="cb176-5"><a href="gans.html#cb176-5"></a></span>
<span id="cb176-6"><a href="gans.html#cb176-6"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">mar =</span> <span class="kw">rep</span>(<span class="fl">0.2</span>, <span class="dv">4</span>))</span>
<span id="cb176-7"><a href="gans.html#cb176-7"></a>rasterize &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</span>
<span id="cb176-8"><a href="gans.html#cb176-8"></a>     x &lt;-<span class="st"> </span>x<span class="op">$</span><span class="kw">numpy</span>()</span>
<span id="cb176-9"><a href="gans.html#cb176-9"></a>     x &lt;-<span class="st"> </span><span class="kw">aperm</span>(x, <span class="dt">perm =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb176-10"><a href="gans.html#cb176-10"></a>     <span class="kw">as.raster</span>(x)</span>
<span id="cb176-11"><a href="gans.html#cb176-11"></a>}</span>
<span id="cb176-12"><a href="gans.html#cb176-12"></a>images <span class="op">%&gt;%</span></span>
<span id="cb176-13"><a href="gans.html#cb176-13"></a><span class="st">   </span>purrr<span class="op">::</span><span class="kw">map</span>(rasterize) <span class="op">%&gt;%</span></span>
<span id="cb176-14"><a href="gans.html#cb176-14"></a><span class="st">   </span>purrr<span class="op">::</span><span class="kw">iwalk</span>(<span class="op">~</span>{<span class="kw">plot</span>(.x)})</span></code></pre></div>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="gans.html#cb177-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/gan_over_time.png&quot;</span>)</span></code></pre></div>
<p>To my (untrained) eyes, the final results look pretty good! Let’s generate a fresh batch:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="gans.html#cb178-1"></a>new <span class="op">=</span> generator(fixed_noise).cpu().detach().numpy()</span></code></pre></div>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="gans.html#cb179-1"></a><span class="co"># dim 64 x 28 x 28 because drop </span></span>
<span id="cb179-2"><a href="gans.html#cb179-2"></a>images &lt;-<span class="st"> </span>py<span class="op">$</span>new[,<span class="dv">1</span>,,] </span>
<span id="cb179-3"><a href="gans.html#cb179-3"></a>images[images <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb179-4"><a href="gans.html#cb179-4"></a></span>
<span id="cb179-5"><a href="gans.html#cb179-5"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">8</span>,<span class="dv">8</span>), <span class="dt">mar =</span> <span class="kw">rep</span>(<span class="fl">0.2</span>, <span class="dv">4</span>))</span>
<span id="cb179-6"><a href="gans.html#cb179-6"></a>images <span class="op">%&gt;%</span></span>
<span id="cb179-7"><a href="gans.html#cb179-7"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">array_tree</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb179-8"><a href="gans.html#cb179-8"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">map</span>(as.raster) <span class="op">%&gt;%</span></span>
<span id="cb179-9"><a href="gans.html#cb179-9"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">iwalk</span>(<span class="op">~</span>{<span class="kw">plot</span>(.x)})</span></code></pre></div>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="gans.html#cb180-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/gan_over_time.png&quot;</span>)</span></code></pre></div>
<p>We can also inspect how the respective losses developed over time:</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="gans.html#cb181-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb181-2"><a href="gans.html#cb181-2"></a><span class="kw">library</span>(tidyr)</span>
<span id="cb181-3"><a href="gans.html#cb181-3"></a></span>
<span id="cb181-4"><a href="gans.html#cb181-4"></a>generator_losses &lt;-<span class="st"> </span>py<span class="op">$</span>generator_losses</span>
<span id="cb181-5"><a href="gans.html#cb181-5"></a>discriminator_losses &lt;-<span class="st"> </span>py<span class="op">$</span>discriminator_losses</span>
<span id="cb181-6"><a href="gans.html#cb181-6"></a>iterations &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(discriminator_losses)</span>
<span id="cb181-7"><a href="gans.html#cb181-7"></a></span>
<span id="cb181-8"><a href="gans.html#cb181-8"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">iteration =</span> iterations, <span class="dt">discriminator =</span> discriminator_losses, <span class="dt">generator =</span> generator_losses)</span>
<span id="cb181-9"><a href="gans.html#cb181-9"></a>df <span class="op">%&gt;%</span></span>
<span id="cb181-10"><a href="gans.html#cb181-10"></a><span class="st">  </span><span class="kw">gather</span>(module, loss, discriminator, generator) <span class="op">%&gt;%</span></span>
<span id="cb181-11"><a href="gans.html#cb181-11"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> iteration, <span class="dt">y =</span> loss, <span class="dt">colour =</span> module)) <span class="op">+</span></span>
<span id="cb181-12"><a href="gans.html#cb181-12"></a><span class="st">    </span><span class="kw">geom_line</span>()</span></code></pre></div>
<p>As well as find out what proportion of real images was classified as real by the discriminator (green line), contrasting this
with the proportion of fake images the discriminator thought were real. Ideally, we would hope for both lines to close to 0.5
(and thus, close to each other), which obviously isn’t the case here. This means there is still room for improvement.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="gans.html#cb182-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb182-2"><a href="gans.html#cb182-2"></a><span class="kw">library</span>(tidyr)</span>
<span id="cb182-3"><a href="gans.html#cb182-3"></a></span>
<span id="cb182-4"><a href="gans.html#cb182-4"></a>discriminator_outputs_fake &lt;-<span class="st"> </span>py<span class="op">$</span>discriminator_outputs_fake</span>
<span id="cb182-5"><a href="gans.html#cb182-5"></a>discriminator_outputs_real &lt;-<span class="st"> </span>py<span class="op">$</span>discriminator_outputs_real</span>
<span id="cb182-6"><a href="gans.html#cb182-6"></a>iterations &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(discriminator_outputs_real)</span>
<span id="cb182-7"><a href="gans.html#cb182-7"></a></span>
<span id="cb182-8"><a href="gans.html#cb182-8"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">iteration =</span> iterations, <span class="dt">real =</span> discriminator_outputs_real, <span class="dt">fake =</span> discriminator_outputs_fake)</span>
<span id="cb182-9"><a href="gans.html#cb182-9"></a>df <span class="op">%&gt;%</span></span>
<span id="cb182-10"><a href="gans.html#cb182-10"></a><span class="st">  </span><span class="kw">gather</span>(images, ratio_accepted, real, fake) <span class="op">%&gt;%</span></span>
<span id="cb182-11"><a href="gans.html#cb182-11"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> iteration, <span class="dt">y =</span> ratio_accepted, <span class="dt">colour =</span> images)) <span class="op">+</span></span>
<span id="cb182-12"><a href="gans.html#cb182-12"></a><span class="st">    </span><span class="kw">geom_line</span>()</span></code></pre></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-clanuwat2018deep">
<p>Clanuwat, Tarin, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and David Ha. 2018. “Deep Learning for Classical Japanese Literature.” December 3, 2018. <a href="http://arxiv.org/abs/cs.CV/1812.01718">http://arxiv.org/abs/cs.CV/1812.01718</a>.</p>
</div>
<div id="ref-goodfellow2014generative">
<p>Goodfellow, Ian J., Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Networks.” <a href="http://arxiv.org/abs/1406.2661">http://arxiv.org/abs/1406.2661</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generative-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="vaes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
