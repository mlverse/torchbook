<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Classifying images | Applied deep learning with torch from R</title>
  <meta name="description" content="tbd" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Classifying images | Applied deep learning with torch from R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="tbd" />
  <meta property="og:image" content="tbdcover.png" />
  <meta property="og:description" content="tbd" />
  <meta name="github-repo" content="tbd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Classifying images | Applied deep learning with torch from R" />
  
  <meta name="twitter:description" content="tbd" />
  <meta name="twitter:image" content="tbdcover.png" />

<meta name="author" content="tbd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="image-recognition-intro.html"/>
<link rel="next" href="unet.html"/>
<script src="libs/header-attrs-2.4.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>I Using Torch</b></span></li>
<li class="chapter" data-level="" data-path="using-torch-intro.html"><a href="using-torch-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="2" data-path="simple-net-R.html"><a href="simple-net-R.html"><i class="fa fa-check"></i><b>2</b> A simple neural network in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#whats-in-a-network"><i class="fa fa-check"></i><b>2.1</b> What’s in a network?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="simple-net-R.html"><a href="simple-net-R.html#gradient-descent"><i class="fa fa-check"></i><b>2.1.1</b> Gradient descent</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-net-R.html"><a href="simple-net-R.html#from-linear-regression-to-a-simple-network"><i class="fa fa-check"></i><b>2.1.2</b> From linear regression to a simple network</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#a-simple-network"><i class="fa fa-check"></i><b>2.2</b> A simple network</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#simulate-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulate data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#initialize-weights-and-biases"><i class="fa fa-check"></i><b>2.2.2</b> Initialize weights and biases</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>2.2.3</b> Training loop</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-net-R.html"><a href="simple-net-R.html#complete-code"><i class="fa fa-check"></i><b>2.2.4</b> Complete code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html"><i class="fa fa-check"></i><b>3</b> Modifying the simple network to use torch tensors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#tensors"><i class="fa fa-check"></i><b>3.1</b> Tensors</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#creation"><i class="fa fa-check"></i><b>3.1.1</b> Creation</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#conversion-to-built-in-r-data-types"><i class="fa fa-check"></i><b>3.1.2</b> Conversion to built-in R data types</a></li>
<li class="chapter" data-level="3.1.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#indexing-and-slicing-tensors"><i class="fa fa-check"></i><b>3.1.3</b> Indexing and slicing tensors</a></li>
<li class="chapter" data-level="3.1.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#reshaping-tensors"><i class="fa fa-check"></i><b>3.1.4</b> Reshaping tensors</a></li>
<li class="chapter" data-level="3.1.5" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#operations-on-tensors"><i class="fa fa-check"></i><b>3.1.5</b> Operations on tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#running-on-gpu"><i class="fa fa-check"></i><b>3.2</b> Running on GPU</a></li>
<li class="chapter" data-level="3.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#broadcasting"><i class="fa fa-check"></i><b>3.3</b> Broadcasting</a></li>
<li class="chapter" data-level="3.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#simple-neural-network-using-torch-tensors"><i class="fa fa-check"></i><b>3.4</b> Simple neural network using <code>torch</code> tensors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html"><i class="fa fa-check"></i><b>4</b> Using autograd</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#automatic-differentiation-with-autograd"><i class="fa fa-check"></i><b>4.1</b> Automatic differentiation with <em>autograd</em></a></li>
<li class="chapter" data-level="4.2" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#the-simple-network-now-using-autograd"><i class="fa fa-check"></i><b>4.2</b> The simple network, now using <em>autograd</em></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-net-modules.html"><a href="simple-net-modules.html"><i class="fa fa-check"></i><b>5</b> Using torch modules</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#modules"><i class="fa fa-check"></i><b>5.1</b> Modules</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#base-modules-layers"><i class="fa fa-check"></i><b>5.1.1</b> Base modules (“layers”)</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#container-modules-models"><i class="fa fa-check"></i><b>5.1.2</b> Container modules (“models”)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#simple-network-using-modules"><i class="fa fa-check"></i><b>5.2</b> Simple network using modules</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-net-optim.html"><a href="simple-net-optim.html"><i class="fa fa-check"></i><b>6</b> Using <code>torch</code> optimizers</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple-net-optim.html"><a href="simple-net-optim.html#losses-and-loss-functions"><i class="fa fa-check"></i><b>6.1</b> Losses and loss functions</a></li>
<li class="chapter" data-level="6.2" data-path="simple-net-optim.html"><a href="simple-net-optim.html#optimizers"><i class="fa fa-check"></i><b>6.2</b> Optimizers</a></li>
<li class="chapter" data-level="6.3" data-path="simple-net-optim.html"><a href="simple-net-optim.html#simple-network-final-version"><i class="fa fa-check"></i><b>6.3</b> Simple network: final version</a></li>
</ul></li>
<li class="part"><span><b>II Image Recognition</b></span></li>
<li class="chapter" data-level="" data-path="image-recognition-intro.html"><a href="image-recognition-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="7" data-path="image-classification.html"><a href="image-classification.html"><i class="fa fa-check"></i><b>7</b> Classifying images</a>
<ul>
<li class="chapter" data-level="7.1" data-path="image-classification.html"><a href="image-classification.html#data-loading-and-preprocessing"><i class="fa fa-check"></i><b>7.1</b> Data loading and preprocessing</a></li>
<li class="chapter" data-level="7.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>7.2</b> Model</a></li>
<li class="chapter" data-level="7.3" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>7.3</b> Training</a></li>
<li class="chapter" data-level="7.4" data-path="image-classification.html"><a href="image-classification.html#test-set-accuracy"><i class="fa fa-check"></i><b>7.4</b> Test set accuracy</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unet.html"><a href="unet.html"><i class="fa fa-check"></i><b>8</b> Brain Image Segmentation with U-Net</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unet.html"><a href="unet.html#image-segmentation-in-a-nutshell"><i class="fa fa-check"></i><b>8.1</b> Image segmentation in a nutshell</a></li>
<li class="chapter" data-level="8.2" data-path="unet.html"><a href="unet.html#u-net"><i class="fa fa-check"></i><b>8.2</b> U-Net</a></li>
<li class="chapter" data-level="8.3" data-path="unet.html"><a href="unet.html#example-application-mri-images"><i class="fa fa-check"></i><b>8.3</b> Example application: MRI images</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="unet.html"><a href="unet.html#preprocessing"><i class="fa fa-check"></i><b>8.3.1</b> Preprocessing</a></li>
<li class="chapter" data-level="8.3.2" data-path="unet.html"><a href="unet.html#u-net-model"><i class="fa fa-check"></i><b>8.3.2</b> U-Net model</a></li>
<li class="chapter" data-level="8.3.3" data-path="unet.html"><a href="unet.html#loss"><i class="fa fa-check"></i><b>8.3.3</b> Loss</a></li>
<li class="chapter" data-level="8.3.4" data-path="unet.html"><a href="unet.html#training-1"><i class="fa fa-check"></i><b>8.3.4</b> Training</a></li>
<li class="chapter" data-level="8.3.5" data-path="unet.html"><a href="unet.html#predictions"><i class="fa fa-check"></i><b>8.3.5</b> Predictions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Natural language processing</b></span></li>
<li class="chapter" data-level="" data-path="NLP-intro.html"><a href="NLP-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="9" data-path="seq2seq-att.html"><a href="seq2seq-att.html"><i class="fa fa-check"></i><b>9</b> Sequence-to-sequence models with attention</a>
<ul>
<li class="chapter" data-level="9.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#why-attention"><i class="fa fa-check"></i><b>9.1</b> Why attention?</a></li>
<li class="chapter" data-level="9.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#preprocessing-with-torchtext"><i class="fa fa-check"></i><b>9.2</b> Preprocessing with <code>torchtext</code></a></li>
<li class="chapter" data-level="9.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#model-1"><i class="fa fa-check"></i><b>9.3</b> Model</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>9.3.1</b> Encoder</a></li>
<li class="chapter" data-level="9.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#attention-module"><i class="fa fa-check"></i><b>9.3.2</b> Attention module</a></li>
<li class="chapter" data-level="9.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>9.3.3</b> Decoder</a></li>
<li class="chapter" data-level="9.3.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#seq2seq-module"><i class="fa fa-check"></i><b>9.3.4</b> Seq2seq module</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#training-and-evaluation"><i class="fa fa-check"></i><b>9.4</b> Training and evaluation</a></li>
<li class="chapter" data-level="9.5" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>9.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="transformer.html"><a href="transformer.html"><i class="fa fa-check"></i><b>10</b> Torch transformer modules</a>
<ul>
<li class="chapter" data-level="10.1" data-path="transformer.html"><a href="transformer.html#attention-is-all-you-need"><i class="fa fa-check"></i><b>10.1</b> “Attention is all you need”</a></li>
<li class="chapter" data-level="10.2" data-path="transformer.html"><a href="transformer.html#implementation-building-blocks"><i class="fa fa-check"></i><b>10.2</b> Implementation: building blocks</a></li>
<li class="chapter" data-level="10.3" data-path="transformer.html"><a href="transformer.html#a-transformer-for-natural-language-translation"><i class="fa fa-check"></i><b>10.3</b> A Transformer for natural language translation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="transformer.html"><a href="transformer.html#load-data"><i class="fa fa-check"></i><b>10.3.1</b> Load data</a></li>
<li class="chapter" data-level="10.3.2" data-path="transformer.html"><a href="transformer.html#encoder-1"><i class="fa fa-check"></i><b>10.3.2</b> Encoder</a></li>
<li class="chapter" data-level="10.3.3" data-path="transformer.html"><a href="transformer.html#decoder-1"><i class="fa fa-check"></i><b>10.3.3</b> Decoder</a></li>
<li class="chapter" data-level="10.3.4" data-path="transformer.html"><a href="transformer.html#overall-model"><i class="fa fa-check"></i><b>10.3.4</b> Overall model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="transformer.html"><a href="transformer.html#results-1"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="tabular.html"><a href="tabular.html"><i class="fa fa-check"></i><b>11</b> torch for tabular data</a>
<ul>
<li class="chapter" data-level="11.1" data-path="tabular.html"><a href="tabular.html#agenda"><i class="fa fa-check"></i><b>11.1</b> Agenda</a></li>
<li class="chapter" data-level="11.2" data-path="tabular.html"><a href="tabular.html#dataset"><i class="fa fa-check"></i><b>11.2</b> Dataset</a></li>
<li class="chapter" data-level="11.3" data-path="tabular.html"><a href="tabular.html#model-2"><i class="fa fa-check"></i><b>11.3</b> Model</a></li>
<li class="chapter" data-level="11.4" data-path="tabular.html"><a href="tabular.html#training-2"><i class="fa fa-check"></i><b>11.4</b> Training</a></li>
<li class="chapter" data-level="11.5" data-path="tabular.html"><a href="tabular.html#evaluation"><i class="fa fa-check"></i><b>11.5</b> Evaluation</a></li>
<li class="chapter" data-level="11.6" data-path="tabular.html"><a href="tabular.html#making-the-task-harder"><i class="fa fa-check"></i><b>11.6</b> Making the task harder</a></li>
<li class="chapter" data-level="11.7" data-path="tabular.html"><a href="tabular.html#a-look-at-the-hidden-representations"><i class="fa fa-check"></i><b>11.7</b> A look at the hidden representations</a></li>
</ul></li>
<li class="part"><span><b>IV Time series</b></span></li>
<li class="chapter" data-level="" data-path="timeseries-intro.html"><a href="timeseries-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V Generative deep learning</b></span></li>
<li class="chapter" data-level="" data-path="generative-intro.html"><a href="generative-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="12" data-path="gans.html"><a href="gans.html"><i class="fa fa-check"></i><b>12</b> Generative adversarial networks</a>
<ul>
<li class="chapter" data-level="12.1" data-path="gans.html"><a href="gans.html#dataset-1"><i class="fa fa-check"></i><b>12.1</b> Dataset</a></li>
<li class="chapter" data-level="12.2" data-path="gans.html"><a href="gans.html#model-3"><i class="fa fa-check"></i><b>12.2</b> Model</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="gans.html"><a href="gans.html#generator"><i class="fa fa-check"></i><b>12.2.1</b> Generator</a></li>
<li class="chapter" data-level="12.2.2" data-path="gans.html"><a href="gans.html#discriminator"><i class="fa fa-check"></i><b>12.2.2</b> Discriminator</a></li>
<li class="chapter" data-level="12.2.3" data-path="gans.html"><a href="gans.html#optimizers-and-loss-function"><i class="fa fa-check"></i><b>12.2.3</b> Optimizers and loss function</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="gans.html"><a href="gans.html#training-loop-3"><i class="fa fa-check"></i><b>12.3</b> Training loop</a></li>
<li class="chapter" data-level="12.4" data-path="gans.html"><a href="gans.html#artifacts"><i class="fa fa-check"></i><b>12.4</b> Artifacts</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="vaes.html"><a href="vaes.html"><i class="fa fa-check"></i><b>13</b> Variational autoencoders</a>
<ul>
<li class="chapter" data-level="13.1" data-path="vaes.html"><a href="vaes.html#dataset-2"><i class="fa fa-check"></i><b>13.1</b> Dataset</a></li>
<li class="chapter" data-level="13.2" data-path="vaes.html"><a href="vaes.html#model-4"><i class="fa fa-check"></i><b>13.2</b> Model</a></li>
<li class="chapter" data-level="13.3" data-path="vaes.html"><a href="vaes.html#training-the-vae"><i class="fa fa-check"></i><b>13.3</b> Training the VAE</a></li>
<li class="chapter" data-level="13.4" data-path="vaes.html"><a href="vaes.html#latent-space"><i class="fa fa-check"></i><b>13.4</b> Latent space</a></li>
</ul></li>
<li class="part"><span><b>VI Deep learning on graphs</b></span></li>
<li class="chapter" data-level="" data-path="graph-intro.html"><a href="graph-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VII Probabilistic deep learning</b></span></li>
<li class="chapter" data-level="" data-path="probabilistic-intro.html"><a href="probabilistic-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VIII Private and secure deep learning</b></span></li>
<li class="chapter" data-level="" data-path="private-secure-intro.html"><a href="private-secure-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>IX Research topics</b></span></li>
<li class="chapter" data-level="" data-path="research-intro.html"><a href="research-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied deep learning with torch from R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="image_classification" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Classifying images</h1>
<p>So far, we’ve been exploring essential <code>torch</code> functionality: tensors, the sine qua non of every deep learning framework; autograd, <code>torch</code>’s implementation of reverse-mode automatic differentiation; modules, composable building blocks of neural networks; and optimizers, the – well – optimization algorithms that <code>torch</code> provides.</p>
<p>But we haven’t really had our “hello world” moment yet, at least not if by “hello world” you mean the inevitable <em>deep learning experience of classifying pets</em>. Cat or dog? Beagle or boxer? Chinook or Chihuahua? We’ll distinguish ourselves by asking a (slightly) different question: What kind of bird?</p>
<p>Topics we’ll address on our way:</p>
<ul>
<li><p>The core roles of <code>torch</code> <em>datasets</em> and <em>data loaders</em>, respectively.</p></li>
<li><p>How to apply <code>transform</code>s, both for image preprocessing and data augmentation.</p></li>
<li><p>How to use Resnet <span class="citation">(<a href="references.html#ref-HeZRS15" role="doc-biblioref">He et al. 2015</a>)</span>, a pre-trained model that comes with <code>torchvision</code>, for transfer learning.</p></li>
<li><p>How to use learning rate schedulers, and in particular, the one-cycle learning rate algorithm [@abs-1708-07120].</p></li>
<li><p>How to find a good initial learning rate.</p></li>
</ul>
<div id="data-loading-and-preprocessing" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Data loading and preprocessing</h2>
<p>The example dataset used here is available on <a href="https://www.kaggle.com/gpiosenka/100-bird-species/data" class="uri">Kaggle</a>.</p>
<p>Conveniently, it may be obtained using <a href="https://github.com/mlverse/torchdatasets"><code>torchdatasets</code></a>, which uses <a href="https://github.com/rstudio/pins"><code>pins</code></a> for authentication, retrieval and storage. To enable <code>pins</code> to manage your Kaggle downloads, please follow the instructions <a href="https://pins.rstudio.com/articles/boards-kaggle.html">here</a>.</p>
<p>This dataset is very “clean,” unlike the images we may be used to from, e.g., <a href="http://image-net.org/">ImageNet</a>. To help with generalization, we introduce noise during training – in other words, we perform <em>data augmentation</em>. In <code>torchvision</code>, data augmentation is part of an <em>image processing pipeline</em> that first converts an image to a tensor, and then applies any transformations such as resizing, cropping, normalization, or various forms of distorsion.</p>
<p>Below are the transformations performed on the training set. Note how most of them are for data augmentation, while normalization is done to comply with what’s expected by ResNet.</p>
<div id="image-preprocessing-pipeline" class="section level4" number="7.1.0.1">
<h4><span class="header-section-number">7.1.0.1</span> Image preprocessing pipeline</h4>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="image-classification.html#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb170-2"><a href="image-classification.html#cb170-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torchvision)</span>
<span id="cb170-3"><a href="image-classification.html#cb170-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torchdatasets)</span>
<span id="cb170-4"><a href="image-classification.html#cb170-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb170-5"><a href="image-classification.html#cb170-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb170-6"><a href="image-classification.html#cb170-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pins)</span>
<span id="cb170-7"><a href="image-classification.html#cb170-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb170-8"><a href="image-classification.html#cb170-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb170-9"><a href="image-classification.html#cb170-9" aria-hidden="true" tabindex="-1"></a>device <span class="ot">&lt;-</span> <span class="cf">if</span> (<span class="fu">cuda_is_available</span>()) <span class="fu">torch_device</span>(<span class="st">&quot;cuda:0&quot;</span>) <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb170-10"><a href="image-classification.html#cb170-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb170-11"><a href="image-classification.html#cb170-11" aria-hidden="true" tabindex="-1"></a>train_transforms <span class="ot">&lt;-</span> <span class="cf">function</span>(img) {</span>
<span id="cb170-12"><a href="image-classification.html#cb170-12" aria-hidden="true" tabindex="-1"></a>  img <span class="sc">%&gt;%</span></span>
<span id="cb170-13"><a href="image-classification.html#cb170-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># first convert image to tensor</span></span>
<span id="cb170-14"><a href="image-classification.html#cb170-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_to_tensor</span>() <span class="sc">%&gt;%</span></span>
<span id="cb170-15"><a href="image-classification.html#cb170-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># then move to the GPU (if available)</span></span>
<span id="cb170-16"><a href="image-classification.html#cb170-16" aria-hidden="true" tabindex="-1"></a>    (<span class="cf">function</span>(x) x<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device)) <span class="sc">%&gt;%</span></span>
<span id="cb170-17"><a href="image-classification.html#cb170-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># data augmentation</span></span>
<span id="cb170-18"><a href="image-classification.html#cb170-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_random_resized_crop</span>(<span class="at">size =</span> <span class="fu">c</span>(<span class="dv">224</span>, <span class="dv">224</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb170-19"><a href="image-classification.html#cb170-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># data augmentation</span></span>
<span id="cb170-20"><a href="image-classification.html#cb170-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_color_jitter</span>() <span class="sc">%&gt;%</span></span>
<span id="cb170-21"><a href="image-classification.html#cb170-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># data augmentation</span></span>
<span id="cb170-22"><a href="image-classification.html#cb170-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_random_horizontal_flip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb170-23"><a href="image-classification.html#cb170-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize according to what is expected by resnet</span></span>
<span id="cb170-24"><a href="image-classification.html#cb170-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_normalize</span>(<span class="at">mean =</span> <span class="fu">c</span>(<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>), <span class="at">std =</span> <span class="fu">c</span>(<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>))</span>
<span id="cb170-25"><a href="image-classification.html#cb170-25" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>On the validation set, we don’t want to introduce noise, but still need to resize, crop, and normalize the images. The test set should be treated identically.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="image-classification.html#cb171-1" aria-hidden="true" tabindex="-1"></a>valid_transforms <span class="ot">&lt;-</span> <span class="cf">function</span>(img) {</span>
<span id="cb171-2"><a href="image-classification.html#cb171-2" aria-hidden="true" tabindex="-1"></a>  img <span class="sc">%&gt;%</span></span>
<span id="cb171-3"><a href="image-classification.html#cb171-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_to_tensor</span>() <span class="sc">%&gt;%</span></span>
<span id="cb171-4"><a href="image-classification.html#cb171-4" aria-hidden="true" tabindex="-1"></a>    (<span class="cf">function</span>(x) x<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device)) <span class="sc">%&gt;%</span></span>
<span id="cb171-5"><a href="image-classification.html#cb171-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_resize</span>(<span class="dv">256</span>) <span class="sc">%&gt;%</span></span>
<span id="cb171-6"><a href="image-classification.html#cb171-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_center_crop</span>(<span class="dv">224</span>) <span class="sc">%&gt;%</span></span>
<span id="cb171-7"><a href="image-classification.html#cb171-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_normalize</span>(<span class="at">mean =</span> <span class="fu">c</span>(<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>), <span class="at">std =</span> <span class="fu">c</span>(<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>))</span>
<span id="cb171-8"><a href="image-classification.html#cb171-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb171-9"><a href="image-classification.html#cb171-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-10"><a href="image-classification.html#cb171-10" aria-hidden="true" tabindex="-1"></a>test_transforms <span class="ot">&lt;-</span> valid_transforms</span></code></pre></div>
<p>And now, let’s get the data, nicely divided into training, validation and test sets. Additionally, we tell the corresponding R objects what transformations they’re expected to apply:<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="image-classification.html#cb172-1" aria-hidden="true" tabindex="-1"></a>train_ds <span class="ot">&lt;-</span> <span class="fu">bird_species_dataset</span>(<span class="st">&quot;data&quot;</span>, <span class="at">download =</span> <span class="cn">TRUE</span>, <span class="at">transform =</span> train_transforms)</span>
<span id="cb172-2"><a href="image-classification.html#cb172-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-3"><a href="image-classification.html#cb172-3" aria-hidden="true" tabindex="-1"></a>valid_ds <span class="ot">&lt;-</span> <span class="fu">bird_species_dataset</span>(<span class="st">&quot;data&quot;</span>, <span class="at">split =</span> <span class="st">&quot;valid&quot;</span>, <span class="at">transform =</span> valid_transforms)</span>
<span id="cb172-4"><a href="image-classification.html#cb172-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-5"><a href="image-classification.html#cb172-5" aria-hidden="true" tabindex="-1"></a>test_ds <span class="ot">&lt;-</span> <span class="fu">bird_species_dataset</span>(<span class="st">&quot;data&quot;</span>, <span class="at">split =</span> <span class="st">&quot;test&quot;</span>, <span class="at">transform =</span> test_transforms)</span></code></pre></div>
<p>Two things to note. First, transformations are part of the <em>dataset</em> concept, as opposed to the <em>data loader</em> we’ll encounter shortly. Second, let’s take a look at how the images have been stored on disk. The overall directory structure (starting from <code>data</code>, which we specified as the root directory to be used) is this:</p>
<pre><code>data/bird_species/train
data/bird_species/valid
data/bird_species/test</code></pre>
<p>In the <code>train</code>, <code>valid</code>, and <code>test</code> directories, different classes of images reside in their own folders. For example, here is the directory layout for the first three classes in the test set:</p>
<pre><code>data/bird_species/test/ALBATROSS/
 - data/bird_species/test/ALBATROSS/1.jpg
 - data/bird_species/test/ALBATROSS/2.jpg
 - data/bird_species/test/ALBATROSS/3.jpg
 - data/bird_species/test/ALBATROSS/4.jpg
 - data/bird_species/test/ALBATROSS/5.jpg
 
data/test/&#39;ALEXANDRINE PARAKEET&#39;/
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/1.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/2.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/3.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/4.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/5.jpg
 
 data/test/&#39;AMERICAN BITTERN&#39;/
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/1.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/2.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/3.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/4.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/5.jpg</code></pre>
<p>This is exactly the kind of layout expected by <code>torch</code>s <code>image_folder_dataset()</code> – and really <code>bird_species_dataset()</code> instantiates a subtype of this class. Had we downloaded the data manually, respecting the required directory structure, we could have created the datasets like so:</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="image-classification.html#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="co"># e.g.</span></span>
<span id="cb175-2"><a href="image-classification.html#cb175-2" aria-hidden="true" tabindex="-1"></a>train_ds <span class="ot">&lt;-</span> <span class="fu">image_folder_dataset</span>(</span>
<span id="cb175-3"><a href="image-classification.html#cb175-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">file.path</span>(data_dir, <span class="st">&quot;train&quot;</span>),</span>
<span id="cb175-4"><a href="image-classification.html#cb175-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">transform =</span> train_transforms)</span></code></pre></div>
<p>Now that we got the data, let’s see how many items there are in each set.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="image-classification.html#cb176-1" aria-hidden="true" tabindex="-1"></a>train_ds<span class="sc">$</span><span class="fu">.length</span>()</span>
<span id="cb176-2"><a href="image-classification.html#cb176-2" aria-hidden="true" tabindex="-1"></a>valid_ds<span class="sc">$</span><span class="fu">.length</span>()</span>
<span id="cb176-3"><a href="image-classification.html#cb176-3" aria-hidden="true" tabindex="-1"></a>test_ds<span class="sc">$</span><span class="fu">.length</span>()</span></code></pre></div>
<pre><code>31316
1125
1125</code></pre>
<p>That training set is really big! It’s thus recommended to run this on GPU, or just play around with the provided Colab notebook.</p>
<p>With so many samples, we’re curious how many classes there are.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="image-classification.html#cb178-1" aria-hidden="true" tabindex="-1"></a>class_names <span class="ot">&lt;-</span> test_ds<span class="sc">$</span>classes</span>
<span id="cb178-2"><a href="image-classification.html#cb178-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(class_names)</span></code></pre></div>
<pre><code>225</code></pre>
<p>So we <em>do</em> have a substantial training set, but the task is formidable as well: We’re going to tell apart no less than 225 different bird species.</p>
</div>
<div id="data-loaders" class="section level4" number="7.1.0.2">
<h4><span class="header-section-number">7.1.0.2</span> Data loaders</h4>
<p>While <em>datasets</em> know what to do with each single item, <em>data loaders</em> know how to treat them collectively. How many samples make up a batch? Do we want to feed them in the same order always, or instead, have a different order chosen for every epoch?</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="image-classification.html#cb180-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">&lt;-</span> <span class="dv">64</span></span>
<span id="cb180-2"><a href="image-classification.html#cb180-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-3"><a href="image-classification.html#cb180-3" aria-hidden="true" tabindex="-1"></a>train_dl <span class="ot">&lt;-</span> <span class="fu">dataloader</span>(train_ds, <span class="at">batch_size =</span> batch_size, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb180-4"><a href="image-classification.html#cb180-4" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="ot">&lt;-</span> <span class="fu">dataloader</span>(valid_ds, <span class="at">batch_size =</span> batch_size)</span>
<span id="cb180-5"><a href="image-classification.html#cb180-5" aria-hidden="true" tabindex="-1"></a>test_dl <span class="ot">&lt;-</span> <span class="fu">dataloader</span>(test_ds, <span class="at">batch_size =</span> batch_size)</span></code></pre></div>
<p>Data loaders, too, may be queried for their length. Now length means: How many batches?</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="image-classification.html#cb181-1" aria-hidden="true" tabindex="-1"></a>train_dl<span class="sc">$</span><span class="fu">.length</span>() </span>
<span id="cb181-2"><a href="image-classification.html#cb181-2" aria-hidden="true" tabindex="-1"></a>valid_dl<span class="sc">$</span><span class="fu">.length</span>() </span>
<span id="cb181-3"><a href="image-classification.html#cb181-3" aria-hidden="true" tabindex="-1"></a>test_dl<span class="sc">$</span><span class="fu">.length</span>()  </span></code></pre></div>
<pre><code>490
18
18</code></pre>
</div>
<div id="some-birds" class="section level4" number="7.1.0.3">
<h4><span class="header-section-number">7.1.0.3</span> Some birds</h4>
<p>Next, let’s view a few images from the test set. We can retrieve the first batch – images and corresponding classes – by creating an iterator from the <code>dataloader</code> and calling <code>next()</code> on it:</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="image-classification.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for display purposes, here we are actually using a batch_size of 24</span></span>
<span id="cb183-2"><a href="image-classification.html#cb183-2" aria-hidden="true" tabindex="-1"></a>batch <span class="ot">&lt;-</span> train_dl<span class="sc">$</span><span class="fu">.iter</span>()<span class="sc">$</span><span class="fu">.next</span>()</span></code></pre></div>
<p><code>batch</code> is a list, the first item being the image tensors:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="image-classification.html#cb184-1" aria-hidden="true" tabindex="-1"></a>batch[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">size</span>()</span></code></pre></div>
<pre><code>[1]  24   3 224 224</code></pre>
<p>And the second, the classes:</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="image-classification.html#cb186-1" aria-hidden="true" tabindex="-1"></a>batch[[<span class="dv">2</span>]]<span class="sc">$</span><span class="fu">size</span>()</span></code></pre></div>
<pre><code>[1] 24</code></pre>
<p>Classes are coded as integers, to be used as indices in a vector of class names. We’ll use those for labeling the images.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="image-classification.html#cb188-1" aria-hidden="true" tabindex="-1"></a>classes <span class="ot">&lt;-</span> batch[[<span class="dv">2</span>]]</span>
<span id="cb188-2"><a href="image-classification.html#cb188-2" aria-hidden="true" tabindex="-1"></a>classes</span></code></pre></div>
<pre><code>torch_tensor 
 1
 1
 1
 1
 1
 2
 2
 2
 2
 2
 3
 3
 3
 3
 3
 4
 4
 4
 4
 4
 5
 5
 5
 5
[ GPULongType{24} ]</code></pre>
<p>The image tensors have shape <code>batch_size x num_channels x height x width</code>. For plotting using <code>as.raster()</code>, we need to reshape the images such that channels come last. We also undo the normalization applied by the <code>dataloader</code>.</p>
<p>Here are the first twenty-four images:</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="image-classification.html#cb190-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb190-2"><a href="image-classification.html#cb190-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-3"><a href="image-classification.html#cb190-3" aria-hidden="true" tabindex="-1"></a>images <span class="ot">&lt;-</span> <span class="fu">as_array</span>(batch[[<span class="dv">1</span>]]) <span class="sc">%&gt;%</span> <span class="fu">aperm</span>(<span class="at">perm =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>))</span>
<span id="cb190-4"><a href="image-classification.html#cb190-4" aria-hidden="true" tabindex="-1"></a>mean <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>)</span>
<span id="cb190-5"><a href="image-classification.html#cb190-5" aria-hidden="true" tabindex="-1"></a>std <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>)</span>
<span id="cb190-6"><a href="image-classification.html#cb190-6" aria-hidden="true" tabindex="-1"></a>images <span class="ot">&lt;-</span> std <span class="sc">*</span> images <span class="sc">+</span> mean</span>
<span id="cb190-7"><a href="image-classification.html#cb190-7" aria-hidden="true" tabindex="-1"></a>images <span class="ot">&lt;-</span> images <span class="sc">*</span> <span class="dv">255</span></span>
<span id="cb190-8"><a href="image-classification.html#cb190-8" aria-hidden="true" tabindex="-1"></a>images[images <span class="sc">&gt;</span> <span class="dv">255</span>] <span class="ot">&lt;-</span> <span class="dv">255</span></span>
<span id="cb190-9"><a href="image-classification.html#cb190-9" aria-hidden="true" tabindex="-1"></a>images[images <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb190-10"><a href="image-classification.html#cb190-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-11"><a href="image-classification.html#cb190-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">6</span>), <span class="at">mar =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">4</span>))</span>
<span id="cb190-12"><a href="image-classification.html#cb190-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-13"><a href="image-classification.html#cb190-13" aria-hidden="true" tabindex="-1"></a>images <span class="sc">%&gt;%</span></span>
<span id="cb190-14"><a href="image-classification.html#cb190-14" aria-hidden="true" tabindex="-1"></a>  purrr<span class="sc">::</span><span class="fu">array_tree</span>(<span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb190-15"><a href="image-classification.html#cb190-15" aria-hidden="true" tabindex="-1"></a>  purrr<span class="sc">::</span><span class="fu">set_names</span>(class_names[<span class="fu">as_array</span>(classes)]) <span class="sc">%&gt;%</span></span>
<span id="cb190-16"><a href="image-classification.html#cb190-16" aria-hidden="true" tabindex="-1"></a>  purrr<span class="sc">::</span><span class="fu">map</span>(as.raster, <span class="at">max =</span> <span class="dv">255</span>) <span class="sc">%&gt;%</span></span>
<span id="cb190-17"><a href="image-classification.html#cb190-17" aria-hidden="true" tabindex="-1"></a>  purrr<span class="sc">::</span><span class="fu">iwalk</span>(<span class="sc">~</span>{<span class="fu">plot</span>(.x); <span class="fu">title</span>(.y)})</span></code></pre></div>
<p><img src="images/image_classif_birds.png" /></p>
</div>
</div>
<div id="model" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Model</h2>
<p>The backbone of our model is a pre-trained instance of ResNet.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="image-classification.html#cb191-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">model_resnet18</span>(<span class="at">pretrained =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>But we want to distinguish among our 225 bird species, while ResNet was trained on 1000 different classes. What can we do? We simply replace the output layer.</p>
<p>The new output layer is also the only one whose weights we are going to train – leaving all other ResNet parameters the way they are. Technically, we <em>could</em> perform backpropagation through the complete model, striving to fine-tune ResNet’s weights as well. However, this would slow down training significantly. In fact, the choice is not all-or-none: It is up to us how many of the original parameters to keep fixed, and how many to “set free” for fine tuning. For the task at hand, we’ll be content to just train the newly added output layer: With the abundance of animals, including birds, in ImageNet, we expect the trained ResNet to know a lot about them!</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="image-classification.html#cb192-1" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>parameters <span class="sc">%&gt;%</span> purrr<span class="sc">::</span><span class="fu">walk</span>(<span class="cf">function</span>(param) param<span class="sc">$</span><span class="fu">requires_grad_</span>(<span class="cn">FALSE</span>))</span></code></pre></div>
<p>To replace the output layer, the model is modified in-place:</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="image-classification.html#cb193-1" aria-hidden="true" tabindex="-1"></a>num_features <span class="ot">&lt;-</span> model<span class="sc">$</span>fc<span class="sc">$</span>in_features</span>
<span id="cb193-2"><a href="image-classification.html#cb193-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb193-3"><a href="image-classification.html#cb193-3" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>fc <span class="ot">&lt;-</span> <span class="fu">nn_linear</span>(<span class="at">in_features =</span> num_features, <span class="at">out_features =</span> <span class="fu">length</span>(class_names))</span></code></pre></div>
<p>Now put the modified model on the GPU (if available):</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="image-classification.html#cb194-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> model<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device)</span></code></pre></div>
</div>
<div id="training" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Training</h2>
<p>For optimization, we use cross entropy loss and stochastic gradient descent.</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="image-classification.html#cb195-1" aria-hidden="true" tabindex="-1"></a>criterion <span class="ot">&lt;-</span> <span class="fu">nn_cross_entropy_loss</span>()</span>
<span id="cb195-2"><a href="image-classification.html#cb195-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-3"><a href="image-classification.html#cb195-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">&lt;-</span> <span class="fu">optim_sgd</span>(model<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.1</span>, <span class="at">momentum =</span> <span class="fl">0.9</span>)</span></code></pre></div>
<div id="finding-an-optimally-efficient-learning-rate" class="section level4" number="7.3.0.1">
<h4><span class="header-section-number">7.3.0.1</span> Finding an optimally efficient learning rate</h4>
<p>We set the learning rate to <code>0.1</code>, but that is just a formality. As has become widely known due to the excellent lectures by <a href="http://fast.ai">fast.ai</a>, it makes sense to spend some time upfront to determine an efficient learning rate. While out-of-the-box, <code>torch</code> does not provide a tool like fast.ai’s learning rate finder, the logic is straightforward to implement. Here’s how to find a good learning rate, as translated to R from <a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html">Sylvain Gugger’s post</a>:</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="image-classification.html#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ported from: https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html</span></span>
<span id="cb196-2"><a href="image-classification.html#cb196-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-3"><a href="image-classification.html#cb196-3" aria-hidden="true" tabindex="-1"></a>losses <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb196-4"><a href="image-classification.html#cb196-4" aria-hidden="true" tabindex="-1"></a>log_lrs <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb196-5"><a href="image-classification.html#cb196-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-6"><a href="image-classification.html#cb196-6" aria-hidden="true" tabindex="-1"></a>find_lr <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">init_value =</span> <span class="fl">1e-8</span>, <span class="at">final_value =</span> <span class="dv">10</span>, <span class="at">beta =</span> <span class="fl">0.98</span>) {</span>
<span id="cb196-7"><a href="image-classification.html#cb196-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-8"><a href="image-classification.html#cb196-8" aria-hidden="true" tabindex="-1"></a>  num <span class="ot">&lt;-</span> train_dl<span class="sc">$</span><span class="fu">.length</span>()</span>
<span id="cb196-9"><a href="image-classification.html#cb196-9" aria-hidden="true" tabindex="-1"></a>  mult <span class="ot">=</span> (final_value<span class="sc">/</span>init_value)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span>num)</span>
<span id="cb196-10"><a href="image-classification.html#cb196-10" aria-hidden="true" tabindex="-1"></a>  lr <span class="ot">&lt;-</span> init_value</span>
<span id="cb196-11"><a href="image-classification.html#cb196-11" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span>param_groups[[<span class="dv">1</span>]]<span class="sc">$</span>lr <span class="ot">&lt;-</span> lr</span>
<span id="cb196-12"><a href="image-classification.html#cb196-12" aria-hidden="true" tabindex="-1"></a>  avg_loss <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb196-13"><a href="image-classification.html#cb196-13" aria-hidden="true" tabindex="-1"></a>  best_loss <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb196-14"><a href="image-classification.html#cb196-14" aria-hidden="true" tabindex="-1"></a>  batch_num <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb196-15"><a href="image-classification.html#cb196-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-16"><a href="image-classification.html#cb196-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="fu">enumerate</span>(train_dl)) {</span>
<span id="cb196-17"><a href="image-classification.html#cb196-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-18"><a href="image-classification.html#cb196-18" aria-hidden="true" tabindex="-1"></a>    batch_num <span class="ot">&lt;-</span> batch_num <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb196-19"><a href="image-classification.html#cb196-19" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb196-20"><a href="image-classification.html#cb196-20" aria-hidden="true" tabindex="-1"></a>    output <span class="ot">&lt;-</span> <span class="fu">model</span>(b[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device))</span>
<span id="cb196-21"><a href="image-classification.html#cb196-21" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">&lt;-</span> <span class="fu">criterion</span>(output, b[[<span class="dv">2</span>]]<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device))</span>
<span id="cb196-22"><a href="image-classification.html#cb196-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-23"><a href="image-classification.html#cb196-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Compute the smoothed loss</span></span>
<span id="cb196-24"><a href="image-classification.html#cb196-24" aria-hidden="true" tabindex="-1"></a>    avg_loss <span class="ot">&lt;-</span> beta <span class="sc">*</span> avg_loss <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>beta) <span class="sc">*</span> loss<span class="sc">$</span><span class="fu">item</span>()</span>
<span id="cb196-25"><a href="image-classification.html#cb196-25" aria-hidden="true" tabindex="-1"></a>    smoothed_loss <span class="ot">&lt;-</span> avg_loss <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> beta<span class="sc">^</span>batch_num)</span>
<span id="cb196-26"><a href="image-classification.html#cb196-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Stop if the loss is exploding</span></span>
<span id="cb196-27"><a href="image-classification.html#cb196-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (batch_num <span class="sc">&gt;</span> <span class="dv">1</span> <span class="sc">&amp;&amp;</span> smoothed_loss <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">*</span> best_loss) <span class="cf">break</span></span>
<span id="cb196-28"><a href="image-classification.html#cb196-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Record the best loss</span></span>
<span id="cb196-29"><a href="image-classification.html#cb196-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (smoothed_loss <span class="sc">&lt;</span> best_loss <span class="sc">||</span> batch_num <span class="sc">==</span> <span class="dv">1</span>) best_loss <span class="ot">&lt;-</span> smoothed_loss</span>
<span id="cb196-30"><a href="image-classification.html#cb196-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-31"><a href="image-classification.html#cb196-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Store the values</span></span>
<span id="cb196-32"><a href="image-classification.html#cb196-32" aria-hidden="true" tabindex="-1"></a>    losses <span class="ot">&lt;&lt;-</span> <span class="fu">c</span>(losses, smoothed_loss)</span>
<span id="cb196-33"><a href="image-classification.html#cb196-33" aria-hidden="true" tabindex="-1"></a>    log_lrs <span class="ot">&lt;&lt;-</span> <span class="fu">c</span>(log_lrs, (<span class="fu">log</span>(lr, <span class="dv">10</span>)))</span>
<span id="cb196-34"><a href="image-classification.html#cb196-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-35"><a href="image-classification.html#cb196-35" aria-hidden="true" tabindex="-1"></a>    loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb196-36"><a href="image-classification.html#cb196-36" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb196-37"><a href="image-classification.html#cb196-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-38"><a href="image-classification.html#cb196-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Update the lr for the next step</span></span>
<span id="cb196-39"><a href="image-classification.html#cb196-39" aria-hidden="true" tabindex="-1"></a>    lr <span class="ot">&lt;-</span> lr <span class="sc">*</span> mult</span>
<span id="cb196-40"><a href="image-classification.html#cb196-40" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="sc">$</span>param_groups[[<span class="dv">1</span>]]<span class="sc">$</span>lr <span class="ot">&lt;-</span> lr</span>
<span id="cb196-41"><a href="image-classification.html#cb196-41" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb196-42"><a href="image-classification.html#cb196-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb196-43"><a href="image-classification.html#cb196-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-44"><a href="image-classification.html#cb196-44" aria-hidden="true" tabindex="-1"></a><span class="fu">find_lr</span>()</span>
<span id="cb196-45"><a href="image-classification.html#cb196-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-46"><a href="image-classification.html#cb196-46" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">log_lrs =</span> log_lrs, <span class="at">losses =</span> losses)</span>
<span id="cb196-47"><a href="image-classification.html#cb196-47" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(log_lrs, losses)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="images/lr_finder.png" /></p>
<p>The best learning rate is not the exact one where loss is at a minimum. Instead, it should be picked somewhat earlier on the curve, while loss is still decreasing. <code>0.05</code> looks like a sensible choice.</p>
<p>This value is nothing but an anchor, however. <em>Learning rate schedulers</em> allow learning rates to evolve according to some proven algorithm. Among others, <code>torch</code> implements one-cycle learning [@abs-1708-07120], cyclical learning rates <span class="citation">(<a href="references.html#ref-Smith15a" role="doc-biblioref">Smith 2015</a>)</span>, and cosine annealing with warm restarts <span class="citation">(<a href="references.html#ref-LoshchilovH16a" role="doc-biblioref">Loshchilov and Hutter 2016</a>)</span>.</p>
<p>Here, we use <code>lr_one_cycle()</code>, passing in our newly found, optimally efficient, hopefully, value <code>0.05</code> as a maximum learning rate. <code>lr_one_cycle()</code> will start with a low rate, then gradually ramp up until it reaches the allowed maximum. After that, the learning rate will slowly, continuously decrease, until it falls slightly below its initial value.</p>
<p>All this happens not per epoch, but exactly once, which is why the name has <code>one_cycle</code> in it. Here’s how the evolution of learning rates looks in our example:</p>
<p><img src="images/one_cycle.png" /></p>
<p>Before we start training, let’s quickly re-initialize the model, so as to start from a clean slate:</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="image-classification.html#cb197-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">model_resnet18</span>(<span class="at">pretrained =</span> <span class="cn">TRUE</span>)</span>
<span id="cb197-2"><a href="image-classification.html#cb197-2" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>parameters <span class="sc">%&gt;%</span> purrr<span class="sc">::</span><span class="fu">walk</span>(<span class="cf">function</span>(param) param<span class="sc">$</span><span class="fu">requires_grad_</span>(<span class="cn">FALSE</span>))</span>
<span id="cb197-3"><a href="image-classification.html#cb197-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb197-4"><a href="image-classification.html#cb197-4" aria-hidden="true" tabindex="-1"></a>num_features <span class="ot">&lt;-</span> model<span class="sc">$</span>fc<span class="sc">$</span>in_features</span>
<span id="cb197-5"><a href="image-classification.html#cb197-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb197-6"><a href="image-classification.html#cb197-6" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>fc <span class="ot">&lt;-</span> <span class="fu">nn_linear</span>(<span class="at">in_features =</span> num_features, <span class="at">out_features =</span> <span class="fu">length</span>(class_names))</span>
<span id="cb197-7"><a href="image-classification.html#cb197-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb197-8"><a href="image-classification.html#cb197-8" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> model<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device)</span>
<span id="cb197-9"><a href="image-classification.html#cb197-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb197-10"><a href="image-classification.html#cb197-10" aria-hidden="true" tabindex="-1"></a>criterion <span class="ot">&lt;-</span> <span class="fu">nn_cross_entropy_loss</span>()</span>
<span id="cb197-11"><a href="image-classification.html#cb197-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb197-12"><a href="image-classification.html#cb197-12" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">&lt;-</span> <span class="fu">optim_sgd</span>(model<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.05</span>, <span class="at">momentum =</span> <span class="fl">0.9</span>)</span></code></pre></div>
<p>And instantiate the scheduler:</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="image-classification.html#cb198-1" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="ot">=</span> <span class="dv">10</span></span>
<span id="cb198-2"><a href="image-classification.html#cb198-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb198-3"><a href="image-classification.html#cb198-3" aria-hidden="true" tabindex="-1"></a>scheduler <span class="ot">&lt;-</span> optimizer <span class="sc">%&gt;%</span> </span>
<span id="cb198-4"><a href="image-classification.html#cb198-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lr_one_cycle</span>(<span class="at">max_lr =</span> <span class="fl">0.05</span>, <span class="at">epochs =</span> num_epochs, <span class="at">steps_per_epoch =</span> train_dl<span class="sc">$</span><span class="fu">.length</span>())</span></code></pre></div>
</div>
<div id="training-loop-2" class="section level4" number="7.3.0.2">
<h4><span class="header-section-number">7.3.0.2</span> Training loop</h4>
<p>Now we train for ten epochs. For every training batch, we call <code>scheduler$step()</code> to adjust the learning rate. Notably, this has to be done <em>after</em> <code>optimizer$step()</code>.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="image-classification.html#cb199-1" aria-hidden="true" tabindex="-1"></a>train_batch <span class="ot">&lt;-</span> <span class="cf">function</span>(b) {</span>
<span id="cb199-2"><a href="image-classification.html#cb199-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-3"><a href="image-classification.html#cb199-3" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb199-4"><a href="image-classification.html#cb199-4" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">model</span>(b[[<span class="dv">1</span>]])</span>
<span id="cb199-5"><a href="image-classification.html#cb199-5" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">&lt;-</span> <span class="fu">criterion</span>(output, b[[<span class="dv">2</span>]]<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device))</span>
<span id="cb199-6"><a href="image-classification.html#cb199-6" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb199-7"><a href="image-classification.html#cb199-7" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb199-8"><a href="image-classification.html#cb199-8" aria-hidden="true" tabindex="-1"></a>  scheduler<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb199-9"><a href="image-classification.html#cb199-9" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">item</span>()</span>
<span id="cb199-10"><a href="image-classification.html#cb199-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-11"><a href="image-classification.html#cb199-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb199-12"><a href="image-classification.html#cb199-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-13"><a href="image-classification.html#cb199-13" aria-hidden="true" tabindex="-1"></a>valid_batch <span class="ot">&lt;-</span> <span class="cf">function</span>(b) {</span>
<span id="cb199-14"><a href="image-classification.html#cb199-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-15"><a href="image-classification.html#cb199-15" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">model</span>(b[[<span class="dv">1</span>]])</span>
<span id="cb199-16"><a href="image-classification.html#cb199-16" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">&lt;-</span> <span class="fu">criterion</span>(output, b[[<span class="dv">2</span>]]<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device))</span>
<span id="cb199-17"><a href="image-classification.html#cb199-17" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">item</span>()</span>
<span id="cb199-18"><a href="image-classification.html#cb199-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb199-19"><a href="image-classification.html#cb199-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-20"><a href="image-classification.html#cb199-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_epochs) {</span>
<span id="cb199-21"><a href="image-classification.html#cb199-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-22"><a href="image-classification.html#cb199-22" aria-hidden="true" tabindex="-1"></a>  model<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb199-23"><a href="image-classification.html#cb199-23" aria-hidden="true" tabindex="-1"></a>  train_losses <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb199-24"><a href="image-classification.html#cb199-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-25"><a href="image-classification.html#cb199-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="fu">enumerate</span>(train_dl)) {</span>
<span id="cb199-26"><a href="image-classification.html#cb199-26" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">&lt;-</span> <span class="fu">train_batch</span>(b)</span>
<span id="cb199-27"><a href="image-classification.html#cb199-27" aria-hidden="true" tabindex="-1"></a>    train_losses <span class="ot">&lt;-</span> <span class="fu">c</span>(train_losses, loss)</span>
<span id="cb199-28"><a href="image-classification.html#cb199-28" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb199-29"><a href="image-classification.html#cb199-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-30"><a href="image-classification.html#cb199-30" aria-hidden="true" tabindex="-1"></a>  model<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb199-31"><a href="image-classification.html#cb199-31" aria-hidden="true" tabindex="-1"></a>  valid_losses <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb199-32"><a href="image-classification.html#cb199-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-33"><a href="image-classification.html#cb199-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="fu">enumerate</span>(valid_dl)) {</span>
<span id="cb199-34"><a href="image-classification.html#cb199-34" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">&lt;-</span> <span class="fu">valid_batch</span>(b)</span>
<span id="cb199-35"><a href="image-classification.html#cb199-35" aria-hidden="true" tabindex="-1"></a>    valid_losses <span class="ot">&lt;-</span> <span class="fu">c</span>(valid_losses, loss)</span>
<span id="cb199-36"><a href="image-classification.html#cb199-36" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb199-37"><a href="image-classification.html#cb199-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-38"><a href="image-classification.html#cb199-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Loss at epoch %d: training: %3f, validation: %3f</span><span class="sc">\n</span><span class="st">&quot;</span>, epoch, <span class="fu">mean</span>(train_losses), <span class="fu">mean</span>(valid_losses)))</span>
<span id="cb199-39"><a href="image-classification.html#cb199-39" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>Loss at epoch 1: training: 2.662901, validation: 0.790769

Loss at epoch 2: training: 1.543315, validation: 1.014409

Loss at epoch 3: training: 1.376392, validation: 0.565186

Loss at epoch 4: training: 1.127091, validation: 0.575583

Loss at epoch 5: training: 0.916446, validation: 0.281600

Loss at epoch 6: training: 0.775241, validation: 0.215212

Loss at epoch 7: training: 0.639521, validation: 0.151283

Loss at epoch 8: training: 0.538825, validation: 0.106301

Loss at epoch 9: training: 0.407440, validation: 0.083270

Loss at epoch 10: training: 0.354659, validation: 0.080389</code></pre>
<p>It looks like the model made good progress, but we don’t yet know anything about classification accuracy in absolute terms. We’ll check that out on the test set.</p>
</div>
</div>
<div id="test-set-accuracy" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Test set accuracy</h2>
<p>Finally, we calculate accuracy on the test set:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="image-classification.html#cb201-1" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb201-2"><a href="image-classification.html#cb201-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-3"><a href="image-classification.html#cb201-3" aria-hidden="true" tabindex="-1"></a>test_batch <span class="ot">&lt;-</span> <span class="cf">function</span>(b) {</span>
<span id="cb201-4"><a href="image-classification.html#cb201-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-5"><a href="image-classification.html#cb201-5" aria-hidden="true" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">model</span>(b[[<span class="dv">1</span>]])</span>
<span id="cb201-6"><a href="image-classification.html#cb201-6" aria-hidden="true" tabindex="-1"></a>  labels <span class="ot">&lt;-</span> b[[<span class="dv">2</span>]]<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> device)</span>
<span id="cb201-7"><a href="image-classification.html#cb201-7" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">&lt;-</span> <span class="fu">criterion</span>(output, labels)</span>
<span id="cb201-8"><a href="image-classification.html#cb201-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb201-9"><a href="image-classification.html#cb201-9" aria-hidden="true" tabindex="-1"></a>  test_losses <span class="ot">&lt;&lt;-</span> <span class="fu">c</span>(test_losses, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb201-10"><a href="image-classification.html#cb201-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># torch_max returns a list, with position 1 containing the values</span></span>
<span id="cb201-11"><a href="image-classification.html#cb201-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># and position 2 containing the respective indices</span></span>
<span id="cb201-12"><a href="image-classification.html#cb201-12" aria-hidden="true" tabindex="-1"></a>  predicted <span class="ot">&lt;-</span> <span class="fu">torch_max</span>(output<span class="sc">$</span><span class="fu">data</span>(), <span class="at">dim =</span> <span class="dv">2</span>)[[<span class="dv">2</span>]]</span>
<span id="cb201-13"><a href="image-classification.html#cb201-13" aria-hidden="true" tabindex="-1"></a>  total <span class="ot">&lt;&lt;-</span> total <span class="sc">+</span> labels<span class="sc">$</span><span class="fu">size</span>(<span class="dv">1</span>)</span>
<span id="cb201-14"><a href="image-classification.html#cb201-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add number of correct classifications in this batch to the aggregate</span></span>
<span id="cb201-15"><a href="image-classification.html#cb201-15" aria-hidden="true" tabindex="-1"></a>  correct <span class="ot">&lt;&lt;-</span> correct <span class="sc">+</span> (predicted <span class="sc">==</span> labels)<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">$</span><span class="fu">item</span>()</span>
<span id="cb201-16"><a href="image-classification.html#cb201-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-17"><a href="image-classification.html#cb201-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb201-18"><a href="image-classification.html#cb201-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-19"><a href="image-classification.html#cb201-19" aria-hidden="true" tabindex="-1"></a>test_losses <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb201-20"><a href="image-classification.html#cb201-20" aria-hidden="true" tabindex="-1"></a>total <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb201-21"><a href="image-classification.html#cb201-21" aria-hidden="true" tabindex="-1"></a>correct <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb201-22"><a href="image-classification.html#cb201-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-23"><a href="image-classification.html#cb201-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="fu">enumerate</span>(test_dl)) {</span>
<span id="cb201-24"><a href="image-classification.html#cb201-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">test_batch</span>(b)</span>
<span id="cb201-25"><a href="image-classification.html#cb201-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb201-26"><a href="image-classification.html#cb201-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-27"><a href="image-classification.html#cb201-27" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(test_losses)</span></code></pre></div>
<pre><code>[1] 0.03719</code></pre>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="image-classification.html#cb203-1" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="ot">&lt;-</span>  correct<span class="sc">/</span>total</span>
<span id="cb203-2"><a href="image-classification.html#cb203-2" aria-hidden="true" tabindex="-1"></a>test_accuracy</span></code></pre></div>
<pre><code>[1] 0.98756</code></pre>
<p>An impressive result, given how many different species there are!</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="10">
<li id="fn10"><p>Physically, the dataset consists of a single <code>zip</code> file; so it is really the first instruction that downloads all the data. The remaining two function calls perform semantic mappings only.<a href="image-classification.html#fnref10" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="image-recognition-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="unet.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
