<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Classifying images | Applied deep learning with torch from R</title>
  <meta name="description" content="tbd" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Classifying images | Applied deep learning with torch from R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="tbd" />
  <meta property="og:image" content="tbdcover.png" />
  <meta property="og:description" content="tbd" />
  <meta name="github-repo" content="tbd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Classifying images | Applied deep learning with torch from R" />
  
  <meta name="twitter:description" content="tbd" />
  <meta name="twitter:image" content="tbdcover.png" />

<meta name="author" content="tbd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="image-recognition-intro.html"/>
<link rel="next" href="unet.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>I Using Torch</b></span></li>
<li class="chapter" data-level="" data-path="using-torch-intro.html"><a href="using-torch-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="2" data-path="simple-net-R.html"><a href="simple-net-R.html"><i class="fa fa-check"></i><b>2</b> A simple neural network in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#whats-in-a-network"><i class="fa fa-check"></i><b>2.1</b> What’s in a network?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="simple-net-R.html"><a href="simple-net-R.html#gradient-descent"><i class="fa fa-check"></i><b>2.1.1</b> Gradient descent</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-net-R.html"><a href="simple-net-R.html#from-linear-regression-to-a-simple-network"><i class="fa fa-check"></i><b>2.1.2</b> From linear regression to a simple network</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#a-simple-network"><i class="fa fa-check"></i><b>2.2</b> A simple network</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#simulate-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulate data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#initialize-weights-and-biases"><i class="fa fa-check"></i><b>2.2.2</b> Initialize weights and biases</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>2.2.3</b> Training loop</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-net-R.html"><a href="simple-net-R.html#complete-code"><i class="fa fa-check"></i><b>2.2.4</b> Complete code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>2.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html"><i class="fa fa-check"></i><b>3</b> Modifying the simple network to use torch tensors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#simple-network-torchified-step-1"><i class="fa fa-check"></i><b>3.1</b> Simple network torchified, step 1</a></li>
<li class="chapter" data-level="3.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#more-on-tensors"><i class="fa fa-check"></i><b>3.2</b> More on tensors</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#creating-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Creating tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#conversion-between-torch-tensors-and-r-values"><i class="fa fa-check"></i><b>3.2.2</b> Conversion between <code>torch</code> tensors and R values</a></li>
<li class="chapter" data-level="3.2.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#indexing-and-slicing-tensors"><i class="fa fa-check"></i><b>3.2.3</b> Indexing and slicing tensors</a></li>
<li class="chapter" data-level="3.2.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#reshaping-tensors"><i class="fa fa-check"></i><b>3.2.4</b> Reshaping tensors</a></li>
<li class="chapter" data-level="3.2.5" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#operations-on-tensors"><i class="fa fa-check"></i><b>3.2.5</b> Operations on tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#broadcasting"><i class="fa fa-check"></i><b>3.3</b> Broadcasting</a></li>
<li class="chapter" data-level="3.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#running-on-gpu"><i class="fa fa-check"></i><b>3.4</b> Running on GPU</a></li>
<li class="chapter" data-level="3.5" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>3.5</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html"><i class="fa fa-check"></i><b>4</b> Using autograd</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#automatic-differentiation-with-autograd"><i class="fa fa-check"></i><b>4.1</b> Automatic differentiation with autograd</a></li>
<li class="chapter" data-level="4.2" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#the-simple-network-now-using-autograd"><i class="fa fa-check"></i><b>4.2</b> The simple network, now using autograd</a></li>
<li class="chapter" data-level="4.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>4.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-net-modules.html"><a href="simple-net-modules.html"><i class="fa fa-check"></i><b>5</b> Using torch modules</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#modules"><i class="fa fa-check"></i><b>5.1</b> Modules</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#layers-as-modules"><i class="fa fa-check"></i><b>5.1.1</b> Layers as modules</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#models-as-modules"><i class="fa fa-check"></i><b>5.1.2</b> Models as modules</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#simple-network-using-modules"><i class="fa fa-check"></i><b>5.2</b> Simple network using modules</a></li>
<li class="chapter" data-level="5.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>5.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-net-optim.html"><a href="simple-net-optim.html"><i class="fa fa-check"></i><b>6</b> Using <code>torch</code> optimizers</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple-net-optim.html"><a href="simple-net-optim.html#torch-optimizers"><i class="fa fa-check"></i><b>6.1</b> Torch optimizers</a></li>
<li class="chapter" data-level="6.2" data-path="simple-net-optim.html"><a href="simple-net-optim.html#simple-net-with-optim"><i class="fa fa-check"></i><b>6.2</b> Simple net with <code>optim</code></a></li>
<li class="chapter" data-level="6.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>6.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="part"><span><b>II Image Recognition</b></span></li>
<li class="chapter" data-level="" data-path="image-recognition-intro.html"><a href="image-recognition-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="7" data-path="image-classification.html"><a href="image-classification.html"><i class="fa fa-check"></i><b>7</b> Classifying images</a>
<ul>
<li class="chapter" data-level="7.1" data-path="image-classification.html"><a href="image-classification.html#data-loading-and-transformation"><i class="fa fa-check"></i><b>7.1</b> Data loading and transformation</a></li>
<li class="chapter" data-level="7.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>7.2</b> Model</a></li>
<li class="chapter" data-level="7.3" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>7.3</b> Training</a></li>
<li class="chapter" data-level="7.4" data-path="image-classification.html"><a href="image-classification.html#performance-on-the-test-set"><i class="fa fa-check"></i><b>7.4</b> Performance on the test set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unet.html"><a href="unet.html"><i class="fa fa-check"></i><b>8</b> Brain Image Segmentation with U-Net</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unet.html"><a href="unet.html#image-segmentation-in-a-nutshell"><i class="fa fa-check"></i><b>8.1</b> Image segmentation in a nutshell</a></li>
<li class="chapter" data-level="8.2" data-path="unet.html"><a href="unet.html#u-net"><i class="fa fa-check"></i><b>8.2</b> U-Net</a></li>
<li class="chapter" data-level="8.3" data-path="unet.html"><a href="unet.html#example-application-mri-images"><i class="fa fa-check"></i><b>8.3</b> Example application: MRI images</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="unet.html"><a href="unet.html#preprocessing"><i class="fa fa-check"></i><b>8.3.1</b> Preprocessing</a></li>
<li class="chapter" data-level="8.3.2" data-path="unet.html"><a href="unet.html#u-net-model"><i class="fa fa-check"></i><b>8.3.2</b> U-Net model</a></li>
<li class="chapter" data-level="8.3.3" data-path="unet.html"><a href="unet.html#loss"><i class="fa fa-check"></i><b>8.3.3</b> Loss</a></li>
<li class="chapter" data-level="8.3.4" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>8.3.4</b> Training</a></li>
<li class="chapter" data-level="8.3.5" data-path="unet.html"><a href="unet.html#predictions"><i class="fa fa-check"></i><b>8.3.5</b> Predictions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Natural language processing</b></span></li>
<li class="chapter" data-level="" data-path="NLP-intro.html"><a href="NLP-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="9" data-path="seq2seq-att.html"><a href="seq2seq-att.html"><i class="fa fa-check"></i><b>9</b> Sequence-to-sequence models with attention</a>
<ul>
<li class="chapter" data-level="9.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#why-attention"><i class="fa fa-check"></i><b>9.1</b> Why attention?</a></li>
<li class="chapter" data-level="9.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#preprocessing-with-torchtext"><i class="fa fa-check"></i><b>9.2</b> Preprocessing with <code>torchtext</code></a></li>
<li class="chapter" data-level="9.3" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>9.3</b> Model</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>9.3.1</b> Encoder</a></li>
<li class="chapter" data-level="9.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#attention-module"><i class="fa fa-check"></i><b>9.3.2</b> Attention module</a></li>
<li class="chapter" data-level="9.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>9.3.3</b> Decoder</a></li>
<li class="chapter" data-level="9.3.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#seq2seq-module"><i class="fa fa-check"></i><b>9.3.4</b> Seq2seq module</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#training-and-evaluation"><i class="fa fa-check"></i><b>9.4</b> Training and evaluation</a></li>
<li class="chapter" data-level="9.5" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>9.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="transformer.html"><a href="transformer.html"><i class="fa fa-check"></i><b>10</b> Torch transformer modules</a>
<ul>
<li class="chapter" data-level="10.1" data-path="transformer.html"><a href="transformer.html#attention-is-all-you-need"><i class="fa fa-check"></i><b>10.1</b> “Attention is all you need”</a></li>
<li class="chapter" data-level="10.2" data-path="transformer.html"><a href="transformer.html#implementation-building-blocks"><i class="fa fa-check"></i><b>10.2</b> Implementation: building blocks</a></li>
<li class="chapter" data-level="10.3" data-path="transformer.html"><a href="transformer.html#a-transformer-for-natural-language-translation"><i class="fa fa-check"></i><b>10.3</b> A Transformer for natural language translation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="transformer.html"><a href="transformer.html#load-data"><i class="fa fa-check"></i><b>10.3.1</b> Load data</a></li>
<li class="chapter" data-level="10.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>10.3.2</b> Encoder</a></li>
<li class="chapter" data-level="10.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>10.3.3</b> Decoder</a></li>
<li class="chapter" data-level="10.3.4" data-path="transformer.html"><a href="transformer.html#overall-model"><i class="fa fa-check"></i><b>10.3.4</b> Overall model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
</ul></li>
<li class="part"><span><b>IV Deep learning for tabular data</b></span></li>
<li class="chapter" data-level="" data-path="tabular-intro.html"><a href="tabular-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V Time series</b></span></li>
<li class="chapter" data-level="" data-path="timeseries-intro.html"><a href="timeseries-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VI Generative deep learning</b></span></li>
<li class="chapter" data-level="" data-path="generative-intro.html"><a href="generative-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="11" data-path="gans.html"><a href="gans.html"><i class="fa fa-check"></i><b>11</b> Generative adversarial networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>11.1</b> Dataset</a></li>
<li class="chapter" data-level="11.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>11.2</b> Model</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="gans.html"><a href="gans.html#generator"><i class="fa fa-check"></i><b>11.2.1</b> Generator</a></li>
<li class="chapter" data-level="11.2.2" data-path="gans.html"><a href="gans.html#discriminator"><i class="fa fa-check"></i><b>11.2.2</b> Discriminator</a></li>
<li class="chapter" data-level="11.2.3" data-path="gans.html"><a href="gans.html#optimizers-and-loss-function"><i class="fa fa-check"></i><b>11.2.3</b> Optimizers and loss function</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>11.3</b> Training loop</a></li>
<li class="chapter" data-level="11.4" data-path="gans.html"><a href="gans.html#artifacts"><i class="fa fa-check"></i><b>11.4</b> Artifacts</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="vaes.html"><a href="vaes.html"><i class="fa fa-check"></i><b>12</b> Variational autoencoders</a>
<ul>
<li class="chapter" data-level="12.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>12.1</b> Dataset</a></li>
<li class="chapter" data-level="12.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>12.2</b> Model</a></li>
<li class="chapter" data-level="12.3" data-path="vaes.html"><a href="vaes.html#training-the-vae"><i class="fa fa-check"></i><b>12.3</b> Training the VAE</a></li>
<li class="chapter" data-level="12.4" data-path="vaes.html"><a href="vaes.html#latent-space"><i class="fa fa-check"></i><b>12.4</b> Latent space</a></li>
</ul></li>
<li class="part"><span><b>VII Deep learning on graphs</b></span></li>
<li class="chapter" data-level="" data-path="graph-intro.html"><a href="graph-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VIII Probabilistic deep learning</b></span></li>
<li class="chapter" data-level="" data-path="probabilistic-intro.html"><a href="probabilistic-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>IX Private and secure deep learning</b></span></li>
<li class="chapter" data-level="" data-path="private-secure-intro.html"><a href="private-secure-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>X Research topics</b></span></li>
<li class="chapter" data-level="" data-path="research-intro.html"><a href="research-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied deep learning with torch from R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="image_classification" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Classifying images</h1>
<p>Our image classification example will differentiate … not dogs and cats, not different dog breeds, but …different species of birds. We start from a model pre-trained on <a href="http://www.image-net.org/">ImageNet</a>, which contains abundantly many photos of birds (and other animals you wouldn’t know even existed).</p>
<p>Concretely, for the pre-trained model we’ll use a Resnet, one of several classic computer vision models provided by <code>torchvision</code>, and attach our own classification layer on top. If you are looking for how to code a convolutional neural network from scratch, you can pick up related information in the following chapter on image segmentation, as well as that on generative adversarial networks (GANs).</p>
<div id="data-loading-and-transformation" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Data loading and transformation</h2>
<p>The example dataset used here is available on Kaggle (<a href="https://www.kaggle.com/gpiosenka/100-bird-species/data" class="uri">https://www.kaggle.com/gpiosenka/100-bird-species/data</a>). It is very “non-noisy”, which is why, the number of classes notwithstanding (130!), accuracy will turn out to be very good.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="image-classification.html#cb98-1"></a><span class="kw">library</span>(torch)</span>
<span id="cb98-2"><a href="image-classification.html#cb98-2"></a><span class="kw">library</span>(torchvision)</span>
<span id="cb98-3"><a href="image-classification.html#cb98-3"></a><span class="kw">library</span>(dplyr)</span></code></pre></div>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="image-classification.html#cb99-1"></a><span class="co"># from: https://www.kaggle.com/gpiosenka/100-bird-species/data</span></span>
<span id="cb99-2"><a href="image-classification.html#cb99-2"></a>data_dir =<span class="st"> &#39;data/bird_species&#39;</span></span></code></pre></div>
<p>The data set being so clean, we’ll want to introduce random noise (<em>data augmentation</em>) on the training set to enhance model resiliency.</p>
<p>In <code>torchvision</code>, data augmentation steps are added as part of an <em>image processing pipeline</em> that also takes care of resizing and/or cropping images, converting them to <code>torch</code> tensors, and possibly, normalizing them according to the model’s expectations. Here they are, deterministic on validation and test sets, but including random components for the training set:</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="image-classification.html#cb100-1"></a>train_transforms &lt;-<span class="st"> </span><span class="cf">function</span>(img) {</span>
<span id="cb100-2"><a href="image-classification.html#cb100-2"></a>  img <span class="op">%&gt;%</span></span>
<span id="cb100-3"><a href="image-classification.html#cb100-3"></a><span class="st">    </span><span class="kw">transform_random_resized_crop</span>(<span class="dt">size =</span> <span class="kw">c</span>(<span class="dv">224</span>, <span class="dv">224</span>)) <span class="op">%&gt;%</span></span>
<span id="cb100-4"><a href="image-classification.html#cb100-4"></a><span class="st">    </span><span class="kw">transform_color_jitter</span>() <span class="op">%&gt;%</span></span>
<span id="cb100-5"><a href="image-classification.html#cb100-5"></a><span class="st">    </span><span class="kw">transform_random_horizontal_flip</span>() <span class="op">%&gt;%</span></span>
<span id="cb100-6"><a href="image-classification.html#cb100-6"></a><span class="st">    </span><span class="kw">transform_to_tensor</span>() <span class="op">%&gt;%</span></span>
<span id="cb100-7"><a href="image-classification.html#cb100-7"></a><span class="st">    </span><span class="kw">transform_normalize</span>(<span class="dt">mean =</span> <span class="kw">c</span>(<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>), <span class="dt">std =</span> <span class="kw">c</span>(<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>))</span>
<span id="cb100-8"><a href="image-classification.html#cb100-8"></a>}</span>
<span id="cb100-9"><a href="image-classification.html#cb100-9"></a></span>
<span id="cb100-10"><a href="image-classification.html#cb100-10"></a>valid_transforms &lt;-<span class="st"> </span><span class="cf">function</span>(img) {</span>
<span id="cb100-11"><a href="image-classification.html#cb100-11"></a>  img <span class="op">%&gt;%</span></span>
<span id="cb100-12"><a href="image-classification.html#cb100-12"></a><span class="st">    </span><span class="kw">transform_resize</span>(<span class="dv">256</span>) <span class="op">%&gt;%</span></span>
<span id="cb100-13"><a href="image-classification.html#cb100-13"></a><span class="st">    </span><span class="kw">transform_center_crop</span>(<span class="dv">224</span>) <span class="op">%&gt;%</span></span>
<span id="cb100-14"><a href="image-classification.html#cb100-14"></a><span class="st">    </span><span class="kw">transform_to_tensor</span>() <span class="op">%&gt;%</span></span>
<span id="cb100-15"><a href="image-classification.html#cb100-15"></a><span class="st">    </span><span class="kw">transform_normalize</span>(<span class="dt">mean =</span> <span class="kw">c</span>(<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>), <span class="dt">std =</span> <span class="kw">c</span>(<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>))</span>
<span id="cb100-16"><a href="image-classification.html#cb100-16"></a>}</span>
<span id="cb100-17"><a href="image-classification.html#cb100-17"></a></span>
<span id="cb100-18"><a href="image-classification.html#cb100-18"></a>test_transforms &lt;-<span class="st"> </span>valid_transforms</span>
<span id="cb100-19"><a href="image-classification.html#cb100-19"></a></span>
<span id="cb100-20"><a href="image-classification.html#cb100-20"></a><span class="co"># </span><span class="al">TBD</span><span class="co"> remove later</span></span>
<span id="cb100-21"><a href="image-classification.html#cb100-21"></a>target_transform =<span class="st"> </span><span class="cf">function</span>(x) {</span>
<span id="cb100-22"><a href="image-classification.html#cb100-22"></a>  x &lt;-<span class="st"> </span><span class="kw">torch_tensor</span>(x, <span class="dt">dtype =</span> <span class="kw">torch_long</span>())</span>
<span id="cb100-23"><a href="image-classification.html#cb100-23"></a>  x<span class="op">$</span><span class="kw">squeeze</span>(<span class="dv">1</span>)</span>
<span id="cb100-24"><a href="image-classification.html#cb100-24"></a>}</span></code></pre></div>
<p><code>image_folder_dataset</code> is a subtype of dataset that encapsulates information about where the images reside, and what transformations to apply. Here, we create such a dataset for each of training, validation and test set:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="image-classification.html#cb101-1"></a>train_ds &lt;-<span class="st"> </span><span class="kw">image_folder_dataset</span>(</span>
<span id="cb101-2"><a href="image-classification.html#cb101-2"></a>  <span class="kw">file.path</span>(data_dir, <span class="st">&quot;train&quot;</span>),</span>
<span id="cb101-3"><a href="image-classification.html#cb101-3"></a>  <span class="dt">transform =</span> train_transforms,</span>
<span id="cb101-4"><a href="image-classification.html#cb101-4"></a>  <span class="dt">target_transform =</span> target_transform)</span>
<span id="cb101-5"><a href="image-classification.html#cb101-5"></a></span>
<span id="cb101-6"><a href="image-classification.html#cb101-6"></a>valid_ds &lt;-<span class="st"> </span><span class="kw">image_folder_dataset</span>(</span>
<span id="cb101-7"><a href="image-classification.html#cb101-7"></a>  <span class="kw">file.path</span>(data_dir, <span class="st">&quot;valid&quot;</span>),</span>
<span id="cb101-8"><a href="image-classification.html#cb101-8"></a>  <span class="dt">transform =</span> valid_transforms,</span>
<span id="cb101-9"><a href="image-classification.html#cb101-9"></a>  <span class="dt">target_transform =</span> target_transform)</span>
<span id="cb101-10"><a href="image-classification.html#cb101-10"></a></span>
<span id="cb101-11"><a href="image-classification.html#cb101-11"></a>test_ds &lt;-<span class="st"> </span><span class="kw">image_folder_dataset</span>(</span>
<span id="cb101-12"><a href="image-classification.html#cb101-12"></a>  <span class="kw">file.path</span>(data_dir, <span class="st">&quot;test&quot;</span>),</span>
<span id="cb101-13"><a href="image-classification.html#cb101-13"></a>  <span class="dt">transform =</span> test_transforms)</span></code></pre></div>
<p><code>image_folder_dataset</code> objects expect the different classes of images to reside each in their own folder. In our example, this is in fact the case; for example, here is the directory layout for the first three classes in the test set:</p>
<pre><code>data/test/ALBATROSS/
 - data/test/ALBATROSS/1.jpg
 - data/test/ALBATROSS/2.jpg
 - data/test/ALBATROSS/3.jpg
 - data/test/ALBATROSS/4.jpg
 - data/test/ALBATROSS/5.jpg
 
data/test/&#39;ALEXANDRINE PARAKEET&#39;/
 - data/test/&#39;ALEXANDRINE PARAKEET&#39;/1.jpg
 - data/test/&#39;ALEXANDRINE PARAKEET&#39;/2.jpg
 - data/test/&#39;ALEXANDRINE PARAKEET&#39;/3.jpg
 - data/test/&#39;ALEXANDRINE PARAKEET&#39;/4.jpg
 - data/test/&#39;ALEXANDRINE PARAKEET&#39;/5.jpg
 
 data/test/&#39;AMERICAN BITTERN&#39;/
 - data/test/&#39;AMERICAN BITTERN&#39;/1.jpg
 - data/test/&#39;AMERICAN BITTERN&#39;/2.jpg
 - data/test/&#39;AMERICAN BITTERN&#39;/3.jpg
 - data/test/&#39;AMERICAN BITTERN&#39;/4.jpg
 - data/test/&#39;AMERICAN BITTERN&#39;/5.jpg</code></pre>
<p>From those specifications, <code>dataloaders</code> are created. These objects, in addition to <em>what</em> to load and which transformations to apply, know things like: how many items to load per batch, whether they should be shuffled, and whether to parallelize the transformations.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="image-classification.html#cb103-1"></a>train_dl &lt;-<span class="st"> </span><span class="kw">dataloader</span>(train_ds, <span class="dt">batch_size =</span> <span class="dv">16</span>, <span class="dt">shuffle =</span> <span class="ot">TRUE</span>)</span>
<span id="cb103-2"><a href="image-classification.html#cb103-2"></a>valid_dl &lt;-<span class="st"> </span><span class="kw">dataloader</span>(valid_ds, <span class="dt">batch_size =</span> <span class="dv">16</span>)</span>
<span id="cb103-3"><a href="image-classification.html#cb103-3"></a>test_dl &lt;-<span class="st"> </span><span class="kw">dataloader</span>(test_ds, <span class="dt">batch_size =</span> <span class="dv">16</span>)</span></code></pre></div>
<p>How many items are there in each set?</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="image-classification.html#cb104-1"></a>train_dl<span class="op">$</span><span class="kw">.length</span>() <span class="co"># 1065</span></span>
<span id="cb104-2"><a href="image-classification.html#cb104-2"></a>valid_dl<span class="op">$</span><span class="kw">.length</span>() <span class="co"># 41</span></span>
<span id="cb104-3"><a href="image-classification.html#cb104-3"></a>test_dl<span class="op">$</span><span class="kw">.length</span>()  <span class="co"># 41</span></span></code></pre></div>
<p>Datasets know what classes there are:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="image-classification.html#cb105-1"></a>class_names &lt;-<span class="st"> </span>train_ds<span class="op">$</span>classes</span>
<span id="cb105-2"><a href="image-classification.html#cb105-2"></a>class_names</span></code></pre></div>
<pre><code> [1] &quot;ALBATROSS&quot;                  &quot;ALEXANDRINE PARAKEET&quot;     
 [3] &quot;AMERICAN BITTERN&quot;           &quot;AMERICAN GOLDFINCH&quot;       
 [5] &quot;AMERICAN KESTREL&quot;           &quot;AMERICAN REDSTART&quot;        
 [7] &quot;ANHINGA&quot;                    &quot;ANNAS HUMMINGBIRD&quot;        
 [9] &quot;BALD EAGLE&quot;                 &quot;BALTIMORE ORIOLE&quot;         
 [11] &quot;BANANAQUIT&quot;                &quot;BAR-TAILED GODWIT&quot;        
 [13] &quot;BARN OWL&quot;                  &quot;BARN SWALLOW&quot;             
 [15] &quot;BAY-BREASTED WARBLER&quot;      &quot;BELTED KINGFISHER&quot;        
 [17] &quot;BIRD OF PARADISE&quot;          &quot;BLACK FRANCOLIN&quot;          
 [19] &quot;BLACK SKIMMER&quot;             &quot;BLACK-CAPPED CHICKADEE&quot;   
 [21] &quot;BLACK-NECKED GREBE&quot;        &quot;BLACKBURNIAM WARBLER&quot;     
 [23] &quot;BLUE HERON&quot;                &quot;BOBOLINK&quot;                 
 [25] &quot;BROWN THRASHER&quot;            &quot;CACTUS WREN&quot;              
 [27] &quot;CALIFORNIA CONDOR&quot;         &quot;CALIFORNIA GULL&quot;          
 [29] &quot;CALIFORNIA QUAIL&quot;          &quot;CAPE MAY WARBLER&quot;         
 [31] &quot;CHARA DE COLLAR&quot;           &quot;CHIPPING SPARROW&quot;         
 [33] &quot;CINNAMON TEAL&quot;             &quot;COCK OF THE  ROCK&quot;        
 [35] &quot;COCKATOO&quot;                  &quot;COMMON LOON&quot;              
 [37] &quot;COMMON POORWILL&quot;           &quot;COMMON STARLING&quot;          
 [39] &quot;COUCHS KINGBIRD&quot;           &quot;CRESTED AUKLET&quot;           
 [41] &quot;CRESTED CARACARA&quot;          &quot;CROW&quot;                     
 [43] &quot;CROWNED PIGEON&quot;            &quot;CURL CRESTED ARACURI&quot;     
 [45] &quot;DARK EYED JUNCO&quot;           &quot;DOWNY WOODPECKER&quot;         
 [47] &quot;EASTERN BLUEBIRD&quot;          &quot;EASTERN ROSELLA&quot;          
 [49] &quot;EASTERN TOWEE&quot;             &quot;ELEGANT TROGON&quot;           
 [51] &quot;EMPEROR PENGUIN&quot;           &quot;EVENING GROSBEAK&quot;         
 [53] &quot;FLAME TANAGER&quot;             &quot;FLAMINGO&quot;                 
 [55] &quot;FRIGATE&quot;                   &quot;GLOSSY IBIS&quot;              
 [57] &quot;GOLD WING WARBLER&quot;         &quot;GOLDEN CHLOROPHONIA&quot;      
 [59] &quot;GOLDEN EAGLE&quot;              &quot;GOLDEN PHEASANT&quot;          
 [61] &quot;GOULDIAN FINCH&quot;            &quot;GRAY CATBIRD&quot;             
 [63] &quot;GRAY PARTRIDGE&quot;            &quot;GREY PLOVER&quot;              
 [65] &quot;HAWAIIAN GOOSE&quot;            &quot;HOODED MERGANSER&quot;         
 [67] &quot;HOOPOES&quot;                   &quot;HOUSE FINCH&quot;              
 [69] &quot;HOUSE SPARROW&quot;             &quot;HYACINTH MACAW&quot;           
 [71] &quot;INDIGO BUNTING&quot;            &quot;JABIRU&quot;                   
 [73] &quot;LARK BUNTING&quot;              &quot;LILAC ROLLER&quot;             
 [75] &quot;LONG-EARED OWL&quot;            &quot;MALLARD DUCK&quot;             
 [77] &quot;MANDRIN DUCK&quot;              &quot;MARABOU STORK&quot;            
 [79] &quot;MOURNING DOVE&quot;             &quot;MYNA&quot;                     
 [81] &quot;NICOBAR PIGEON&quot;            &quot;NORTHERN CARDINAL&quot;        
 [83] &quot;NORTHERN FLICKER&quot;          &quot;NORTHERN GOSHAWK&quot;         
 [85] &quot;NORTHERN MOCKINGBIRD&quot;      &quot;OSTRICH&quot;                  
 [87] &quot;PAINTED BUNTIG&quot;            &quot;PARADISE TANAGER&quot;         
 [89] &quot;PARUS MAJOR&quot;               &quot;PEACOCK&quot;                  
 [91] &quot;PELICAN&quot;                   &quot;PEREGRINE FALCON&quot;         
 [93] &quot;PINK ROBIN&quot;                &quot;PUFFIN&quot;                   
 [95] &quot;PURPLE FINCH&quot;              &quot;PURPLE GALLINULE&quot;         
 [97] &quot;PURPLE MARTIN&quot;             &quot;QUETZAL&quot;                  
 [99] &quot;RAINBOW LORIKEET&quot;          &quot;RED FACED CORMORANT&quot;      
[101] &quot;RED HEADED WOODPECKER&quot;     &quot;RED THROATED BEE EATER&quot;   
[103] &quot;RED WINGED BLACKBIRD&quot;      &quot;RED WISKERED BULBUL&quot;      
[105] &quot;RING-NECKED PHEASANT&quot;      &quot;ROADRUNNER&quot;               
[107] &quot;ROBIN&quot;                     &quot;ROUGH LEG BUZZARD&quot;        
[109] &quot;RUBY THROATED HUMMINGBIRD&quot; &quot;SAND MARTIN&quot;              
[111] &quot;SCARLET IBIS&quot;              &quot;SCARLET MACAW&quot;            
[113] &quot;SNOWY EGRET&quot;               &quot;SPLENDID WREN&quot;            
[115] &quot;STORK BILLED KINGFISHER&quot;   &quot;STRAWBERRY FINCH&quot;         
[117] &quot;TEAL DUCK&quot;                 &quot;TIT MOUSE&quot;                
[119] &quot;TOUCHAN&quot;                   &quot;TRUMPTER SWAN&quot;            
[121] &quot;TURKEY VULTURE&quot;            &quot;TURQUOISE MOTMOT&quot;         
[123] &quot;VARIED THRUSH&quot;             &quot;VENEZUELIAN TROUPIAL&quot;     
[125] &quot;VERMILION FLYCATHER&quot;       &quot;VIOLET GREEN SWALLOW&quot;     
[127] &quot;WESTERN MEADOWLARK&quot;        &quot;WILSONS BIRD OF PARADISE&quot; 
[129] &quot;WOOD DUCK&quot;                 &quot;YELLOW HEADED BLACKBIRD&quot;  
&gt; </code></pre>
<p>Next, let’s view a few images from the test set. We can retrieve the first batch – images and corresponding classes – by creating an iterator from the <code>dataloader</code> and calling <code>next()</code> on it:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="image-classification.html#cb107-1"></a>batch &lt;-<span class="st"> </span>train_dl<span class="op">$</span><span class="kw">.iter</span>()<span class="op">$</span><span class="kw">.next</span>()</span></code></pre></div>
<p><code>batch</code> is a list, the first item being the image tensors …</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="image-classification.html#cb108-1"></a>batch[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">size</span>()</span></code></pre></div>
<pre><code>[1]  16   3 224 224</code></pre>
<p>… and the second, the classes:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="image-classification.html#cb110-1"></a>batch[[<span class="dv">2</span>]]<span class="op">$</span><span class="kw">size</span>()</span></code></pre></div>
<pre><code>[1] 16</code></pre>
<p>The classes are coded as integers, to be used as indexes into the vector of class names. We’ll use those for labeling the images.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="image-classification.html#cb112-1"></a>classes &lt;-<span class="st"> </span>batch[[<span class="dv">2</span>]]</span>
<span id="cb112-2"><a href="image-classification.html#cb112-2"></a>classes</span></code></pre></div>
<pre><code>torch_tensor 
   3
  46
  67
  52
  88
 112
  76
 111
 109
  70
  40
  72
  75
  53
  27
  90
[ CPULongType{16} ]</code></pre>
<p>Now to visualization. The image tensors are of shape <code>batch_size x num_channels x height x width</code>. Since we want to use <code>as.raster</code> for plotting, we need to reshape images such that channels come last. Here are the first sixteen images:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="image-classification.html#cb114-1"></a><span class="kw">library</span>(dplyr)</span>
<span id="cb114-2"><a href="image-classification.html#cb114-2"></a></span>
<span id="cb114-3"><a href="image-classification.html#cb114-3"></a>images &lt;-<span class="st"> </span><span class="kw">as_array</span>(batch[[<span class="dv">1</span>]]) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">aperm</span>(<span class="dt">perm =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>))</span>
<span id="cb114-4"><a href="image-classification.html#cb114-4"></a>mean &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>)</span>
<span id="cb114-5"><a href="image-classification.html#cb114-5"></a>std &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>)</span>
<span id="cb114-6"><a href="image-classification.html#cb114-6"></a>images &lt;-<span class="st"> </span>std <span class="op">*</span><span class="st"> </span>images <span class="op">+</span><span class="st"> </span>mean</span>
<span id="cb114-7"><a href="image-classification.html#cb114-7"></a>images &lt;-<span class="st"> </span>images <span class="op">*</span><span class="st"> </span><span class="dv">255</span></span>
<span id="cb114-8"><a href="image-classification.html#cb114-8"></a>images[images <span class="op">&gt;</span><span class="st"> </span><span class="dv">255</span>] &lt;-<span class="st"> </span><span class="dv">255</span></span>
<span id="cb114-9"><a href="image-classification.html#cb114-9"></a>images[images <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb114-10"><a href="image-classification.html#cb114-10"></a></span>
<span id="cb114-11"><a href="image-classification.html#cb114-11"></a><span class="kw">par</span>(<span class="dt">mfcol =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>), <span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">4</span>))</span>
<span id="cb114-12"><a href="image-classification.html#cb114-12"></a></span>
<span id="cb114-13"><a href="image-classification.html#cb114-13"></a>images <span class="op">%&gt;%</span></span>
<span id="cb114-14"><a href="image-classification.html#cb114-14"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">array_tree</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb114-15"><a href="image-classification.html#cb114-15"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">set_names</span>(class_names[<span class="kw">as_array</span>(classes)]) <span class="op">%&gt;%</span></span>
<span id="cb114-16"><a href="image-classification.html#cb114-16"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">map</span>(as.raster, <span class="dt">max =</span> <span class="dv">255</span>) <span class="op">%&gt;%</span></span>
<span id="cb114-17"><a href="image-classification.html#cb114-17"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">iwalk</span>(<span class="op">~</span>{<span class="kw">plot</span>(.x); <span class="kw">title</span>(.y)})</span></code></pre></div>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="image-classification.html#cb115-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/image_classif_birds.png&quot;</span>)</span></code></pre></div>
<p><img src="images/image_classif_birds.png" width="384" /></p>
</div>
<div id="model" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Model</h2>
<p>The backbone of our model is a pre-trained instance of Resnet.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="image-classification.html#cb116-1"></a>model &lt;-<span class="st"> </span><span class="kw">model_resnet18</span>(<span class="dt">pretrained =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p>We will modify the model’s output layer to distinguish between our 130 bird classes, instead of the 1000 ImageNet classes it was trained for. This means we only need to train a single layer – the one we’re going to add. We <em>could</em> perform backpropagation through the complete model, trying to fine-tune Resnet’s weights as well, but that would have a significant effect on training time. (Alternatively, we could try to fine-tune just a few of Resnet’s weights, those located in the layers directly preceding the output.)</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="image-classification.html#cb117-1"></a>model<span class="op">$</span>parameters <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb117-2"><a href="image-classification.html#cb117-2"></a><span class="st">  </span>purrr<span class="op">::</span><span class="kw">walk</span>(<span class="cf">function</span>(param) param<span class="op">$</span>requires_grad &lt;-<span class="st"> </span><span class="ot">FALSE</span>)</span></code></pre></div>
<p>To replace the output layer, the model is just modified in-place:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="image-classification.html#cb118-1"></a>num_features &lt;-<span class="st"> </span>model<span class="op">$</span>fc<span class="op">$</span>in_features</span>
<span id="cb118-2"><a href="image-classification.html#cb118-2"></a></span>
<span id="cb118-3"><a href="image-classification.html#cb118-3"></a>model<span class="op">$</span>fc &lt;-<span class="st"> </span><span class="kw">nn_linear</span>(<span class="dt">in_features =</span> num_features, <span class="dt">out_features =</span> <span class="kw">length</span>(class_names))</span></code></pre></div>
<p>Now put the modified model on the GPU:</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="image-classification.html#cb119-1"></a>device &lt;-<span class="st"> </span><span class="cf">if</span> (<span class="kw">cuda_is_available</span>()) <span class="kw">torch_device</span>(<span class="st">&quot;cuda:0&quot;</span>) <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb119-2"><a href="image-classification.html#cb119-2"></a></span>
<span id="cb119-3"><a href="image-classification.html#cb119-3"></a>model &lt;-<span class="st"> </span>model<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> device)</span></code></pre></div>
</div>
<div id="training" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Training</h2>
<p>For training, we use cross entropy loss and stochastic gradient descent.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="image-classification.html#cb120-1"></a>criterion &lt;-<span class="st"> </span><span class="kw">nn_cross_entropy_loss</span>()</span>
<span id="cb120-2"><a href="image-classification.html#cb120-2"></a></span>
<span id="cb120-3"><a href="image-classification.html#cb120-3"></a>optimizer &lt;-<span class="st"> </span><span class="kw">optim_sgd</span>(model<span class="op">$</span>parameters, <span class="dt">lr =</span> <span class="fl">0.001</span>, <span class="dt">momentum =</span> <span class="fl">0.9</span>)</span></code></pre></div>
<p>We set the learning rate to 0.1, but that is just a formality. As became widely known due to <a href="">fast.ai’s deep learning lectures</a>, it always makes sense to spend some time upfront to determine a good learning rate, and then during training, evolve the learning rate according to some established algorithm. While out-of-the-box, <code>torch</code> does not provide a tool like fast.ai’s learning rate finder, the logic is straightforward to implement, and sample code is given on Sylvain Gugger’s blog.</p>
<p>Algorithms like one-cycle learning <span class="citation">(Smith and Topin <a href="#ref-abs-1708-07120" role="doc-biblioref">2017</a>)</span>, cyclical learning rates <span class="citation">(Smith <a href="#ref-Smith15a" role="doc-biblioref">2015</a>)</span>, or cosine annealing with warm restarts <span class="citation">(Loshchilov and Hutter <a href="#ref-LoshchilovH16a" role="doc-biblioref">2016</a>)</span> are, however, implemented in <code>torch</code>, and we’ll make use of <code>lr_scheduler.OneCycleLR</code> once we’ve determined an appropriate value for the required parameter <code>max_lr</code>.</p>
<p>Here is how to find a good learning rate, translated to R from <a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html">Sylvain Gugger’s post</a>:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="image-classification.html#cb121-1"></a><span class="co"># ported from: https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html</span></span>
<span id="cb121-2"><a href="image-classification.html#cb121-2"></a></span>
<span id="cb121-3"><a href="image-classification.html#cb121-3"></a>losses &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb121-4"><a href="image-classification.html#cb121-4"></a>log_lrs &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb121-5"><a href="image-classification.html#cb121-5"></a></span>
<span id="cb121-6"><a href="image-classification.html#cb121-6"></a>find_lr &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">init_value =</span> <span class="fl">1e-8</span>, <span class="dt">final_value =</span> <span class="dv">10</span>, <span class="dt">beta =</span> <span class="fl">0.98</span>) {</span>
<span id="cb121-7"><a href="image-classification.html#cb121-7"></a></span>
<span id="cb121-8"><a href="image-classification.html#cb121-8"></a>  num &lt;-<span class="st"> </span>train_dl<span class="op">$</span><span class="kw">.length</span>()</span>
<span id="cb121-9"><a href="image-classification.html#cb121-9"></a>  mult =<span class="st"> </span>(final_value<span class="op">/</span>init_value)<span class="op">^</span>(<span class="dv">1</span><span class="op">/</span>num)</span>
<span id="cb121-10"><a href="image-classification.html#cb121-10"></a>  lr &lt;-<span class="st"> </span>init_value</span>
<span id="cb121-11"><a href="image-classification.html#cb121-11"></a>  optimizer<span class="op">$</span>param_groups[[<span class="dv">1</span>]]<span class="op">$</span>lr &lt;-<span class="st"> </span>lr</span>
<span id="cb121-12"><a href="image-classification.html#cb121-12"></a>  avg_loss &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb121-13"><a href="image-classification.html#cb121-13"></a>  best_loss &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb121-14"><a href="image-classification.html#cb121-14"></a>  batch_num &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb121-15"><a href="image-classification.html#cb121-15"></a></span>
<span id="cb121-16"><a href="image-classification.html#cb121-16"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="kw">enumerate</span>(train_dl)) {</span>
<span id="cb121-17"><a href="image-classification.html#cb121-17"></a></span>
<span id="cb121-18"><a href="image-classification.html#cb121-18"></a>    batch_num &lt;-<span class="st"> </span>batch_num <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb121-19"><a href="image-classification.html#cb121-19"></a>    optimizer<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb121-20"><a href="image-classification.html#cb121-20"></a>    output &lt;-<span class="st"> </span><span class="kw">model</span>(b[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cuda&quot;</span>))</span>
<span id="cb121-21"><a href="image-classification.html#cb121-21"></a>    loss &lt;-<span class="st"> </span><span class="kw">criterion</span>(output, b[[<span class="dv">2</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cuda&quot;</span>))</span>
<span id="cb121-22"><a href="image-classification.html#cb121-22"></a></span>
<span id="cb121-23"><a href="image-classification.html#cb121-23"></a>    <span class="co">#Compute the smoothed loss</span></span>
<span id="cb121-24"><a href="image-classification.html#cb121-24"></a>    avg_loss &lt;-<span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>avg_loss <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>beta) <span class="op">*</span><span class="st"> </span>loss<span class="op">$</span><span class="kw">item</span>()</span>
<span id="cb121-25"><a href="image-classification.html#cb121-25"></a>    smoothed_loss &lt;-<span class="st"> </span>avg_loss <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>beta<span class="op">^</span>batch_num)</span>
<span id="cb121-26"><a href="image-classification.html#cb121-26"></a>    <span class="co">#Stop if the loss is exploding</span></span>
<span id="cb121-27"><a href="image-classification.html#cb121-27"></a>    <span class="cf">if</span> (batch_num <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;&amp;</span><span class="st"> </span>smoothed_loss <span class="op">&gt;</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>best_loss) <span class="cf">break</span></span>
<span id="cb121-28"><a href="image-classification.html#cb121-28"></a>    <span class="co">#Record the best loss</span></span>
<span id="cb121-29"><a href="image-classification.html#cb121-29"></a>    <span class="cf">if</span> (smoothed_loss <span class="op">&lt;</span><span class="st"> </span>best_loss <span class="op">||</span><span class="st"> </span>batch_num <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) best_loss &lt;-<span class="st"> </span>smoothed_loss</span>
<span id="cb121-30"><a href="image-classification.html#cb121-30"></a></span>
<span id="cb121-31"><a href="image-classification.html#cb121-31"></a>    <span class="co">#Store the values</span></span>
<span id="cb121-32"><a href="image-classification.html#cb121-32"></a>    losses &lt;-<span class="st"> </span><span class="kw">c</span>(losses, smoothed_loss)</span>
<span id="cb121-33"><a href="image-classification.html#cb121-33"></a>    log_lrs &lt;-<span class="st"> </span><span class="kw">c</span>(log_lrs, (<span class="kw">log</span>(lr, <span class="dv">10</span>)))</span>
<span id="cb121-34"><a href="image-classification.html#cb121-34"></a></span>
<span id="cb121-35"><a href="image-classification.html#cb121-35"></a>    loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb121-36"><a href="image-classification.html#cb121-36"></a>    optimizer<span class="op">$</span><span class="kw">step</span>()</span>
<span id="cb121-37"><a href="image-classification.html#cb121-37"></a></span>
<span id="cb121-38"><a href="image-classification.html#cb121-38"></a>    <span class="co">#Update the lr for the next step</span></span>
<span id="cb121-39"><a href="image-classification.html#cb121-39"></a>    lr &lt;-<span class="st"> </span>lr <span class="op">*</span><span class="st"> </span>mult</span>
<span id="cb121-40"><a href="image-classification.html#cb121-40"></a>    optimizer<span class="op">$</span>param_groups[[<span class="dv">1</span>]]<span class="op">$</span>lr &lt;-<span class="st"> </span>lr</span>
<span id="cb121-41"><a href="image-classification.html#cb121-41"></a>  }</span>
<span id="cb121-42"><a href="image-classification.html#cb121-42"></a>}</span>
<span id="cb121-43"><a href="image-classification.html#cb121-43"></a></span>
<span id="cb121-44"><a href="image-classification.html#cb121-44"></a><span class="kw">find_lr</span>()</span></code></pre></div>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="image-classification.html#cb122-1"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">log_lrs =</span> log_lrs, <span class="dt">losses =</span> losses)</span>
<span id="cb122-2"><a href="image-classification.html#cb122-2"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb122-3"><a href="image-classification.html#cb122-3"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(log_lrs, losses)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>The best learning rate is not the exact one where loss is at a minimum, instead, it should be picked somewhat earlier on the curve, while loss still decreases. We’ll try 0.05 here.</p>
<p><code>OneCycleLR</code> will then vary the learning rate continuously, performing just a single ramp-up and a single ramp-down over the whole training period:</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="image-classification.html#cb123-1"></a>num_epochs =<span class="st"> </span><span class="dv">10</span></span>
<span id="cb123-2"><a href="image-classification.html#cb123-2"></a><span class="co"># </span><span class="al">TBD</span></span>
<span id="cb123-3"><a href="image-classification.html#cb123-3"></a>lr_scheduler =<span class="st"> </span><span class="kw">torch.optim.lr_scheduler.OneCycleLR</span>(optimizer, <span class="dt">max_lr =</span> <span class="fl">0.05</span>, <span class="dt">epochs =</span> num_epochs, <span class="dt">steps_per_epoch=</span><span class="kw">len</span>(dataloaders[<span class="st">&#39;train&#39;</span>]))</span></code></pre></div>
<p>Now we train for ten epochs. Every epoch, we iterate over both training and validation sets, performing optimization on the training set while just calculating accuracy on the test set. Note that <code>lr_scheduler$step()</code> has to be called explicitly after each batch, and it has to be called <em>after</em> <code>optimizer$step()</code>.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="image-classification.html#cb124-1"></a><span class="cf">for</span> (epoch <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>num_epochs) {</span>
<span id="cb124-2"><a href="image-classification.html#cb124-2"></a></span>
<span id="cb124-3"><a href="image-classification.html#cb124-3"></a>  model<span class="op">$</span><span class="kw">train</span>()</span>
<span id="cb124-4"><a href="image-classification.html#cb124-4"></a>  train_losses &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb124-5"><a href="image-classification.html#cb124-5"></a></span>
<span id="cb124-6"><a href="image-classification.html#cb124-6"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="kw">enumerate</span>(train_dl)) {</span>
<span id="cb124-7"><a href="image-classification.html#cb124-7"></a>    optimizer<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb124-8"><a href="image-classification.html#cb124-8"></a>    output &lt;-<span class="st"> </span><span class="kw">model</span>(b[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cuda&quot;</span>))</span>
<span id="cb124-9"><a href="image-classification.html#cb124-9"></a>    loss &lt;-<span class="st"> </span><span class="kw">criterion</span>(output, b[[<span class="dv">2</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cuda&quot;</span>))</span>
<span id="cb124-10"><a href="image-classification.html#cb124-10"></a>    loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb124-11"><a href="image-classification.html#cb124-11"></a>    optimizer<span class="op">$</span><span class="kw">step</span>()</span>
<span id="cb124-12"><a href="image-classification.html#cb124-12"></a>    <span class="co"># tbd</span></span>
<span id="cb124-13"><a href="image-classification.html#cb124-13"></a>    scheduler<span class="op">$</span><span class="kw">step</span>()</span>
<span id="cb124-14"><a href="image-classification.html#cb124-14"></a>    train_losses &lt;-<span class="st"> </span><span class="kw">c</span>(train_losses, loss<span class="op">$</span><span class="kw">item</span>())</span>
<span id="cb124-15"><a href="image-classification.html#cb124-15"></a>    <span class="kw">print</span>(loss)</span>
<span id="cb124-16"><a href="image-classification.html#cb124-16"></a>  }</span>
<span id="cb124-17"><a href="image-classification.html#cb124-17"></a></span>
<span id="cb124-18"><a href="image-classification.html#cb124-18"></a>  model<span class="op">$</span><span class="kw">eval</span>()</span>
<span id="cb124-19"><a href="image-classification.html#cb124-19"></a>  valid_losses &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb124-20"><a href="image-classification.html#cb124-20"></a></span>
<span id="cb124-21"><a href="image-classification.html#cb124-21"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="kw">enumerate</span>(valid_dl)) {</span>
<span id="cb124-22"><a href="image-classification.html#cb124-22"></a>    output &lt;-<span class="st"> </span><span class="kw">model</span>(b[[<span class="dv">1</span>]])</span>
<span id="cb124-23"><a href="image-classification.html#cb124-23"></a>    loss &lt;-<span class="st"> </span><span class="kw">criterion</span>(output, b[[<span class="dv">2</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cuda&quot;</span>))</span>
<span id="cb124-24"><a href="image-classification.html#cb124-24"></a>    valid_losses &lt;-<span class="st"> </span><span class="kw">c</span>(valid_losses, loss<span class="op">$</span><span class="kw">item</span>())</span>
<span id="cb124-25"><a href="image-classification.html#cb124-25"></a>  }</span>
<span id="cb124-26"><a href="image-classification.html#cb124-26"></a></span>
<span id="cb124-27"><a href="image-classification.html#cb124-27"></a>  <span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">&quot;Loss at epoch %d: training: %3f, validation: %3f</span><span class="ch">\n</span><span class="st">&quot;</span>, epoch, <span class="kw">mean</span>(train_losses), <span class="kw">mean</span>(valid_losses)))</span>
<span id="cb124-28"><a href="image-classification.html#cb124-28"></a>}</span></code></pre></div>
</div>
<div id="performance-on-the-test-set" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Performance on the test set</h2>
<p>Finally, we calculate accuracy on the test set:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="image-classification.html#cb125-1"></a>model<span class="op">$</span><span class="kw">eval</span>()</span>
<span id="cb125-2"><a href="image-classification.html#cb125-2"></a></span>
<span id="cb125-3"><a href="image-classification.html#cb125-3"></a>test_losses &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb125-4"><a href="image-classification.html#cb125-4"></a>total &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb125-5"><a href="image-classification.html#cb125-5"></a>correct &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb125-6"><a href="image-classification.html#cb125-6"></a></span>
<span id="cb125-7"><a href="image-classification.html#cb125-7"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="kw">enumerate</span>(test_dl)) {</span>
<span id="cb125-8"><a href="image-classification.html#cb125-8"></a>  output &lt;-<span class="st"> </span><span class="kw">model</span>(b[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cuda&quot;</span>))</span>
<span id="cb125-9"><a href="image-classification.html#cb125-9"></a>  labels &lt;-<span class="st"> </span>b[[<span class="dv">2</span>]]<span class="op">$</span><span class="kw">to</span>(<span class="dt">device =</span> <span class="st">&quot;cuda&quot;</span>)</span>
<span id="cb125-10"><a href="image-classification.html#cb125-10"></a>  loss &lt;-<span class="st"> </span><span class="kw">criterion</span>(output, labels)</span>
<span id="cb125-11"><a href="image-classification.html#cb125-11"></a>  test_losses &lt;-<span class="st"> </span><span class="kw">c</span>(test_losses, loss<span class="op">$</span><span class="kw">item</span>())</span>
<span id="cb125-12"><a href="image-classification.html#cb125-12"></a>  <span class="co"># torch_max returns a list, with position 1 containing the values</span></span>
<span id="cb125-13"><a href="image-classification.html#cb125-13"></a>  <span class="co"># and position 2 containing the respective indices</span></span>
<span id="cb125-14"><a href="image-classification.html#cb125-14"></a>  predicted &lt;-<span class="st"> </span><span class="kw">torch_max</span>(output<span class="op">$</span><span class="kw">data</span>(), <span class="dt">dim =</span> <span class="dv">2</span>)[[<span class="dv">2</span>]]</span>
<span id="cb125-15"><a href="image-classification.html#cb125-15"></a>  total &lt;-<span class="st"> </span>total <span class="op">+</span><span class="st"> </span>labels<span class="op">$</span><span class="kw">size</span>(<span class="dv">1</span>)</span>
<span id="cb125-16"><a href="image-classification.html#cb125-16"></a>  <span class="co"># add number of correct classifications in this batch to the aggregate</span></span>
<span id="cb125-17"><a href="image-classification.html#cb125-17"></a>  correct &lt;-<span class="st"> </span>correct <span class="op">+</span><span class="st"> </span>(predicted <span class="op">==</span><span class="st"> </span>labels)<span class="op">$</span><span class="kw">sum</span>()<span class="op">$</span><span class="kw">item</span>()</span>
<span id="cb125-18"><a href="image-classification.html#cb125-18"></a>}</span>
<span id="cb125-19"><a href="image-classification.html#cb125-19"></a></span>
<span id="cb125-20"><a href="image-classification.html#cb125-20"></a><span class="kw">mean</span>(test_losses)</span></code></pre></div>
<pre><code>tbd</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="image-classification.html#cb127-1"></a>test_accuracy &lt;-<span class="st">  </span>correct<span class="op">/</span>total</span>
<span id="cb127-2"><a href="image-classification.html#cb127-2"></a>test_accuracy</span></code></pre></div>
<pre><code>tbd</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-LoshchilovH16a">
<p>Loshchilov, Ilya, and Frank Hutter. 2016. “SGDR: Stochastic Gradient Descent with Restarts.” <em>CoRR</em> abs/1608.03983. <a href="http://arxiv.org/abs/1608.03983">http://arxiv.org/abs/1608.03983</a>.</p>
</div>
<div id="ref-Smith15a">
<p>Smith, Leslie N. 2015. “No More Pesky Learning Rate Guessing Games.” <em>CoRR</em> abs/1506.01186. <a href="http://arxiv.org/abs/1506.01186">http://arxiv.org/abs/1506.01186</a>.</p>
</div>
<div id="ref-abs-1708-07120">
<p>Smith, Leslie N., and Nicholay Topin. 2017. “Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates.” <em>CoRR</em> abs/1708.07120. <a href="http://arxiv.org/abs/1708.07120">http://arxiv.org/abs/1708.07120</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="image-recognition-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="unet.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
