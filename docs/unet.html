<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8 Brain Image Segmentation with U-Net | Applied deep learning with torch from R</title>
  <meta name="description" content="tbd" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="8 Brain Image Segmentation with U-Net | Applied deep learning with torch from R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="tbd" />
  <meta property="og:image" content="tbdcover.png" />
  <meta property="og:description" content="tbd" />
  <meta name="github-repo" content="tbd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Brain Image Segmentation with U-Net | Applied deep learning with torch from R" />
  
  <meta name="twitter:description" content="tbd" />
  <meta name="twitter:image" content="tbdcover.png" />

<meta name="author" content="tbd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="image-classification.html"/>
<link rel="next" href="NLP-intro.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>I Using Torch</b></span></li>
<li class="chapter" data-level="" data-path="using-torch-intro.html"><a href="using-torch-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="2" data-path="simple-net-R.html"><a href="simple-net-R.html"><i class="fa fa-check"></i><b>2</b> A simple neural network in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#whats-in-a-network"><i class="fa fa-check"></i><b>2.1</b> What’s in a network?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="simple-net-R.html"><a href="simple-net-R.html#gradient-descent"><i class="fa fa-check"></i><b>2.1.1</b> Gradient descent</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-net-R.html"><a href="simple-net-R.html#from-linear-regression-to-a-simple-network"><i class="fa fa-check"></i><b>2.1.2</b> From linear regression to a simple network</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#a-simple-network"><i class="fa fa-check"></i><b>2.2</b> A simple network</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#simulate-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulate data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#initialize-weights-and-biases"><i class="fa fa-check"></i><b>2.2.2</b> Initialize weights and biases</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>2.2.3</b> Training loop</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-net-R.html"><a href="simple-net-R.html#complete-code"><i class="fa fa-check"></i><b>2.2.4</b> Complete code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>2.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html"><i class="fa fa-check"></i><b>3</b> Modifying the simple network to use torch tensors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#simple-network-torchified-step-1"><i class="fa fa-check"></i><b>3.1</b> Simple network torchified, step 1</a></li>
<li class="chapter" data-level="3.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#more-on-tensors"><i class="fa fa-check"></i><b>3.2</b> More on tensors</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#creating-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Creating tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#conversion-between-torch-tensors-and-r-values"><i class="fa fa-check"></i><b>3.2.2</b> Conversion between <code>torch</code> tensors and R values</a></li>
<li class="chapter" data-level="3.2.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#indexing-and-slicing-tensors"><i class="fa fa-check"></i><b>3.2.3</b> Indexing and slicing tensors</a></li>
<li class="chapter" data-level="3.2.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#reshaping-tensors"><i class="fa fa-check"></i><b>3.2.4</b> Reshaping tensors</a></li>
<li class="chapter" data-level="3.2.5" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#operations-on-tensors"><i class="fa fa-check"></i><b>3.2.5</b> Operations on tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#broadcasting"><i class="fa fa-check"></i><b>3.3</b> Broadcasting</a></li>
<li class="chapter" data-level="3.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#running-on-gpu"><i class="fa fa-check"></i><b>3.4</b> Running on GPU</a></li>
<li class="chapter" data-level="3.5" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>3.5</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html"><i class="fa fa-check"></i><b>4</b> Using autograd</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#automatic-differentiation-with-autograd"><i class="fa fa-check"></i><b>4.1</b> Automatic differentiation with autograd</a></li>
<li class="chapter" data-level="4.2" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#the-simple-network-now-using-autograd"><i class="fa fa-check"></i><b>4.2</b> The simple network, now using autograd</a></li>
<li class="chapter" data-level="4.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>4.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-net-modules.html"><a href="simple-net-modules.html"><i class="fa fa-check"></i><b>5</b> Using torch modules</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#modules"><i class="fa fa-check"></i><b>5.1</b> Modules</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#layers-as-modules"><i class="fa fa-check"></i><b>5.1.1</b> Layers as modules</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#models-as-modules"><i class="fa fa-check"></i><b>5.1.2</b> Models as modules</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#simple-network-using-modules"><i class="fa fa-check"></i><b>5.2</b> Simple network using modules</a></li>
<li class="chapter" data-level="5.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>5.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-net-optim.html"><a href="simple-net-optim.html"><i class="fa fa-check"></i><b>6</b> Using <code>torch</code> optimizers</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple-net-optim.html"><a href="simple-net-optim.html#torch-optimizers"><i class="fa fa-check"></i><b>6.1</b> Torch optimizers</a></li>
<li class="chapter" data-level="6.2" data-path="simple-net-optim.html"><a href="simple-net-optim.html#simple-net-with-optim"><i class="fa fa-check"></i><b>6.2</b> Simple net with <code>optim</code></a></li>
<li class="chapter" data-level="6.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>6.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="part"><span><b>II Image Recognition</b></span></li>
<li class="chapter" data-level="" data-path="image-recognition-intro.html"><a href="image-recognition-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="7" data-path="image-classification.html"><a href="image-classification.html"><i class="fa fa-check"></i><b>7</b> Classifying images</a>
<ul>
<li class="chapter" data-level="7.1" data-path="image-classification.html"><a href="image-classification.html#data-loading-and-transformation"><i class="fa fa-check"></i><b>7.1</b> Data loading and transformation</a></li>
<li class="chapter" data-level="7.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>7.2</b> Model</a></li>
<li class="chapter" data-level="7.3" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>7.3</b> Training</a></li>
<li class="chapter" data-level="7.4" data-path="image-classification.html"><a href="image-classification.html#performance-on-the-test-set"><i class="fa fa-check"></i><b>7.4</b> Performance on the test set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unet.html"><a href="unet.html"><i class="fa fa-check"></i><b>8</b> Brain Image Segmentation with U-Net</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unet.html"><a href="unet.html#image-segmentation-in-a-nutshell"><i class="fa fa-check"></i><b>8.1</b> Image segmentation in a nutshell</a></li>
<li class="chapter" data-level="8.2" data-path="unet.html"><a href="unet.html#u-net"><i class="fa fa-check"></i><b>8.2</b> U-Net</a></li>
<li class="chapter" data-level="8.3" data-path="unet.html"><a href="unet.html#example-application-mri-images"><i class="fa fa-check"></i><b>8.3</b> Example application: MRI images</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="unet.html"><a href="unet.html#preprocessing"><i class="fa fa-check"></i><b>8.3.1</b> Preprocessing</a></li>
<li class="chapter" data-level="8.3.2" data-path="unet.html"><a href="unet.html#u-net-model"><i class="fa fa-check"></i><b>8.3.2</b> U-Net model</a></li>
<li class="chapter" data-level="8.3.3" data-path="unet.html"><a href="unet.html#loss"><i class="fa fa-check"></i><b>8.3.3</b> Loss</a></li>
<li class="chapter" data-level="8.3.4" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>8.3.4</b> Training</a></li>
<li class="chapter" data-level="8.3.5" data-path="unet.html"><a href="unet.html#predictions"><i class="fa fa-check"></i><b>8.3.5</b> Predictions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Natural language processing</b></span></li>
<li class="chapter" data-level="" data-path="NLP-intro.html"><a href="NLP-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="9" data-path="seq2seq-att.html"><a href="seq2seq-att.html"><i class="fa fa-check"></i><b>9</b> Sequence-to-sequence models with attention</a>
<ul>
<li class="chapter" data-level="9.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#why-attention"><i class="fa fa-check"></i><b>9.1</b> Why attention?</a></li>
<li class="chapter" data-level="9.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#preprocessing-with-torchtext"><i class="fa fa-check"></i><b>9.2</b> Preprocessing with <code>torchtext</code></a></li>
<li class="chapter" data-level="9.3" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>9.3</b> Model</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>9.3.1</b> Encoder</a></li>
<li class="chapter" data-level="9.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#attention-module"><i class="fa fa-check"></i><b>9.3.2</b> Attention module</a></li>
<li class="chapter" data-level="9.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>9.3.3</b> Decoder</a></li>
<li class="chapter" data-level="9.3.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#seq2seq-module"><i class="fa fa-check"></i><b>9.3.4</b> Seq2seq module</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#training-and-evaluation"><i class="fa fa-check"></i><b>9.4</b> Training and evaluation</a></li>
<li class="chapter" data-level="9.5" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>9.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="transformer.html"><a href="transformer.html"><i class="fa fa-check"></i><b>10</b> Torch transformer modules</a>
<ul>
<li class="chapter" data-level="10.1" data-path="transformer.html"><a href="transformer.html#attention-is-all-you-need"><i class="fa fa-check"></i><b>10.1</b> “Attention is all you need”</a></li>
<li class="chapter" data-level="10.2" data-path="transformer.html"><a href="transformer.html#implementation-building-blocks"><i class="fa fa-check"></i><b>10.2</b> Implementation: building blocks</a></li>
<li class="chapter" data-level="10.3" data-path="transformer.html"><a href="transformer.html#a-transformer-for-natural-language-translation"><i class="fa fa-check"></i><b>10.3</b> A Transformer for natural language translation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="transformer.html"><a href="transformer.html#load-data"><i class="fa fa-check"></i><b>10.3.1</b> Load data</a></li>
<li class="chapter" data-level="10.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>10.3.2</b> Encoder</a></li>
<li class="chapter" data-level="10.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>10.3.3</b> Decoder</a></li>
<li class="chapter" data-level="10.3.4" data-path="transformer.html"><a href="transformer.html#overall-model"><i class="fa fa-check"></i><b>10.3.4</b> Overall model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
</ul></li>
<li class="part"><span><b>IV Deep learning for tabular data</b></span></li>
<li class="chapter" data-level="" data-path="tabular-intro.html"><a href="tabular-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V Time series</b></span></li>
<li class="chapter" data-level="" data-path="timeseries-intro.html"><a href="timeseries-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VI Generative deep learning</b></span></li>
<li class="chapter" data-level="" data-path="generative-intro.html"><a href="generative-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="11" data-path="gans.html"><a href="gans.html"><i class="fa fa-check"></i><b>11</b> Generative adversarial networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>11.1</b> Dataset</a></li>
<li class="chapter" data-level="11.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>11.2</b> Model</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="gans.html"><a href="gans.html#generator"><i class="fa fa-check"></i><b>11.2.1</b> Generator</a></li>
<li class="chapter" data-level="11.2.2" data-path="gans.html"><a href="gans.html#discriminator"><i class="fa fa-check"></i><b>11.2.2</b> Discriminator</a></li>
<li class="chapter" data-level="11.2.3" data-path="gans.html"><a href="gans.html#optimizers-and-loss-function"><i class="fa fa-check"></i><b>11.2.3</b> Optimizers and loss function</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>11.3</b> Training loop</a></li>
<li class="chapter" data-level="11.4" data-path="gans.html"><a href="gans.html#artifacts"><i class="fa fa-check"></i><b>11.4</b> Artifacts</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="vaes.html"><a href="vaes.html"><i class="fa fa-check"></i><b>12</b> Variational autoencoders</a>
<ul>
<li class="chapter" data-level="12.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>12.1</b> Dataset</a></li>
<li class="chapter" data-level="12.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>12.2</b> Model</a></li>
<li class="chapter" data-level="12.3" data-path="vaes.html"><a href="vaes.html#training-the-vae"><i class="fa fa-check"></i><b>12.3</b> Training the VAE</a></li>
<li class="chapter" data-level="12.4" data-path="vaes.html"><a href="vaes.html#latent-space"><i class="fa fa-check"></i><b>12.4</b> Latent space</a></li>
</ul></li>
<li class="part"><span><b>VII Deep learning on graphs</b></span></li>
<li class="chapter" data-level="" data-path="graph-intro.html"><a href="graph-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VIII Probabilistic deep learning</b></span></li>
<li class="chapter" data-level="" data-path="probabilistic-intro.html"><a href="probabilistic-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>IX Private and secure deep learning</b></span></li>
<li class="chapter" data-level="" data-path="private-secure-intro.html"><a href="private-secure-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>X Research topics</b></span></li>
<li class="chapter" data-level="" data-path="research-intro.html"><a href="research-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied deep learning with torch from R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="unet" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Brain Image Segmentation with U-Net</h1>
<div id="image-segmentation-in-a-nutshell" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Image segmentation in a nutshell</h2>
<p>Now that we’ve seen how to <em>classify</em> images – as of this writing, probably the “Hello World” of deep learning – we proceed
to a type of application vastly important in practice, especially in medicine, biology, geology and other natural sciences. In
image <em>segmentation</em>, we’re not interested in labeling the entire image; instead, we want to classify every pixel (2-d) or
voxel (3-d) according to some criterion.</p>
<p>In medicine, for example, we might want to detect different cell types, or identify tumors or lesions. The decision could be
two-way – tumor cell yes or no? –, or there could be some higher number of classes to discern. To train a supervised model,
ground truth data needs to be present. In these tasks, the ground truth comes in form of a <em>mask</em>: an image, of same spatial
dimension as the target data, that designates the true classes. Loss values are calculated for every pixel (voxel) separately,
and summed up to yield an aggregate that can be minimized.</p>
</div>
<div id="u-net" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> U-Net</h2>
<p>Here is the “canonical U-Net architecture”, as depicted in the original Rönneberger et al. paper <span class="citation">(Ronneberger, Fischer, and Brox <a href="#ref-RonnebergerFB15" role="doc-biblioref">2015</a>)</span>. In
different realizations, layer sizes, activations, ways to achieve downsizing and upsizing will vary, but there is one defining
characteristic: The U-shape (clearly visible below), enriched by the “bridges” crossing over horizontally at all levels.</p>
<p><img src="images/unet.png" title="The original U-Net, as depicted in Ronnerberger et al. (2015)." /></p>
<p>In a nutshell, the left-hand side of the U is like a simple convnet used to classify images; the input is successively
downsized spatially but at the same time, another dimension – the <em>channels</em> dimension – is used to successively encode a
hierarchy of features, ranging from very basic and universal to very specialized. As the output, however, should have the same
spatial resolution as the input, we need to upsize again – this is taken care of by the right-hand side of the U. But, how
are we going to arrive at a good <em>per-pixel</em> classification if so much spatial information is lost on the way? This is what
the “bridges” are for: At each depth, the input to an upsampling layer is a <em>concatenation</em> of the previous layer’s output –
which went through the whole spatially-compress-and-decompress routine – and some preserved intermediate representation from
the “way down”. Like that, a U-Net architecture combines attention to detail with feature extraction.</p>
<p>In fact, this architecture, seen as a generic strategy, has been seen in many other places since its original appearance, and
itself is flexible enough to incorporate strategies from other architectures, such as, for exmple, ResNet blocks.</p>
</div>
<div id="example-application-mri-images" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Example application: MRI images</h2>
<p>Just as the architecture is flexible, applicability is broad. Our example will be about detecting abnormalities in brain
scans. The dataset, used in <span class="citation">(Buda, Saha, and Mazurowski <a href="#ref-BUDA2019218" role="doc-biblioref">2019</a>)</span>, contains MR images together with manual
<a href="https://en.wikipedia.org/wiki/Fluid-attenuated_inversion_recovery">FLAIR</a> abnormality segmentation masks. The dataset is
available on <a href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation">Kaggle</a>, and the paper is accompanied by a <a href="https://github.com/mateuszbuda/brain-segmentation-pytorch">GitHub
repository</a> that thankfully, includes all preprocessing steps.
While our model below will be more customizable and generic than the authors’, we completely follow their preprocessing
routines for the MRI data (basically just porting their Python code to R).</p>
<p>If you’re interested in this area of application, please consult the paper for background and additional information. If, on
the other hand, you’re mainly interested in the model, and plan to apply it to other types of data, feel free to just skim the
extensive preprocessing code, and focus on the architecture instead.</p>
<p>As will often be the case in medical imaging applications, there is a class imbalance in this data. For every patient,
sections have been taken at multiple positions (the number of sections per patient varies). Most sections will not have any
lesions, so the masks will be coloured black everywhere.</p>
<p>Here are three examples of orientations where the masks actually indicate an abnormality:</p>
<p><img src="images/scans.png" title="Examples of FLAIR images and corresponding masks" /></p>
<div class="sourceCode" id="cb129"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb129-1"><a href="unet.html#cb129-1"></a><span class="ex">montage</span> TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_15.tif  TCGA_DU_5871_19941206/TCGA_DU_5871_19941206_25.tif TCGA_FG_6689_20020326/TCGA_FG_6689_20020326_25.tif TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_15_mask.tif  TCGA_DU_5871_19941206/TCGA_DU_5871_19941206_25_mask.tif TCGA_FG_6689_20020326/TCGA_FG_6689_20020326_25_mask.tif -tile 3x3 -geometry +5+5 scans.tif</span></code></pre></div>
<div id="preprocessing" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Preprocessing</h3>
<div class="sourceCode" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="unet.html#cb130-1"></a><span class="im">import</span> torch</span>
<span id="cb130-2"><a href="unet.html#cb130-2"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb130-3"><a href="unet.html#cb130-3"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb130-4"><a href="unet.html#cb130-4"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb130-5"><a href="unet.html#cb130-5"></a></span>
<span id="cb130-6"><a href="unet.html#cb130-6"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb130-7"><a href="unet.html#cb130-7"></a><span class="im">import</span> os</span>
<span id="cb130-8"><a href="unet.html#cb130-8"></a><span class="im">import</span> copy</span>
<span id="cb130-9"><a href="unet.html#cb130-9"></a><span class="im">import</span> random</span>
<span id="cb130-10"><a href="unet.html#cb130-10"></a><span class="im">import</span> torchvision</span>
<span id="cb130-11"><a href="unet.html#cb130-11"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, models, transforms</span>
<span id="cb130-12"><a href="unet.html#cb130-12"></a></span>
<span id="cb130-13"><a href="unet.html#cb130-13"></a><span class="im">from</span> skimage.io <span class="im">import</span> imread</span></code></pre></div>
<p>The data comes organized into folders containing FLAIR images and masks for a single patient. We randomly partition these into
a training and a validation set, keeping the latter very small as overall, this dataset is not very big. (You might want to
experiment with different splits or better even, use a cross-validation approach. We don’t do that here as anyway, this
apllication example is pretty extensive already.) “Randomly” here meant we picked (at random) two patients from each
institution, as indicated by the pair of letters second in the folder names (tbd: check this!).</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="unet.html#cb131-1"></a>train_dir <span class="op">=</span> <span class="st">&quot;data/kaggle_3m_train&quot;</span></span>
<span id="cb131-2"><a href="unet.html#cb131-2"></a>valid_dir <span class="op">=</span> <span class="st">&quot;data/kaggle_3m_valid&quot;</span></span></code></pre></div>
<p>Preprocessing will be encapsulated in a <code>dataset</code> , that is, a structure that <code>torch</code> knows how to handle. Before we look at
that structure, let’s quickly look at helper functions and components it will make use of. As indicated above, these, as well
as <code>BrainSegmentationDataset</code> itself, are direct ports of the Python preprocessing logic in <a href="https://github.com/mateuszbuda/brain-segmentation-pytorch">Mateusz Buda’s GitHub
repository</a>.</p>
<div id="image-preprocessing-and-transforms" class="section level4" number="8.3.1.1">
<h4><span class="header-section-number">8.3.1.1</span> Image preprocessing and transforms</h4>
<p>Both FLAIR images and masks come in <code>.tif</code> format. These images have to be preprocessed spatially (cropped, padded and
resized), as well as normalized. The following functions will be called inside <code>BrainSegmentationDataset</code>:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="unet.html#cb132-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb132-2"><a href="unet.html#cb132-2"></a><span class="im">from</span> medpy.<span class="bu">filter</span>.binary <span class="im">import</span> largest_connected_component</span>
<span id="cb132-3"><a href="unet.html#cb132-3"></a><span class="im">from</span> skimage.exposure <span class="im">import</span> rescale_intensity</span>
<span id="cb132-4"><a href="unet.html#cb132-4"></a><span class="im">from</span> skimage.transform <span class="im">import</span> resize</span>
<span id="cb132-5"><a href="unet.html#cb132-5"></a></span>
<span id="cb132-6"><a href="unet.html#cb132-6"></a><span class="kw">def</span> crop_sample(x):</span>
<span id="cb132-7"><a href="unet.html#cb132-7"></a>    volume, mask <span class="op">=</span> x</span>
<span id="cb132-8"><a href="unet.html#cb132-8"></a>    volume[volume <span class="op">&lt;</span> np.<span class="bu">max</span>(volume) <span class="op">*</span> <span class="fl">0.1</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb132-9"><a href="unet.html#cb132-9"></a>    z_projection <span class="op">=</span> np.<span class="bu">max</span>(np.<span class="bu">max</span>(np.<span class="bu">max</span>(volume, axis<span class="op">=-</span><span class="dv">1</span>), axis<span class="op">=-</span><span class="dv">1</span>), axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb132-10"><a href="unet.html#cb132-10"></a>    z_nonzero <span class="op">=</span> np.nonzero(z_projection)</span>
<span id="cb132-11"><a href="unet.html#cb132-11"></a>    z_min <span class="op">=</span> np.<span class="bu">min</span>(z_nonzero)</span>
<span id="cb132-12"><a href="unet.html#cb132-12"></a>    z_max <span class="op">=</span> np.<span class="bu">max</span>(z_nonzero) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb132-13"><a href="unet.html#cb132-13"></a>    y_projection <span class="op">=</span> np.<span class="bu">max</span>(np.<span class="bu">max</span>(np.<span class="bu">max</span>(volume, axis<span class="op">=</span><span class="dv">0</span>), axis<span class="op">=-</span><span class="dv">1</span>), axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb132-14"><a href="unet.html#cb132-14"></a>    y_nonzero <span class="op">=</span> np.nonzero(y_projection)</span>
<span id="cb132-15"><a href="unet.html#cb132-15"></a>    y_min <span class="op">=</span> np.<span class="bu">min</span>(y_nonzero)</span>
<span id="cb132-16"><a href="unet.html#cb132-16"></a>    y_max <span class="op">=</span> np.<span class="bu">max</span>(y_nonzero) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb132-17"><a href="unet.html#cb132-17"></a>    x_projection <span class="op">=</span> np.<span class="bu">max</span>(np.<span class="bu">max</span>(np.<span class="bu">max</span>(volume, axis<span class="op">=</span><span class="dv">0</span>), axis<span class="op">=</span><span class="dv">0</span>), axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb132-18"><a href="unet.html#cb132-18"></a>    x_nonzero <span class="op">=</span> np.nonzero(x_projection)</span>
<span id="cb132-19"><a href="unet.html#cb132-19"></a>    x_min <span class="op">=</span> np.<span class="bu">min</span>(x_nonzero)</span>
<span id="cb132-20"><a href="unet.html#cb132-20"></a>    x_max <span class="op">=</span> np.<span class="bu">max</span>(x_nonzero) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb132-21"><a href="unet.html#cb132-21"></a>    <span class="cf">return</span> (</span>
<span id="cb132-22"><a href="unet.html#cb132-22"></a>        volume[z_min:z_max, y_min:y_max, x_min:x_max],</span>
<span id="cb132-23"><a href="unet.html#cb132-23"></a>        mask[z_min:z_max, y_min:y_max, x_min:x_max],</span>
<span id="cb132-24"><a href="unet.html#cb132-24"></a>    )</span>
<span id="cb132-25"><a href="unet.html#cb132-25"></a></span>
<span id="cb132-26"><a href="unet.html#cb132-26"></a></span>
<span id="cb132-27"><a href="unet.html#cb132-27"></a><span class="kw">def</span> pad_sample(x):</span>
<span id="cb132-28"><a href="unet.html#cb132-28"></a>    volume, mask <span class="op">=</span> x</span>
<span id="cb132-29"><a href="unet.html#cb132-29"></a>    a <span class="op">=</span> volume.shape[<span class="dv">1</span>]</span>
<span id="cb132-30"><a href="unet.html#cb132-30"></a>    b <span class="op">=</span> volume.shape[<span class="dv">2</span>]</span>
<span id="cb132-31"><a href="unet.html#cb132-31"></a>    <span class="cf">if</span> a <span class="op">==</span> b:</span>
<span id="cb132-32"><a href="unet.html#cb132-32"></a>        <span class="cf">return</span> volume, mask</span>
<span id="cb132-33"><a href="unet.html#cb132-33"></a>    diff <span class="op">=</span> (<span class="bu">max</span>(a, b) <span class="op">-</span> <span class="bu">min</span>(a, b)) <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb132-34"><a href="unet.html#cb132-34"></a>    <span class="cf">if</span> a <span class="op">&gt;</span> b:</span>
<span id="cb132-35"><a href="unet.html#cb132-35"></a>        padding <span class="op">=</span> ((<span class="dv">0</span>, <span class="dv">0</span>), (<span class="dv">0</span>, <span class="dv">0</span>), (<span class="bu">int</span>(np.floor(diff)), <span class="bu">int</span>(np.ceil(diff))))</span>
<span id="cb132-36"><a href="unet.html#cb132-36"></a>    <span class="cf">else</span>:</span>
<span id="cb132-37"><a href="unet.html#cb132-37"></a>        padding <span class="op">=</span> ((<span class="dv">0</span>, <span class="dv">0</span>), (<span class="bu">int</span>(np.floor(diff)), <span class="bu">int</span>(np.ceil(diff))), (<span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb132-38"><a href="unet.html#cb132-38"></a>    mask <span class="op">=</span> np.pad(mask, padding, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>, constant_values<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb132-39"><a href="unet.html#cb132-39"></a>    padding <span class="op">=</span> padding <span class="op">+</span> ((<span class="dv">0</span>, <span class="dv">0</span>),)</span>
<span id="cb132-40"><a href="unet.html#cb132-40"></a>    volume <span class="op">=</span> np.pad(volume, padding, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>, constant_values<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb132-41"><a href="unet.html#cb132-41"></a>    <span class="cf">return</span> volume, mask</span>
<span id="cb132-42"><a href="unet.html#cb132-42"></a></span>
<span id="cb132-43"><a href="unet.html#cb132-43"></a></span>
<span id="cb132-44"><a href="unet.html#cb132-44"></a><span class="kw">def</span> resize_sample(x, size<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb132-45"><a href="unet.html#cb132-45"></a>    volume, mask <span class="op">=</span> x</span>
<span id="cb132-46"><a href="unet.html#cb132-46"></a>    v_shape <span class="op">=</span> volume.shape</span>
<span id="cb132-47"><a href="unet.html#cb132-47"></a>    out_shape <span class="op">=</span> (v_shape[<span class="dv">0</span>], size, size)</span>
<span id="cb132-48"><a href="unet.html#cb132-48"></a>    mask <span class="op">=</span> resize(</span>
<span id="cb132-49"><a href="unet.html#cb132-49"></a>        mask,</span>
<span id="cb132-50"><a href="unet.html#cb132-50"></a>        output_shape<span class="op">=</span>out_shape,</span>
<span id="cb132-51"><a href="unet.html#cb132-51"></a>        order<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb132-52"><a href="unet.html#cb132-52"></a>        mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb132-53"><a href="unet.html#cb132-53"></a>        cval<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb132-54"><a href="unet.html#cb132-54"></a>        anti_aliasing<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb132-55"><a href="unet.html#cb132-55"></a>    )</span>
<span id="cb132-56"><a href="unet.html#cb132-56"></a>    out_shape <span class="op">=</span> out_shape <span class="op">+</span> (v_shape[<span class="dv">3</span>],)</span>
<span id="cb132-57"><a href="unet.html#cb132-57"></a>    volume <span class="op">=</span> resize(</span>
<span id="cb132-58"><a href="unet.html#cb132-58"></a>        volume,</span>
<span id="cb132-59"><a href="unet.html#cb132-59"></a>        output_shape<span class="op">=</span>out_shape,</span>
<span id="cb132-60"><a href="unet.html#cb132-60"></a>        order<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb132-61"><a href="unet.html#cb132-61"></a>        mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb132-62"><a href="unet.html#cb132-62"></a>        cval<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb132-63"><a href="unet.html#cb132-63"></a>        anti_aliasing<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb132-64"><a href="unet.html#cb132-64"></a>    )</span>
<span id="cb132-65"><a href="unet.html#cb132-65"></a>    <span class="cf">return</span> volume, mask</span>
<span id="cb132-66"><a href="unet.html#cb132-66"></a></span>
<span id="cb132-67"><a href="unet.html#cb132-67"></a></span>
<span id="cb132-68"><a href="unet.html#cb132-68"></a><span class="kw">def</span> normalize_volume(volume):</span>
<span id="cb132-69"><a href="unet.html#cb132-69"></a>    p10 <span class="op">=</span> np.percentile(volume, <span class="dv">10</span>)</span>
<span id="cb132-70"><a href="unet.html#cb132-70"></a>    p99 <span class="op">=</span> np.percentile(volume, <span class="dv">99</span>)</span>
<span id="cb132-71"><a href="unet.html#cb132-71"></a>    volume <span class="op">=</span> rescale_intensity(volume, in_range<span class="op">=</span>(p10, p99))</span>
<span id="cb132-72"><a href="unet.html#cb132-72"></a>    m <span class="op">=</span> np.mean(volume, axis<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb132-73"><a href="unet.html#cb132-73"></a>    s <span class="op">=</span> np.std(volume, axis<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb132-74"><a href="unet.html#cb132-74"></a>    volume <span class="op">=</span> (volume <span class="op">-</span> m) <span class="op">/</span> s</span>
<span id="cb132-75"><a href="unet.html#cb132-75"></a>    <span class="cf">return</span> volume</span></code></pre></div>
<p>On the training set, we’ll also want to use data augmentation. Here are the relative <code>Transform</code>s:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="unet.html#cb133-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb133-2"><a href="unet.html#cb133-2"></a><span class="im">from</span> skimage.transform <span class="im">import</span> rescale, rotate</span>
<span id="cb133-3"><a href="unet.html#cb133-3"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> Compose</span>
<span id="cb133-4"><a href="unet.html#cb133-4"></a></span>
<span id="cb133-5"><a href="unet.html#cb133-5"></a></span>
<span id="cb133-6"><a href="unet.html#cb133-6"></a><span class="kw">def</span> transforms(scale<span class="op">=</span><span class="va">None</span>, angle<span class="op">=</span><span class="va">None</span>, flip_prob<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb133-7"><a href="unet.html#cb133-7"></a>    transform_list <span class="op">=</span> []</span>
<span id="cb133-8"><a href="unet.html#cb133-8"></a></span>
<span id="cb133-9"><a href="unet.html#cb133-9"></a>    <span class="cf">if</span> scale <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb133-10"><a href="unet.html#cb133-10"></a>        transform_list.append(Scale(scale))</span>
<span id="cb133-11"><a href="unet.html#cb133-11"></a>    <span class="cf">if</span> angle <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb133-12"><a href="unet.html#cb133-12"></a>        transform_list.append(Rotate(angle))</span>
<span id="cb133-13"><a href="unet.html#cb133-13"></a>    <span class="cf">if</span> flip_prob <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb133-14"><a href="unet.html#cb133-14"></a>        transform_list.append(HorizontalFlip(flip_prob))</span>
<span id="cb133-15"><a href="unet.html#cb133-15"></a></span>
<span id="cb133-16"><a href="unet.html#cb133-16"></a>    <span class="cf">return</span> Compose(transform_list)</span>
<span id="cb133-17"><a href="unet.html#cb133-17"></a></span>
<span id="cb133-18"><a href="unet.html#cb133-18"></a></span>
<span id="cb133-19"><a href="unet.html#cb133-19"></a><span class="kw">class</span> Scale(<span class="bu">object</span>):</span>
<span id="cb133-20"><a href="unet.html#cb133-20"></a></span>
<span id="cb133-21"><a href="unet.html#cb133-21"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, scale):</span>
<span id="cb133-22"><a href="unet.html#cb133-22"></a>        <span class="va">self</span>.scale <span class="op">=</span> scale</span>
<span id="cb133-23"><a href="unet.html#cb133-23"></a></span>
<span id="cb133-24"><a href="unet.html#cb133-24"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, sample):</span>
<span id="cb133-25"><a href="unet.html#cb133-25"></a>        image, mask <span class="op">=</span> sample</span>
<span id="cb133-26"><a href="unet.html#cb133-26"></a></span>
<span id="cb133-27"><a href="unet.html#cb133-27"></a>        img_size <span class="op">=</span> image.shape[<span class="dv">0</span>]</span>
<span id="cb133-28"><a href="unet.html#cb133-28"></a></span>
<span id="cb133-29"><a href="unet.html#cb133-29"></a>        scale <span class="op">=</span> np.random.uniform(low<span class="op">=</span><span class="fl">1.0</span> <span class="op">-</span> <span class="va">self</span>.scale, high<span class="op">=</span><span class="fl">1.0</span> <span class="op">+</span> <span class="va">self</span>.scale)</span>
<span id="cb133-30"><a href="unet.html#cb133-30"></a></span>
<span id="cb133-31"><a href="unet.html#cb133-31"></a>        image <span class="op">=</span> rescale(</span>
<span id="cb133-32"><a href="unet.html#cb133-32"></a>            image,</span>
<span id="cb133-33"><a href="unet.html#cb133-33"></a>            (scale, scale),</span>
<span id="cb133-34"><a href="unet.html#cb133-34"></a>            multichannel<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb133-35"><a href="unet.html#cb133-35"></a>            preserve_range<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb133-36"><a href="unet.html#cb133-36"></a>            mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb133-37"><a href="unet.html#cb133-37"></a>            anti_aliasing<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb133-38"><a href="unet.html#cb133-38"></a>        )</span>
<span id="cb133-39"><a href="unet.html#cb133-39"></a>        mask <span class="op">=</span> rescale(</span>
<span id="cb133-40"><a href="unet.html#cb133-40"></a>            mask,</span>
<span id="cb133-41"><a href="unet.html#cb133-41"></a>            (scale, scale),</span>
<span id="cb133-42"><a href="unet.html#cb133-42"></a>            order<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb133-43"><a href="unet.html#cb133-43"></a>            multichannel<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb133-44"><a href="unet.html#cb133-44"></a>            preserve_range<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb133-45"><a href="unet.html#cb133-45"></a>            mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb133-46"><a href="unet.html#cb133-46"></a>            anti_aliasing<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb133-47"><a href="unet.html#cb133-47"></a>        )</span>
<span id="cb133-48"><a href="unet.html#cb133-48"></a></span>
<span id="cb133-49"><a href="unet.html#cb133-49"></a>        <span class="cf">if</span> scale <span class="op">&lt;</span> <span class="fl">1.0</span>:</span>
<span id="cb133-50"><a href="unet.html#cb133-50"></a>            diff <span class="op">=</span> (img_size <span class="op">-</span> image.shape[<span class="dv">0</span>]) <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb133-51"><a href="unet.html#cb133-51"></a>            padding <span class="op">=</span> ((<span class="bu">int</span>(np.floor(diff)), <span class="bu">int</span>(np.ceil(diff))),) <span class="op">*</span> <span class="dv">2</span> <span class="op">+</span> ((<span class="dv">0</span>, <span class="dv">0</span>),)</span>
<span id="cb133-52"><a href="unet.html#cb133-52"></a>            image <span class="op">=</span> np.pad(image, padding, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>, constant_values<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb133-53"><a href="unet.html#cb133-53"></a>            mask <span class="op">=</span> np.pad(mask, padding, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>, constant_values<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb133-54"><a href="unet.html#cb133-54"></a>        <span class="cf">else</span>:</span>
<span id="cb133-55"><a href="unet.html#cb133-55"></a>            x_min <span class="op">=</span> (image.shape[<span class="dv">0</span>] <span class="op">-</span> img_size) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb133-56"><a href="unet.html#cb133-56"></a>            x_max <span class="op">=</span> x_min <span class="op">+</span> img_size</span>
<span id="cb133-57"><a href="unet.html#cb133-57"></a>            image <span class="op">=</span> image[x_min:x_max, x_min:x_max, ...]</span>
<span id="cb133-58"><a href="unet.html#cb133-58"></a>            mask <span class="op">=</span> mask[x_min:x_max, x_min:x_max, ...]</span>
<span id="cb133-59"><a href="unet.html#cb133-59"></a></span>
<span id="cb133-60"><a href="unet.html#cb133-60"></a>        <span class="cf">return</span> image, mask</span>
<span id="cb133-61"><a href="unet.html#cb133-61"></a></span>
<span id="cb133-62"><a href="unet.html#cb133-62"></a></span>
<span id="cb133-63"><a href="unet.html#cb133-63"></a><span class="kw">class</span> Rotate(<span class="bu">object</span>):</span>
<span id="cb133-64"><a href="unet.html#cb133-64"></a></span>
<span id="cb133-65"><a href="unet.html#cb133-65"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, angle):</span>
<span id="cb133-66"><a href="unet.html#cb133-66"></a>        <span class="va">self</span>.angle <span class="op">=</span> angle</span>
<span id="cb133-67"><a href="unet.html#cb133-67"></a></span>
<span id="cb133-68"><a href="unet.html#cb133-68"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, sample):</span>
<span id="cb133-69"><a href="unet.html#cb133-69"></a>        image, mask <span class="op">=</span> sample</span>
<span id="cb133-70"><a href="unet.html#cb133-70"></a></span>
<span id="cb133-71"><a href="unet.html#cb133-71"></a>        angle <span class="op">=</span> np.random.uniform(low<span class="op">=-</span><span class="va">self</span>.angle, high<span class="op">=</span><span class="va">self</span>.angle)</span>
<span id="cb133-72"><a href="unet.html#cb133-72"></a>        image <span class="op">=</span> rotate(image, angle, resize<span class="op">=</span><span class="va">False</span>, preserve_range<span class="op">=</span><span class="va">True</span>, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>)</span>
<span id="cb133-73"><a href="unet.html#cb133-73"></a>        mask <span class="op">=</span> rotate(</span>
<span id="cb133-74"><a href="unet.html#cb133-74"></a>            mask, angle, resize<span class="op">=</span><span class="va">False</span>, order<span class="op">=</span><span class="dv">0</span>, preserve_range<span class="op">=</span><span class="va">True</span>, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span></span>
<span id="cb133-75"><a href="unet.html#cb133-75"></a>        )</span>
<span id="cb133-76"><a href="unet.html#cb133-76"></a>        <span class="cf">return</span> image, mask</span>
<span id="cb133-77"><a href="unet.html#cb133-77"></a></span>
<span id="cb133-78"><a href="unet.html#cb133-78"></a></span>
<span id="cb133-79"><a href="unet.html#cb133-79"></a><span class="kw">class</span> HorizontalFlip(<span class="bu">object</span>):</span>
<span id="cb133-80"><a href="unet.html#cb133-80"></a></span>
<span id="cb133-81"><a href="unet.html#cb133-81"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, flip_prob):</span>
<span id="cb133-82"><a href="unet.html#cb133-82"></a>        <span class="va">self</span>.flip_prob <span class="op">=</span> flip_prob</span>
<span id="cb133-83"><a href="unet.html#cb133-83"></a></span>
<span id="cb133-84"><a href="unet.html#cb133-84"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, sample):</span>
<span id="cb133-85"><a href="unet.html#cb133-85"></a>        image, mask <span class="op">=</span> sample</span>
<span id="cb133-86"><a href="unet.html#cb133-86"></a></span>
<span id="cb133-87"><a href="unet.html#cb133-87"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&gt;</span> <span class="va">self</span>.flip_prob:</span>
<span id="cb133-88"><a href="unet.html#cb133-88"></a>            <span class="cf">return</span> image, mask</span>
<span id="cb133-89"><a href="unet.html#cb133-89"></a></span>
<span id="cb133-90"><a href="unet.html#cb133-90"></a>        image <span class="op">=</span> np.fliplr(image).copy()</span>
<span id="cb133-91"><a href="unet.html#cb133-91"></a>        mask <span class="op">=</span> np.fliplr(mask).copy()</span>
<span id="cb133-92"><a href="unet.html#cb133-92"></a></span>
<span id="cb133-93"><a href="unet.html#cb133-93"></a>        <span class="cf">return</span> image, mask</span></code></pre></div>
</div>
<div id="brainsegmentationdataset" class="section level4" number="8.3.1.2">
<h4><span class="header-section-number">8.3.1.2</span> BrainSegmentationDataset</h4>
<p>The <code>BrainSegmentationDataset</code> walks through a given directory, applies preprocessing and - possibly – transformations, and
returns batches of tensors as requested. Through the <code>init</code> method’s <code>random_sampling</code> parameter, you can control whether
<em>weighted sampling</em> should be applied to counter class imbalance: If set to true, FLAIR-mask pairs will be sampled in
proportion to lesion size. From our experiments, training on this dataset is sped up by using weighted sampling, but final
training performance is not much affected, and neither is performance on the validation set.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb134-1"><a href="unet.html#cb134-1"></a><span class="kw">class</span> BrainSegmentationDataset(Dataset):</span>
<span id="cb134-2"><a href="unet.html#cb134-2"></a>    <span class="co">&quot;&quot;&quot;Brain MRI dataset for FLAIR abnormality segmentation&quot;&quot;&quot;</span></span>
<span id="cb134-3"><a href="unet.html#cb134-3"></a>    in_channels <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb134-4"><a href="unet.html#cb134-4"></a>    out_channels <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb134-5"><a href="unet.html#cb134-5"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb134-6"><a href="unet.html#cb134-6"></a>        <span class="va">self</span>,</span>
<span id="cb134-7"><a href="unet.html#cb134-7"></a>        images_dir,</span>
<span id="cb134-8"><a href="unet.html#cb134-8"></a>        transform <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb134-9"><a href="unet.html#cb134-9"></a>        image_size <span class="op">=</span> <span class="dv">256</span>,</span>
<span id="cb134-10"><a href="unet.html#cb134-10"></a>        random_sampling <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb134-11"><a href="unet.html#cb134-11"></a>    ):</span>
<span id="cb134-12"><a href="unet.html#cb134-12"></a>        volumes <span class="op">=</span> {}</span>
<span id="cb134-13"><a href="unet.html#cb134-13"></a>        masks <span class="op">=</span> {}</span>
<span id="cb134-14"><a href="unet.html#cb134-14"></a>        <span class="bu">print</span>(<span class="st">&quot;reading images...&quot;</span>)</span>
<span id="cb134-15"><a href="unet.html#cb134-15"></a>        <span class="cf">for</span> (dirpath, dirnames, filenames) <span class="kw">in</span> os.walk(images_dir):</span>
<span id="cb134-16"><a href="unet.html#cb134-16"></a>            image_slices <span class="op">=</span> []</span>
<span id="cb134-17"><a href="unet.html#cb134-17"></a>            mask_slices <span class="op">=</span> []</span>
<span id="cb134-18"><a href="unet.html#cb134-18"></a>            <span class="cf">for</span> filename <span class="kw">in</span> <span class="bu">sorted</span>(</span>
<span id="cb134-19"><a href="unet.html#cb134-19"></a>                <span class="bu">filter</span>(<span class="kw">lambda</span> f: <span class="st">&quot;.tif&quot;</span> <span class="kw">in</span> f, filenames),</span>
<span id="cb134-20"><a href="unet.html#cb134-20"></a>                key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">int</span>(x.split(<span class="st">&quot;.&quot;</span>)[<span class="op">-</span><span class="dv">2</span>].split(<span class="st">&quot;_&quot;</span>)[<span class="dv">4</span>]),</span>
<span id="cb134-21"><a href="unet.html#cb134-21"></a>            ):</span>
<span id="cb134-22"><a href="unet.html#cb134-22"></a>                filepath <span class="op">=</span> os.path.join(dirpath, filename)</span>
<span id="cb134-23"><a href="unet.html#cb134-23"></a>                <span class="cf">if</span> <span class="st">&quot;mask&quot;</span> <span class="kw">in</span> filename:</span>
<span id="cb134-24"><a href="unet.html#cb134-24"></a>                    mask_slices.append(imread(filepath, as_gray<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb134-25"><a href="unet.html#cb134-25"></a>                <span class="cf">else</span>:</span>
<span id="cb134-26"><a href="unet.html#cb134-26"></a>                    image_slices.append(imread(filepath))</span>
<span id="cb134-27"><a href="unet.html#cb134-27"></a>            <span class="cf">if</span> <span class="bu">len</span>(image_slices) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb134-28"><a href="unet.html#cb134-28"></a>                patient_id <span class="op">=</span> dirpath.split(<span class="st">&quot;/&quot;</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb134-29"><a href="unet.html#cb134-29"></a>                volumes[patient_id] <span class="op">=</span> np.array(image_slices[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb134-30"><a href="unet.html#cb134-30"></a>                masks[patient_id] <span class="op">=</span> np.array(mask_slices[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb134-31"><a href="unet.html#cb134-31"></a>        <span class="va">self</span>.patients <span class="op">=</span> <span class="bu">sorted</span>(volumes)</span>
<span id="cb134-32"><a href="unet.html#cb134-32"></a>        <span class="bu">print</span>(<span class="st">&quot;preprocessing volumes...&quot;</span>)</span>
<span id="cb134-33"><a href="unet.html#cb134-33"></a>        <span class="co"># create list of tuples (volume, mask)</span></span>
<span id="cb134-34"><a href="unet.html#cb134-34"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [(volumes[k], masks[k]) <span class="cf">for</span> k <span class="kw">in</span> <span class="va">self</span>.patients]</span>
<span id="cb134-35"><a href="unet.html#cb134-35"></a>        <span class="bu">print</span>(<span class="st">&quot;cropping volumes...&quot;</span>)</span>
<span id="cb134-36"><a href="unet.html#cb134-36"></a>        <span class="co"># crop to smallest enclosing volume</span></span>
<span id="cb134-37"><a href="unet.html#cb134-37"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [crop_sample(v) <span class="cf">for</span> v <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb134-38"><a href="unet.html#cb134-38"></a>        <span class="bu">print</span>(<span class="st">&quot;padding volumes...&quot;</span>)</span>
<span id="cb134-39"><a href="unet.html#cb134-39"></a>        <span class="co"># pad to square</span></span>
<span id="cb134-40"><a href="unet.html#cb134-40"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [pad_sample(v) <span class="cf">for</span> v <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb134-41"><a href="unet.html#cb134-41"></a>        <span class="bu">print</span>(<span class="st">&quot;resizing volumes...&quot;</span>)</span>
<span id="cb134-42"><a href="unet.html#cb134-42"></a>        <span class="co"># resize</span></span>
<span id="cb134-43"><a href="unet.html#cb134-43"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [resize_sample(v, size<span class="op">=</span>image_size) <span class="cf">for</span> v <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb134-44"><a href="unet.html#cb134-44"></a>        <span class="bu">print</span>(<span class="st">&quot;normalizing volumes...&quot;</span>)</span>
<span id="cb134-45"><a href="unet.html#cb134-45"></a>        <span class="co"># normalize channel-wise</span></span>
<span id="cb134-46"><a href="unet.html#cb134-46"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [(normalize_volume(v), m) <span class="cf">for</span> v, m <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb134-47"><a href="unet.html#cb134-47"></a>        <span class="co"># probabilities for sampling slices based on masks</span></span>
<span id="cb134-48"><a href="unet.html#cb134-48"></a>        <span class="va">self</span>.slice_weights <span class="op">=</span> [m.<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>).<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>) <span class="cf">for</span> v, m <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb134-49"><a href="unet.html#cb134-49"></a>        <span class="va">self</span>.slice_weights <span class="op">=</span> [</span>
<span id="cb134-50"><a href="unet.html#cb134-50"></a>            (s <span class="op">+</span> (s.<span class="bu">sum</span>() <span class="op">*</span> <span class="fl">0.1</span> <span class="op">/</span> <span class="bu">len</span>(s))) <span class="op">/</span> (s.<span class="bu">sum</span>() <span class="op">*</span> <span class="fl">1.1</span>) <span class="cf">for</span> s <span class="kw">in</span> <span class="va">self</span>.slice_weights</span>
<span id="cb134-51"><a href="unet.html#cb134-51"></a>        ]</span>
<span id="cb134-52"><a href="unet.html#cb134-52"></a>        <span class="co"># add channel dimension to masks</span></span>
<span id="cb134-53"><a href="unet.html#cb134-53"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [(v, m[..., np.newaxis]) <span class="cf">for</span> (v, m) <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb134-54"><a href="unet.html#cb134-54"></a>        <span class="bu">print</span>(<span class="st">&quot;done creating dataset&quot;</span>)</span>
<span id="cb134-55"><a href="unet.html#cb134-55"></a>        <span class="co"># create global index for patient and slice (idx -&gt; (p_idx, s_idx))</span></span>
<span id="cb134-56"><a href="unet.html#cb134-56"></a>        num_slices <span class="op">=</span> [v.shape[<span class="dv">0</span>] <span class="cf">for</span> v, m <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb134-57"><a href="unet.html#cb134-57"></a>        <span class="va">self</span>.patient_slice_index <span class="op">=</span> <span class="bu">list</span>(</span>
<span id="cb134-58"><a href="unet.html#cb134-58"></a>            <span class="bu">zip</span>(</span>
<span id="cb134-59"><a href="unet.html#cb134-59"></a>                <span class="bu">sum</span>([[i] <span class="op">*</span> num_slices[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(num_slices))], []),</span>
<span id="cb134-60"><a href="unet.html#cb134-60"></a>                <span class="bu">sum</span>([<span class="bu">list</span>(<span class="bu">range</span>(x)) <span class="cf">for</span> x <span class="kw">in</span> num_slices], []),</span>
<span id="cb134-61"><a href="unet.html#cb134-61"></a>            )</span>
<span id="cb134-62"><a href="unet.html#cb134-62"></a>        )</span>
<span id="cb134-63"><a href="unet.html#cb134-63"></a>        <span class="va">self</span>.random_sampling <span class="op">=</span> random_sampling</span>
<span id="cb134-64"><a href="unet.html#cb134-64"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb134-65"><a href="unet.html#cb134-65"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb134-66"><a href="unet.html#cb134-66"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.patient_slice_index)</span>
<span id="cb134-67"><a href="unet.html#cb134-67"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb134-68"><a href="unet.html#cb134-68"></a>        patient <span class="op">=</span> <span class="va">self</span>.patient_slice_index[idx][<span class="dv">0</span>]</span>
<span id="cb134-69"><a href="unet.html#cb134-69"></a>        slice_n <span class="op">=</span> <span class="va">self</span>.patient_slice_index[idx][<span class="dv">1</span>]</span>
<span id="cb134-70"><a href="unet.html#cb134-70"></a>        <span class="cf">if</span> <span class="va">self</span>.random_sampling:</span>
<span id="cb134-71"><a href="unet.html#cb134-71"></a>            patient <span class="op">=</span> np.random.randint(<span class="bu">len</span>(<span class="va">self</span>.volumes))</span>
<span id="cb134-72"><a href="unet.html#cb134-72"></a>            slice_n <span class="op">=</span> np.random.choice(</span>
<span id="cb134-73"><a href="unet.html#cb134-73"></a>                <span class="bu">range</span>(<span class="va">self</span>.volumes[patient][<span class="dv">0</span>].shape[<span class="dv">0</span>]), p<span class="op">=</span><span class="va">self</span>.slice_weights[patient]</span>
<span id="cb134-74"><a href="unet.html#cb134-74"></a>            )</span>
<span id="cb134-75"><a href="unet.html#cb134-75"></a>        v, m <span class="op">=</span> <span class="va">self</span>.volumes[patient]</span>
<span id="cb134-76"><a href="unet.html#cb134-76"></a>        image <span class="op">=</span> v[slice_n]</span>
<span id="cb134-77"><a href="unet.html#cb134-77"></a>        mask <span class="op">=</span> m[slice_n]</span>
<span id="cb134-78"><a href="unet.html#cb134-78"></a>        <span class="cf">if</span> <span class="va">self</span>.transform <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb134-79"><a href="unet.html#cb134-79"></a>            image, mask <span class="op">=</span> <span class="va">self</span>.transform((image, mask))</span>
<span id="cb134-80"><a href="unet.html#cb134-80"></a>        <span class="co"># fix dimensions (C, H, W)</span></span>
<span id="cb134-81"><a href="unet.html#cb134-81"></a>        image <span class="op">=</span> image.transpose(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb134-82"><a href="unet.html#cb134-82"></a>        mask <span class="op">=</span> mask.transpose(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb134-83"><a href="unet.html#cb134-83"></a>        image_tensor <span class="op">=</span> torch.from_numpy(image.astype(np.float32))</span>
<span id="cb134-84"><a href="unet.html#cb134-84"></a>        mask_tensor <span class="op">=</span> torch.from_numpy(mask.astype(np.float32))</span>
<span id="cb134-85"><a href="unet.html#cb134-85"></a>        <span class="co"># return tensors</span></span>
<span id="cb134-86"><a href="unet.html#cb134-86"></a>        <span class="cf">return</span> image_tensor, mask_tensor</span></code></pre></div>
</div>
<div id="loading-the-data" class="section level4" number="8.3.1.3">
<h4><span class="header-section-number">8.3.1.3</span> Loading the data</h4>
<p>We use data augmentation and shuffling on the training set, and none of those on the validation set:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="unet.html#cb135-1"></a>image_size <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb135-2"><a href="unet.html#cb135-2"></a>aug_scale <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb135-3"><a href="unet.html#cb135-3"></a>aug_angle <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb135-4"><a href="unet.html#cb135-4"></a>flip_prob <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb135-5"><a href="unet.html#cb135-5"></a></span>
<span id="cb135-6"><a href="unet.html#cb135-6"></a>train_ds <span class="op">=</span> BrainSegmentationDataset(</span>
<span id="cb135-7"><a href="unet.html#cb135-7"></a>        images_dir <span class="op">=</span> train_dir,</span>
<span id="cb135-8"><a href="unet.html#cb135-8"></a>        image_size <span class="op">=</span> image_size,</span>
<span id="cb135-9"><a href="unet.html#cb135-9"></a>        transform <span class="op">=</span> transforms(scale <span class="op">=</span> aug_scale, angle <span class="op">=</span> aug_angle, flip_prob<span class="op">=</span><span class="fl">0.5</span>),</span>
<span id="cb135-10"><a href="unet.html#cb135-10"></a>        random_sampling <span class="op">=</span> <span class="va">True</span></span>
<span id="cb135-11"><a href="unet.html#cb135-11"></a>)</span>
<span id="cb135-12"><a href="unet.html#cb135-12"></a></span>
<span id="cb135-13"><a href="unet.html#cb135-13"></a>valid_ds <span class="op">=</span> BrainSegmentationDataset(</span>
<span id="cb135-14"><a href="unet.html#cb135-14"></a>        images_dir <span class="op">=</span> valid_dir,</span>
<span id="cb135-15"><a href="unet.html#cb135-15"></a>        image_size <span class="op">=</span> image_size,</span>
<span id="cb135-16"><a href="unet.html#cb135-16"></a>        random_sampling<span class="op">=</span><span class="va">False</span></span>
<span id="cb135-17"><a href="unet.html#cb135-17"></a>)</span>
<span id="cb135-18"><a href="unet.html#cb135-18"></a></span>
<span id="cb135-19"><a href="unet.html#cb135-19"></a>batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb135-20"><a href="unet.html#cb135-20"></a></span>
<span id="cb135-21"><a href="unet.html#cb135-21"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb135-22"><a href="unet.html#cb135-22"></a>        train_ds,</span>
<span id="cb135-23"><a href="unet.html#cb135-23"></a>        batch_size <span class="op">=</span> batch_size,</span>
<span id="cb135-24"><a href="unet.html#cb135-24"></a>        shuffle <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb135-25"><a href="unet.html#cb135-25"></a>        drop_last <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb135-26"><a href="unet.html#cb135-26"></a>        num_workers <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb135-27"><a href="unet.html#cb135-27"></a>)</span>
<span id="cb135-28"><a href="unet.html#cb135-28"></a></span>
<span id="cb135-29"><a href="unet.html#cb135-29"></a>valid_loader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb135-30"><a href="unet.html#cb135-30"></a>        valid_ds,</span>
<span id="cb135-31"><a href="unet.html#cb135-31"></a>        batch_size <span class="op">=</span> batch_size,</span>
<span id="cb135-32"><a href="unet.html#cb135-32"></a>        drop_last <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb135-33"><a href="unet.html#cb135-33"></a>)</span>
<span id="cb135-34"><a href="unet.html#cb135-34"></a></span>
<span id="cb135-35"><a href="unet.html#cb135-35"></a>dataloaders <span class="op">=</span> {<span class="st">&quot;train&quot;</span>: train_loader, <span class="st">&quot;valid&quot;</span>: valid_loader}</span>
<span id="cb135-36"><a href="unet.html#cb135-36"></a>dataset_sizes <span class="op">=</span> {x: <span class="bu">len</span>(dataloaders[x]) <span class="cf">for</span> x <span class="kw">in</span> [<span class="st">&#39;train&#39;</span>, <span class="st">&#39;valid&#39;</span>]}</span></code></pre></div>
<p>On to the model.</p>
</div>
</div>
<div id="u-net-model" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> U-Net model</h3>
<p>We formulate the model in a generic way: The layers for the <em>up</em> and <em>down</em> paths are kept in lists. During the downward pass,
the model saves away the intermediate activations, and during the upward phase, passes them on for concatenation (and thus,
use in upsampling) as required.</p>
<p>Model depth is configurable (<code>depth</code>), as is a starting point for the number of filters (<code>n_filters</code>): The first downward
convolution block will have <code>2^n_filters</code> channels, and in every successive convolution block the exponent will be incremented
by one. The number of input channels (in our example: 3) and the number of output classes can be changed, as well. With a
binary problem, although logically the number of classes is two, there is no need for two output channels; a single output
channel with sigmoid activation is enough. If you had, say, four different cell types instead, you’d set <code>n_classes</code> to four.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb136-1"><a href="unet.html#cb136-1"></a><span class="kw">class</span> UNet(nn.Module):</span>
<span id="cb136-2"><a href="unet.html#cb136-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb136-3"><a href="unet.html#cb136-3"></a>        <span class="va">self</span>,</span>
<span id="cb136-4"><a href="unet.html#cb136-4"></a>        channels_in <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb136-5"><a href="unet.html#cb136-5"></a>        n_classes <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb136-6"><a href="unet.html#cb136-6"></a>        depth <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb136-7"><a href="unet.html#cb136-7"></a>        n_filters <span class="op">=</span> <span class="dv">6</span>, </span>
<span id="cb136-8"><a href="unet.html#cb136-8"></a>    ):</span>
<span id="cb136-9"><a href="unet.html#cb136-9"></a>        <span class="bu">super</span>(UNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb136-10"><a href="unet.html#cb136-10"></a>        <span class="va">self</span>.depth <span class="op">=</span> depth</span>
<span id="cb136-11"><a href="unet.html#cb136-11"></a>        prev_channels <span class="op">=</span> channels_in</span>
<span id="cb136-12"><a href="unet.html#cb136-12"></a>        <span class="va">self</span>.down_path <span class="op">=</span> nn.ModuleList()</span>
<span id="cb136-13"><a href="unet.html#cb136-13"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(depth):</span>
<span id="cb136-14"><a href="unet.html#cb136-14"></a>            <span class="va">self</span>.down_path.append(</span>
<span id="cb136-15"><a href="unet.html#cb136-15"></a>                DownBlock(prev_channels, <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i))</span>
<span id="cb136-16"><a href="unet.html#cb136-16"></a>            )</span>
<span id="cb136-17"><a href="unet.html#cb136-17"></a>            prev_channels <span class="op">=</span> <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i)</span>
<span id="cb136-18"><a href="unet.html#cb136-18"></a>        <span class="va">self</span>.up_path <span class="op">=</span> nn.ModuleList()</span>
<span id="cb136-19"><a href="unet.html#cb136-19"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(depth <span class="op">-</span> <span class="dv">1</span>)):</span>
<span id="cb136-20"><a href="unet.html#cb136-20"></a>            <span class="va">self</span>.up_path.append(</span>
<span id="cb136-21"><a href="unet.html#cb136-21"></a>                UpBlock(prev_channels, <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i))</span>
<span id="cb136-22"><a href="unet.html#cb136-22"></a>            )</span>
<span id="cb136-23"><a href="unet.html#cb136-23"></a>            prev_channels <span class="op">=</span> <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i)</span>
<span id="cb136-24"><a href="unet.html#cb136-24"></a>        <span class="va">self</span>.last <span class="op">=</span> nn.Conv2d(prev_channels, n_classes, kernel_size <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb136-25"><a href="unet.html#cb136-25"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb136-26"><a href="unet.html#cb136-26"></a>        blocks <span class="op">=</span> []</span>
<span id="cb136-27"><a href="unet.html#cb136-27"></a>        <span class="cf">for</span> i, down <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.down_path):</span>
<span id="cb136-28"><a href="unet.html#cb136-28"></a>            x <span class="op">=</span> down(x)</span>
<span id="cb136-29"><a href="unet.html#cb136-29"></a>            <span class="cf">if</span> i <span class="op">!=</span> <span class="bu">len</span>(<span class="va">self</span>.down_path) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb136-30"><a href="unet.html#cb136-30"></a>                blocks.append(x)</span>
<span id="cb136-31"><a href="unet.html#cb136-31"></a>                x <span class="op">=</span> F.max_pool2d(x, <span class="dv">2</span>)</span>
<span id="cb136-32"><a href="unet.html#cb136-32"></a>        <span class="cf">for</span> i, up <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.up_path):</span>
<span id="cb136-33"><a href="unet.html#cb136-33"></a>            x <span class="op">=</span> up(x, blocks[<span class="op">-</span>i <span class="op">-</span> <span class="dv">1</span>])</span>
<span id="cb136-34"><a href="unet.html#cb136-34"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.last(x))</span>
<span id="cb136-35"><a href="unet.html#cb136-35"></a>{r}</span></code></pre></div>
<p>As you’ll have seen, this top-level module makes use of two helper modules, <code>DownBlock</code> and <code>UpBlock</code>. These again assemble
and call instances of <code>ConvBlock</code>, the lowest-level module, that chains convolutional, activation, dropout and batchnorm
layers. For this specific application, we’ve found that batchnorm actually resulted in deteriorated performance on the
validation set, probably due to very small batch size. When working with other datasets and/or larger batches that could be
very different.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="unet.html#cb137-1"></a><span class="kw">class</span> ConvBlock(nn.Module):</span>
<span id="cb137-2"><a href="unet.html#cb137-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_size, out_size):</span>
<span id="cb137-3"><a href="unet.html#cb137-3"></a>        <span class="bu">super</span>(ConvBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb137-4"><a href="unet.html#cb137-4"></a>        block <span class="op">=</span> []</span>
<span id="cb137-5"><a href="unet.html#cb137-5"></a>        block.append(nn.Conv2d(in_size, out_size, kernel_size <span class="op">=</span> <span class="dv">3</span>, padding <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb137-6"><a href="unet.html#cb137-6"></a>        block.append(nn.ReLU())</span>
<span id="cb137-7"><a href="unet.html#cb137-7"></a>        <span class="co">#block.append(nn.BatchNorm2d(out_size))</span></span>
<span id="cb137-8"><a href="unet.html#cb137-8"></a>        block.append(nn.Dropout(<span class="fl">0.6</span>))</span>
<span id="cb137-9"><a href="unet.html#cb137-9"></a>        block.append(nn.Conv2d(out_size, out_size, kernel_size <span class="op">=</span> <span class="dv">3</span>, padding <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb137-10"><a href="unet.html#cb137-10"></a>        block.append(nn.ReLU())</span>
<span id="cb137-11"><a href="unet.html#cb137-11"></a>        <span class="co">#block.append(nn.BatchNorm2d(out_size))</span></span>
<span id="cb137-12"><a href="unet.html#cb137-12"></a>        block.append(nn.Dropout(<span class="fl">0.6</span>))</span>
<span id="cb137-13"><a href="unet.html#cb137-13"></a>        <span class="va">self</span>.block <span class="op">=</span> nn.Sequential(<span class="op">*</span>block)</span>
<span id="cb137-14"><a href="unet.html#cb137-14"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb137-15"><a href="unet.html#cb137-15"></a>        out <span class="op">=</span> <span class="va">self</span>.block(x)</span>
<span id="cb137-16"><a href="unet.html#cb137-16"></a>        <span class="cf">return</span> out</span></code></pre></div>
<div class="sourceCode" id="cb138"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="unet.html#cb138-1"></a><span class="kw">class</span> DownBlock(nn.Module):</span>
<span id="cb138-2"><a href="unet.html#cb138-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_size, out_size):</span>
<span id="cb138-3"><a href="unet.html#cb138-3"></a>        <span class="bu">super</span>(DownBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb138-4"><a href="unet.html#cb138-4"></a>        <span class="va">self</span>.conv_block <span class="op">=</span> ConvBlock(in_size, out_size)</span>
<span id="cb138-5"><a href="unet.html#cb138-5"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb138-6"><a href="unet.html#cb138-6"></a>        down <span class="op">=</span> <span class="va">self</span>.conv_block(x)</span>
<span id="cb138-7"><a href="unet.html#cb138-7"></a>        <span class="cf">return</span> down</span></code></pre></div>
<div class="sourceCode" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="unet.html#cb139-1"></a><span class="kw">class</span> UpBlock(nn.Module):</span>
<span id="cb139-2"><a href="unet.html#cb139-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_size, out_size):</span>
<span id="cb139-3"><a href="unet.html#cb139-3"></a>        <span class="bu">super</span>(UpBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb139-4"><a href="unet.html#cb139-4"></a>        <span class="va">self</span>.up <span class="op">=</span> nn.ConvTranspose2d(in_size, out_size, kernel_size <span class="op">=</span> <span class="dv">2</span>, stride <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb139-5"><a href="unet.html#cb139-5"></a>        <span class="va">self</span>.conv_block <span class="op">=</span> ConvBlock(in_size, out_size)</span>
<span id="cb139-6"><a href="unet.html#cb139-6"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, bridge):</span>
<span id="cb139-7"><a href="unet.html#cb139-7"></a>        up <span class="op">=</span> <span class="va">self</span>.up(x)</span>
<span id="cb139-8"><a href="unet.html#cb139-8"></a>        out <span class="op">=</span> torch.cat([up, bridge], <span class="dv">1</span>)</span>
<span id="cb139-9"><a href="unet.html#cb139-9"></a>        out <span class="op">=</span> <span class="va">self</span>.conv_block(out)</span>
<span id="cb139-10"><a href="unet.html#cb139-10"></a>        <span class="cf">return</span> out</span></code></pre></div>
<p>We instantiate the model with default parameters.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="unet.html#cb140-1"></a>device <span class="op">=</span> torch.device(<span class="st">&#39;cuda&#39;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb140-2"><a href="unet.html#cb140-2"></a>model <span class="op">=</span> UNet().to(device)</span></code></pre></div>
<p>This results in a U-structure of the following dimensionality:</p>
<table>
<colgroup>
<col width="20%" />
<col width="55%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th>down</th>
<th></th>
<th>up</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>channels x width x height</td>
<td></td>
<td>channels x width x height</td>
</tr>
<tr class="even">
<td>3 x 256 x 256 (input)</td>
<td></td>
<td>1 x 256 x 256 (1 x1 conv)</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>64 x 256 x 256 (conv)</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>128 x 256 x 256 (concat)</td>
</tr>
<tr class="odd">
<td>64 x 256 x 256 (conv)</td>
<td>CONCAT</td>
<td>64 x 256 x 256 (conv + deconv)</td>
</tr>
<tr class="even">
<td>64 x 128 x 128 (pool)</td>
<td></td>
<td>256 x 128 x 128 (concat)</td>
</tr>
<tr class="odd">
<td>128 x 128 x 128 (conv)</td>
<td>CONCAT</td>
<td>128 x 128 x 128 (conv + deconv)</td>
</tr>
<tr class="even">
<td>128 x 64 x 64 (pool)</td>
<td></td>
<td>512 x 64 x 64 (concat)</td>
</tr>
<tr class="odd">
<td>256 x 64 x 64 (conv)</td>
<td>CONCAT</td>
<td>256 x 64 x 64 (conv + deconv)</td>
</tr>
<tr class="even">
<td>256 x 32 x 32 (pool)</td>
<td></td>
<td>1024 x 32 x 32 (concat)</td>
</tr>
<tr class="odd">
<td>512 x 32 x 32 (conv)</td>
<td>CONCAT</td>
<td>512 x 32 x 32 (deconv)</td>
</tr>
<tr class="even">
<td>512 x 16 x 16 (pool)</td>
<td>------------------------------------&gt;</td>
<td>1024 x 16 x 16 (conv)</td>
</tr>
</tbody>
</table>
<p>Note that when on the <em>down</em> path, the number of channels goes <em>up</em>, this is due to the convolution layers; spatial
downsizing, however, occurs due to max pooling. This is an implementation feature, not a requirement – we could replace max
pooling by using <code>strides</code> greater than <code>1</code> in the conv layers instead. This is another place where for a concrete
application, you might want to experiment a bit.</p>
<p>On the <em>up</em> path, we conveniently concatenate stored-away activations preceding max pooling layers to upwards-“bubbling”
activations of same spatial resolution. The concatenated values are then upsized spatially using transposed convolutions,
while the number of filters is reduced by conv layers. As an alternative to transposed convolution, you might want to try
<code>UpSampling</code> layers.</p>
</div>
<div id="loss" class="section level3" number="8.3.3">
<h3><span class="header-section-number">8.3.3</span> Loss</h3>
<p>Thinking about loss functions that match the task, the first that probably comes to mind is binary crossentropy,
<code>torch.nn.BCELoss</code>, applied pixel-wise. We’ll use it …</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="unet.html#cb141-1"></a>bce_loss <span class="op">=</span> nn.BCELoss()</span></code></pre></div>
<p>but we’ll augment it by another, called <em>dice loss</em> after the <a href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient">dice
coefficient</a>:<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p><span class="math display">\[
d = \frac{2 * |X \cap Y|}{|X \cup Y|}
\]</span></p>
<p>The dice coefficient is similar in spirit to the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard index</a>, also known as
<em>intersection over union</em>, but differs in that it scales the numerator by two. Here is an implementation of the derived loss:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="unet.html#cb142-1"></a><span class="kw">class</span> DiceLoss(nn.Module):</span>
<span id="cb142-2"><a href="unet.html#cb142-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb142-3"><a href="unet.html#cb142-3"></a>        <span class="bu">super</span>(DiceLoss, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb142-4"><a href="unet.html#cb142-4"></a>        <span class="va">self</span>.smooth <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb142-5"><a href="unet.html#cb142-5"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, y_pred, y_true):</span>
<span id="cb142-6"><a href="unet.html#cb142-6"></a>        <span class="cf">assert</span> y_pred.size() <span class="op">==</span> y_true.size()</span>
<span id="cb142-7"><a href="unet.html#cb142-7"></a>        y_pred <span class="op">=</span> y_pred[:, <span class="dv">0</span>].contiguous().view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb142-8"><a href="unet.html#cb142-8"></a>        y_true <span class="op">=</span> y_true[:, <span class="dv">0</span>].contiguous().view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb142-9"><a href="unet.html#cb142-9"></a>        intersection <span class="op">=</span> (y_pred <span class="op">*</span> y_true).<span class="bu">sum</span>()</span>
<span id="cb142-10"><a href="unet.html#cb142-10"></a>        dsc <span class="op">=</span> (<span class="fl">2.</span> <span class="op">*</span> intersection <span class="op">+</span> <span class="va">self</span>.smooth) <span class="op">/</span> (</span>
<span id="cb142-11"><a href="unet.html#cb142-11"></a>            y_pred.<span class="bu">sum</span>() <span class="op">+</span> y_true.<span class="bu">sum</span>() <span class="op">+</span> <span class="va">self</span>.smooth</span>
<span id="cb142-12"><a href="unet.html#cb142-12"></a>        )</span>
<span id="cb142-13"><a href="unet.html#cb142-13"></a>        <span class="cf">return</span> <span class="fl">1.</span> <span class="op">-</span> dsc</span></code></pre></div>
<p>Dice loss, defined as one minus the dice coefficient, is said to improve training on imbalanced datasets. Looking closely, we
see that if a mask is all zero, the only way to not to incur loss is by predicting all zeroes, as well.</p>
<p>For easy experimentation, we combine make it so both losses are combined in a weighted fashion:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="unet.html#cb143-1"></a>dice_loss <span class="op">=</span> DiceLoss()</span>
<span id="cb143-2"><a href="unet.html#cb143-2"></a></span>
<span id="cb143-3"><a href="unet.html#cb143-3"></a>dice_weight <span class="op">=</span> <span class="fl">0.3</span></span></code></pre></div>
</div>
<div id="training" class="section level3" number="8.3.4">
<h3><span class="header-section-number">8.3.4</span> Training</h3>
<p>We train for fifty epochs, continously saving the model weights that are best so far.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="unet.html#cb144-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr <span class="op">=</span> <span class="fl">0.1</span>, momentum <span class="op">=</span> <span class="fl">0.9</span>)</span>
<span id="cb144-2"><a href="unet.html#cb144-2"></a></span>
<span id="cb144-3"><a href="unet.html#cb144-3"></a>scheduler <span class="op">=</span> torch.optim.lr_scheduler.OneCycleLR(</span>
<span id="cb144-4"><a href="unet.html#cb144-4"></a>    optimizer,</span>
<span id="cb144-5"><a href="unet.html#cb144-5"></a>    max_lr <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb144-6"><a href="unet.html#cb144-6"></a>    steps_per_epoch <span class="op">=</span> <span class="bu">len</span>(train_loader),</span>
<span id="cb144-7"><a href="unet.html#cb144-7"></a>    epochs <span class="op">=</span> num_epochs</span>
<span id="cb144-8"><a href="unet.html#cb144-8"></a>)</span>
<span id="cb144-9"><a href="unet.html#cb144-9"></a></span>
<span id="cb144-10"><a href="unet.html#cb144-10"></a>best_model_wts <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb144-11"><a href="unet.html#cb144-11"></a>best_dice_coef <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb144-12"><a href="unet.html#cb144-12"></a></span>
<span id="cb144-13"><a href="unet.html#cb144-13"></a>num_epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb144-14"><a href="unet.html#cb144-14"></a></span>
<span id="cb144-15"><a href="unet.html#cb144-15"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb144-16"><a href="unet.html#cb144-16"></a>    <span class="bu">print</span>(<span class="st">&#39;Epoch </span><span class="sc">{}</span><span class="st">/</span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(epoch, num_epochs <span class="op">-</span> <span class="dv">1</span>), flush <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb144-17"><a href="unet.html#cb144-17"></a>    <span class="bu">print</span>(<span class="st">&#39;-&#39;</span> <span class="op">*</span> <span class="dv">10</span>)</span>
<span id="cb144-18"><a href="unet.html#cb144-18"></a>    <span class="cf">for</span> phase <span class="kw">in</span> [<span class="st">&#39;train&#39;</span>, <span class="st">&#39;valid&#39;</span>]:</span>
<span id="cb144-19"><a href="unet.html#cb144-19"></a>        <span class="bu">print</span>(<span class="st">&quot;Entering phase: &quot;</span> <span class="op">+</span> phase, flush <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb144-20"><a href="unet.html#cb144-20"></a>        <span class="cf">if</span> phase <span class="op">==</span> <span class="st">&#39;train&#39;</span>:</span>
<span id="cb144-21"><a href="unet.html#cb144-21"></a>            model <span class="op">=</span> model.train() </span>
<span id="cb144-22"><a href="unet.html#cb144-22"></a>        <span class="cf">else</span>:</span>
<span id="cb144-23"><a href="unet.html#cb144-23"></a>            model <span class="op">=</span> model.<span class="bu">eval</span>()   </span>
<span id="cb144-24"><a href="unet.html#cb144-24"></a>        running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb144-25"><a href="unet.html#cb144-25"></a>        running_dice <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb144-26"><a href="unet.html#cb144-26"></a>        running_bce <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb144-27"><a href="unet.html#cb144-27"></a>        <span class="cf">for</span> inputs, labels <span class="kw">in</span> dataloaders[phase]:</span>
<span id="cb144-28"><a href="unet.html#cb144-28"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb144-29"><a href="unet.html#cb144-29"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb144-30"><a href="unet.html#cb144-30"></a>            optimizer.zero_grad()</span>
<span id="cb144-31"><a href="unet.html#cb144-31"></a>            <span class="cf">with</span> torch.set_grad_enabled(phase <span class="op">==</span> <span class="st">&#39;train&#39;</span>):</span>
<span id="cb144-32"><a href="unet.html#cb144-32"></a>                preds <span class="op">=</span> model(inputs)</span>
<span id="cb144-33"><a href="unet.html#cb144-33"></a>                dice_loss <span class="op">=</span> dsc_loss(preds, labels)</span>
<span id="cb144-34"><a href="unet.html#cb144-34"></a>                xent_loss <span class="op">=</span> bce_loss(preds, labels)</span>
<span id="cb144-35"><a href="unet.html#cb144-35"></a>                loss <span class="op">=</span> dice_weight <span class="op">*</span> dice_loss <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> dice_weight) <span class="op">*</span> xent_loss</span>
<span id="cb144-36"><a href="unet.html#cb144-36"></a>                <span class="cf">if</span> phase <span class="op">==</span> <span class="st">&#39;train&#39;</span>:</span>
<span id="cb144-37"><a href="unet.html#cb144-37"></a>                    loss.backward()</span>
<span id="cb144-38"><a href="unet.html#cb144-38"></a>                    optimizer.step()</span>
<span id="cb144-39"><a href="unet.html#cb144-39"></a>            running_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb144-40"><a href="unet.html#cb144-40"></a>            running_dice <span class="op">+=</span> dice_loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb144-41"><a href="unet.html#cb144-41"></a>            <span class="cf">if</span> phase <span class="op">==</span> <span class="st">&#39;train&#39;</span>:</span>
<span id="cb144-42"><a href="unet.html#cb144-42"></a>                scheduler.step()</span>
<span id="cb144-43"><a href="unet.html#cb144-43"></a>        epoch_loss <span class="op">=</span> running_loss <span class="op">/</span> dataset_sizes[phase]</span>
<span id="cb144-44"><a href="unet.html#cb144-44"></a>        epoch_dice <span class="op">=</span> running_dice <span class="op">/</span> dataset_sizes[phase]</span>
<span id="cb144-45"><a href="unet.html#cb144-45"></a>        epoch_bce <span class="op">=</span> running_bce <span class="op">/</span> dataset_sizes[phase]</span>
<span id="cb144-46"><a href="unet.html#cb144-46"></a>        <span class="cf">if</span> phase <span class="op">==</span> <span class="st">&#39;valid&#39;</span> <span class="kw">and</span> epoch_dice <span class="op">&lt;</span> best_dice_coef:</span>
<span id="cb144-47"><a href="unet.html#cb144-47"></a>            best_dice <span class="op">=</span> epoch_dice</span>
<span id="cb144-48"><a href="unet.html#cb144-48"></a>            best_model_wts <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb144-49"><a href="unet.html#cb144-49"></a>        <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> Loss: </span><span class="sc">{:.4f}</span><span class="st">&#39;</span>.<span class="bu">format</span>(phase, epoch_loss), flush <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb144-50"><a href="unet.html#cb144-50"></a>        <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> Dice coef: </span><span class="sc">{:.4f}</span><span class="st">&#39;</span>.<span class="bu">format</span>(phase, epoch_dice), flush <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb144-51"><a href="unet.html#cb144-51"></a>        <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> BCE: </span><span class="sc">{:.4f}</span><span class="st">&#39;</span>.<span class="bu">format</span>(phase, epoch_bce), flush <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb144-52"><a href="unet.html#cb144-52"></a>    <span class="bu">print</span>()</span>
<span id="cb144-53"><a href="unet.html#cb144-53"></a></span>
<span id="cb144-54"><a href="unet.html#cb144-54"></a>model.load_state_dict(best_model_wts)</span>
<span id="cb144-55"><a href="unet.html#cb144-55"></a>torch.save(model.state_dict(), <span class="st">&quot;mri.pt&quot;</span>)</span></code></pre></div>
<p>Here is a excerpt from the training history:</p>
<pre><code>Epoch 0/49
----------
Entering phase: train
train Loss: 1.0315
train Dice coef: 2.3604
train BCE: 0.4620
Entering phase: valid
valid Loss: 1.3413
valid Dice coef: 3.2042
valid BCE: 0.5429

Epoch 1/49
----------
Entering phase: train
train Loss: 0.7160
train Dice coef: 1.5426
train BCE: 0.3618
Entering phase: valid
valid Loss: 1.3800
valid Dice coef: 3.2879
valid BCE: 0.5624

...

Epoch 48/49
----------
Entering phase: train
train Loss: 0.2059
train Dice coef: 0.4564
train BCE: 0.0985
Entering phase: valid
valid Loss: 1.1764
valid Dice coef: 3.0436
valid BCE: 0.3762

Epoch 49/49
----------
Entering phase: train
train Loss: 0.2033
train Dice coef: 0.4519
train BCE: 0.0968
Entering phase: valid
valid Loss: 1.1654
valid Dice coef: 3.0353
valid BCE: 0.3641

</code></pre>
</div>
<div id="predictions" class="section level3" number="8.3.5">
<h3><span class="header-section-number">8.3.5</span> Predictions</h3>
<p>TBD when in R.</p>

</div>
</div>
</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-BUDA2019218">
<p>Buda, Mateusz, Ashirbani Saha, and Maciej A. Mazurowski. 2019. “Association of Genomic Subtypes of Lower-Grade Gliomas with Shape Features Automatically Extracted by a Deep Learning Algorithm.” <em>Computers in Biology and Medicine</em> 109: 218–25. <a href="https://doi.org/https://doi.org/10.1016/j.compbiomed.2019.05.002">https://doi.org/https://doi.org/10.1016/j.compbiomed.2019.05.002</a>.</p>
</div>
<div id="ref-RonnebergerFB15">
<p>Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. “U-Net: Convolutional Networks for Biomedical Image Segmentation.” <em>CoRR</em> abs/1505.04597. <a href="http://arxiv.org/abs/1505.04597">http://arxiv.org/abs/1505.04597</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>here in set notation<a href="unet.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="image-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="NLP-intro.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
