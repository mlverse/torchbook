<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8 Brain Image Segmentation with U-Net | Applied deep learning with torch from R</title>
  <meta name="description" content="tbd" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="8 Brain Image Segmentation with U-Net | Applied deep learning with torch from R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="tbd" />
  <meta property="og:image" content="tbdcover.png" />
  <meta property="og:description" content="tbd" />
  <meta name="github-repo" content="tbd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Brain Image Segmentation with U-Net | Applied deep learning with torch from R" />
  
  <meta name="twitter:description" content="tbd" />
  <meta name="twitter:image" content="tbdcover.png" />

<meta name="author" content="tbd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="image-classification.html"/>
<link rel="next" href="NLP-intro.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>I Using Torch</b></span></li>
<li class="chapter" data-level="" data-path="using-torch-intro.html"><a href="using-torch-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="2" data-path="simple-net-R.html"><a href="simple-net-R.html"><i class="fa fa-check"></i><b>2</b> A simple neural network in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#whats-in-a-network"><i class="fa fa-check"></i><b>2.1</b> What’s in a network?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="simple-net-R.html"><a href="simple-net-R.html#gradient-descent"><i class="fa fa-check"></i><b>2.1.1</b> Gradient descent</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-net-R.html"><a href="simple-net-R.html#from-linear-regression-to-a-simple-network"><i class="fa fa-check"></i><b>2.1.2</b> From linear regression to a simple network</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#a-simple-network"><i class="fa fa-check"></i><b>2.2</b> A simple network</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#simulate-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulate data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#initialize-weights-and-biases"><i class="fa fa-check"></i><b>2.2.2</b> Initialize weights and biases</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>2.2.3</b> Training loop</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-net-R.html"><a href="simple-net-R.html#complete-code"><i class="fa fa-check"></i><b>2.2.4</b> Complete code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#appendix-python-code"><i class="fa fa-check"></i><b>2.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html"><i class="fa fa-check"></i><b>3</b> Modifying the simple network to use torch tensors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#simple-network-torchified-step-1"><i class="fa fa-check"></i><b>3.1</b> Simple network torchified, step 1</a></li>
<li class="chapter" data-level="3.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#more-on-tensors"><i class="fa fa-check"></i><b>3.2</b> More on tensors</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#creating-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Creating tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#conversion-from-and-to-r"><i class="fa fa-check"></i><b>3.2.2</b> Conversion from and to R</a></li>
<li class="chapter" data-level="3.2.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#indexing-and-slicing-tensors"><i class="fa fa-check"></i><b>3.2.3</b> Indexing and slicing tensors</a></li>
<li class="chapter" data-level="3.2.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#reshaping-tensors"><i class="fa fa-check"></i><b>3.2.4</b> Reshaping tensors</a></li>
<li class="chapter" data-level="3.2.5" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#operations-on-tensors"><i class="fa fa-check"></i><b>3.2.5</b> Operations on tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#broadcasting"><i class="fa fa-check"></i><b>3.3</b> Broadcasting</a></li>
<li class="chapter" data-level="3.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#running-on-gpu"><i class="fa fa-check"></i><b>3.4</b> Running on GPU</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html"><i class="fa fa-check"></i><b>4</b> Using autograd</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#automatic-differentiation-with-autograd"><i class="fa fa-check"></i><b>4.1</b> Automatic differentiation with autograd</a></li>
<li class="chapter" data-level="4.2" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#the-simple-network-now-using-autograd"><i class="fa fa-check"></i><b>4.2</b> The simple network, now using autograd</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-net-modules.html"><a href="simple-net-modules.html"><i class="fa fa-check"></i><b>5</b> Using torch modules</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#modules"><i class="fa fa-check"></i><b>5.1</b> Modules</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#layers-as-modules"><i class="fa fa-check"></i><b>5.1.1</b> Layers as modules</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#models-as-modules"><i class="fa fa-check"></i><b>5.1.2</b> Models as modules</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#simple-network-using-modules"><i class="fa fa-check"></i><b>5.2</b> Simple network using modules</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-net-optim.html"><a href="simple-net-optim.html"><i class="fa fa-check"></i><b>6</b> Using torch optimizers</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple-net-optim.html"><a href="simple-net-optim.html#torch-optimizers"><i class="fa fa-check"></i><b>6.1</b> Torch optimizers</a></li>
<li class="chapter" data-level="6.2" data-path="simple-net-optim.html"><a href="simple-net-optim.html#simple-net-with-torch.optim"><i class="fa fa-check"></i><b>6.2</b> Simple net with <code>torch.optim</code></a></li>
</ul></li>
<li class="part"><span><b>II Image Recognition</b></span></li>
<li class="chapter" data-level="" data-path="image-recognition-intro.html"><a href="image-recognition-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="7" data-path="image-classification.html"><a href="image-classification.html"><i class="fa fa-check"></i><b>7</b> Classifying images</a>
<ul>
<li class="chapter" data-level="7.1" data-path="image-classification.html"><a href="image-classification.html#data-loading-and-transformation"><i class="fa fa-check"></i><b>7.1</b> Data loading and transformation</a></li>
<li class="chapter" data-level="7.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>7.2</b> Model</a></li>
<li class="chapter" data-level="7.3" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>7.3</b> Training</a></li>
<li class="chapter" data-level="7.4" data-path="image-classification.html"><a href="image-classification.html#performance-on-the-test-set"><i class="fa fa-check"></i><b>7.4</b> Performance on the test set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unet.html"><a href="unet.html"><i class="fa fa-check"></i><b>8</b> Brain Image Segmentation with U-Net</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unet.html"><a href="unet.html#image-segmentation-in-a-nutshell"><i class="fa fa-check"></i><b>8.1</b> Image segmentation in a nutshell</a></li>
<li class="chapter" data-level="8.2" data-path="unet.html"><a href="unet.html#u-net"><i class="fa fa-check"></i><b>8.2</b> U-Net</a></li>
<li class="chapter" data-level="8.3" data-path="unet.html"><a href="unet.html#example-application-mri-images"><i class="fa fa-check"></i><b>8.3</b> Example application: MRI images</a></li>
<li class="chapter" data-level="8.4" data-path="unet.html"><a href="unet.html#preprocessing"><i class="fa fa-check"></i><b>8.4</b> Preprocessing</a></li>
<li class="chapter" data-level="8.5" data-path="unet.html"><a href="unet.html#u-net-model"><i class="fa fa-check"></i><b>8.5</b> U-Net model</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="unet.html"><a href="unet.html#heading"><i class="fa fa-check"></i><b>8.5.1</b> heading</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Natural language processing</b></span></li>
<li class="chapter" data-level="" data-path="NLP-intro.html"><a href="NLP-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="9" data-path="seq2seq-att.html"><a href="seq2seq-att.html"><i class="fa fa-check"></i><b>9</b> Sequence-to-sequence models with attention</a>
<ul>
<li class="chapter" data-level="9.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#why-attention"><i class="fa fa-check"></i><b>9.1</b> Why attention?</a></li>
<li class="chapter" data-level="9.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#preprocessing-with-torchtext"><i class="fa fa-check"></i><b>9.2</b> Preprocessing with <code>torchtext</code></a></li>
<li class="chapter" data-level="9.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#model-1"><i class="fa fa-check"></i><b>9.3</b> Model</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>9.3.1</b> Encoder</a></li>
<li class="chapter" data-level="9.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#attention-module"><i class="fa fa-check"></i><b>9.3.2</b> Attention module</a></li>
<li class="chapter" data-level="9.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>9.3.3</b> Decoder</a></li>
<li class="chapter" data-level="9.3.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#seq2seq-module"><i class="fa fa-check"></i><b>9.3.4</b> Seq2seq module</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#training-and-evaluation"><i class="fa fa-check"></i><b>9.4</b> Training and evaluation</a></li>
<li class="chapter" data-level="9.5" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>9.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="transformer.html"><a href="transformer.html"><i class="fa fa-check"></i><b>10</b> Torch transformer modules</a>
<ul>
<li class="chapter" data-level="10.1" data-path="transformer.html"><a href="transformer.html#attention-is-all-you-need"><i class="fa fa-check"></i><b>10.1</b> “Attention is all you need”</a></li>
<li class="chapter" data-level="10.2" data-path="transformer.html"><a href="transformer.html#implementation-building-blocks"><i class="fa fa-check"></i><b>10.2</b> Implementation: building blocks</a></li>
<li class="chapter" data-level="10.3" data-path="transformer.html"><a href="transformer.html#a-transformer-for-natural-language-translation"><i class="fa fa-check"></i><b>10.3</b> A Transformer for natural language translation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="transformer.html"><a href="transformer.html#load-data"><i class="fa fa-check"></i><b>10.3.1</b> Load data</a></li>
<li class="chapter" data-level="10.3.2" data-path="transformer.html"><a href="transformer.html#encoder-1"><i class="fa fa-check"></i><b>10.3.2</b> Encoder</a></li>
<li class="chapter" data-level="10.3.3" data-path="transformer.html"><a href="transformer.html#decoder-1"><i class="fa fa-check"></i><b>10.3.3</b> Decoder</a></li>
<li class="chapter" data-level="10.3.4" data-path="transformer.html"><a href="transformer.html#overall-model"><i class="fa fa-check"></i><b>10.3.4</b> Overall model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="transformer.html"><a href="transformer.html#results-1"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
</ul></li>
<li class="part"><span><b>IV Deep learning for tabular data</b></span></li>
<li class="chapter" data-level="" data-path="tabular-intro.html"><a href="tabular-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V Time series</b></span></li>
<li class="chapter" data-level="" data-path="timeseries-intro.html"><a href="timeseries-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VI Generative deep learning</b></span></li>
<li class="chapter" data-level="" data-path="generative-intro.html"><a href="generative-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="11" data-path="gans.html"><a href="gans.html"><i class="fa fa-check"></i><b>11</b> Generative adversarial networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>11.1</b> Dataset</a></li>
<li class="chapter" data-level="11.2" data-path="gans.html"><a href="gans.html#model-2"><i class="fa fa-check"></i><b>11.2</b> Model</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="gans.html"><a href="gans.html#generator"><i class="fa fa-check"></i><b>11.2.1</b> Generator</a></li>
<li class="chapter" data-level="11.2.2" data-path="gans.html"><a href="gans.html#discriminator"><i class="fa fa-check"></i><b>11.2.2</b> Discriminator</a></li>
<li class="chapter" data-level="11.2.3" data-path="gans.html"><a href="gans.html#optimizers-and-loss-function"><i class="fa fa-check"></i><b>11.2.3</b> Optimizers and loss function</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="gans.html"><a href="gans.html#training-loop-1"><i class="fa fa-check"></i><b>11.3</b> Training loop</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="vaes.html"><a href="vaes.html"><i class="fa fa-check"></i><b>12</b> Variational autoencoders</a>
<ul>
<li class="chapter" data-level="12.1" data-path="vaes.html"><a href="vaes.html#dataset-1"><i class="fa fa-check"></i><b>12.1</b> Dataset</a></li>
<li class="chapter" data-level="12.2" data-path="vaes.html"><a href="vaes.html#model-3"><i class="fa fa-check"></i><b>12.2</b> Model</a></li>
<li class="chapter" data-level="12.3" data-path="vaes.html"><a href="vaes.html#training-the-vae"><i class="fa fa-check"></i><b>12.3</b> Training the VAE</a></li>
<li class="chapter" data-level="12.4" data-path="vaes.html"><a href="vaes.html#latent-space"><i class="fa fa-check"></i><b>12.4</b> Latent space</a></li>
</ul></li>
<li class="part"><span><b>VII Deep learning on graphs</b></span></li>
<li class="chapter" data-level="" data-path="graph-intro.html"><a href="graph-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VIII Probabilistic deep learning</b></span></li>
<li class="chapter" data-level="" data-path="probabilistic-intro.html"><a href="probabilistic-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>IX Private and secure deep learning</b></span></li>
<li class="chapter" data-level="" data-path="private-secure-intro.html"><a href="private-secure-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>X Research topics</b></span></li>
<li class="chapter" data-level="" data-path="research-intro.html"><a href="research-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied deep learning with torch from R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="unet" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Brain Image Segmentation with U-Net</h1>
<div id="image-segmentation-in-a-nutshell" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Image segmentation in a nutshell</h2>
<p>Now that we’ve seen how to <em>classify</em> images – as of this writing, probably the “Hello World” of deep learning – we proceed
to a type of application vastly important in practice, especially in medicine, biology, geology and other natural sciences. In
image <em>segmentation</em>, we’re not interested in labeling the entire image; instead, we want to classify every pixel (2-d) or
voxel (3-d) according to some criterion.</p>
<p>In medicine, for example, we might want to detect different cell types, or identify tumors or lesions. The decision could be
two-way – tumor cell yes or no? –, or there could be some higher number of classes to discern. To train a supervised model,
ground truth data needs to be present. In these tasks, the ground truth comes in form of a <em>mask</em>: an image, of same spatial
dimension as the target data, that designates the true classes. Loss values are calculated for every pixel (voxel) separately,
and summed up to yield an aggregate that can be minimized.</p>
</div>
<div id="u-net" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> U-Net</h2>
<p>Here is the “canonical U-Net architecture”, as depicted in the original Rönneberger et al. paper <span class="citation">(Ronneberger, Fischer, and Brox <a href="#ref-RonnebergerFB15" role="doc-biblioref">2015</a>)</span>. In
different realizations, layer sizes, activations, ways to achieve downsizing and upsizing will vary, but there is one defining
characteristic: The U-shape (clearly visible below), enriched by the “bridges” crossing over horizontally at all levels.</p>
<p><img src="images/unet.png" title="The original U-Net, as depicted in Ronnerberger et al. (2015)." /></p>
<p>In a nutshell, the left-hand side of the U is like a simple convnet used to classify images; the input is successively
downsized spatially but at the same time, another dimension – the <em>channels</em> dimension – is used to successively encode a
hierarchy of features, ranging from very basic and universal to very specialized. As the output, however, should have the same
spatial resolution as the input, we need to upsize again – this is taken care of by the right-hand side of the U. But, how
are we going to arrive at a good <em>per-pixel</em> classification if so much spatial information is lost on the way? This is what
the “bridges” are for: At each depth, the input to an upsampling layer is a <em>concatenation</em> of the previous layer’s output –
which went through the whole spatially-compress-and-decompress routine – and some preserved intermediate representation from
the “way down”. Like that, a U-Net architecture combines attention to detail with feature extraction.</p>
<p>In fact, this architecture, seen as a generic strategy, has been seen in many other places since its original appearance, and
itself is flexible enough to incorporate strategies from other architectures, such as, for exmple, ResNet blocks.</p>
</div>
<div id="example-application-mri-images" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Example application: MRI images</h2>
<p>Just as the architecture is flexible, applicability is broad. Our example will be about detecting abnormalities in brain
scans. The dataset, used in <span class="citation">(Buda, Saha, and Mazurowski <a href="#ref-BUDA2019218" role="doc-biblioref">2019</a>)</span>, contains MR images together with manual
<a href="https://en.wikipedia.org/wiki/Fluid-attenuated_inversion_recovery">FLAIR</a> abnormality segmentation masks. The dataset is
available on <a href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation">Kaggle</a>, and the paper is accompanied by a <a href="https://github.com/mateuszbuda/brain-segmentation-pytorch">GitHub
repository</a> that thankfully, includes all preprocessing steps.
While our model below will be more customizable and generic than the authors’, we completely follow their preprocessing
routines for the MRI data (basically just porting their Python code to R).</p>
<p>If you’re interested in this area of application, please consult the paper for background and additional information. If, on
the other hand, you’re mainly interested in the model, and plan to apply it to other types of data, feel free to just skim the
extensive preprocessing code, and focus on the architecture instead.</p>
<p>As will often be the case in medical imaging applications, there is a class imbalance in this data. For every patient,
sections have been taken at multiple positions (the number of sections per patient varies). Most sections will not have any
lesions, so the masks will be coloured black everywhere.</p>
<p>Here are three examples of orientations where the masks actually indicate an abnormality:</p>
<p><img src="images/scans.png" title="Examples of FLAIR images and corresponding masks" /></p>
<div class="sourceCode" id="cb109"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb109-1"><a href="unet.html#cb109-1"></a><span class="ex">montage</span> TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_15.tif  TCGA_DU_5871_19941206/TCGA_DU_5871_19941206_25.tif TCGA_FG_6689_20020326/TCGA_FG_6689_20020326_25.tif TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_15_mask.tif  TCGA_DU_5871_19941206/TCGA_DU_5871_19941206_25_mask.tif TCGA_FG_6689_20020326/TCGA_FG_6689_20020326_25_mask.tif -tile 3x3 -geometry +5+5 scans.tif</span></code></pre></div>
</div>
<div id="preprocessing" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Preprocessing</h2>
<div class="sourceCode" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="unet.html#cb110-1"></a><span class="im">import</span> torch</span>
<span id="cb110-2"><a href="unet.html#cb110-2"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb110-3"><a href="unet.html#cb110-3"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb110-4"><a href="unet.html#cb110-4"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb110-5"><a href="unet.html#cb110-5"></a></span>
<span id="cb110-6"><a href="unet.html#cb110-6"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb110-7"><a href="unet.html#cb110-7"></a><span class="im">import</span> os</span>
<span id="cb110-8"><a href="unet.html#cb110-8"></a><span class="im">import</span> copy</span>
<span id="cb110-9"><a href="unet.html#cb110-9"></a><span class="im">import</span> random</span>
<span id="cb110-10"><a href="unet.html#cb110-10"></a><span class="im">import</span> torchvision</span>
<span id="cb110-11"><a href="unet.html#cb110-11"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, models, transforms</span>
<span id="cb110-12"><a href="unet.html#cb110-12"></a></span>
<span id="cb110-13"><a href="unet.html#cb110-13"></a><span class="im">from</span> skimage.io <span class="im">import</span> imread</span></code></pre></div>
<p>The data comes organized into folders containing FLAIR images and masks for a single patient. We randomly partition these into
a training and a validation set, keeping the latter very small as overall, this dataset is not very big. (You might want to
experiment with different splits or better even, use a cross-validation approach. We don’t do that here as anyway, this
apllication example is pretty extensive already.) “Randomly” here meant we picked (at random) two patients from each
institution, as indicated by the pair of letters second in the folder names (tbd: check this!).</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="unet.html#cb111-1"></a>train_dir <span class="op">=</span> <span class="st">&quot;data/kaggle_3m_train&quot;</span></span>
<span id="cb111-2"><a href="unet.html#cb111-2"></a>valid_dir <span class="op">=</span> <span class="st">&quot;data/kaggle_3m_valid&quot;</span></span></code></pre></div>
<p>Preprocessing will be encapsulated in a <code>dataset</code> , that is, a structure that <code>torch</code> knows how to handle. Before we look at
that structure, let’s quickly look at helper functions and components it will make use of. As indicated above, these, as well
as <code>BrainSegmentationDataset</code> itself, are direct ports of the Python preprocessing logic in <a href="https://github.com/mateuszbuda/brain-segmentation-pytorch">Mateusz Buda’s GitHub
repository</a>.</p>
<div id="image-preprocessing-and-transforms" class="section level4" number="8.4.0.1">
<h4><span class="header-section-number">8.4.0.1</span> Image preprocessing and transforms</h4>
<p>Both FLAIR images and masks come in <code>.tif</code> format. These images have to be preprocessed spatially (cropped, padded and
resized), as well as normalized. The following functions will be called inside <code>BrainSegmentationDataset</code>:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="unet.html#cb112-1"></a>import numpy as np</span>
<span id="cb112-2"><a href="unet.html#cb112-2"></a>from medpy.filter.binary import largest_connected_component</span>
<span id="cb112-3"><a href="unet.html#cb112-3"></a>from skimage.exposure import rescale_intensity</span>
<span id="cb112-4"><a href="unet.html#cb112-4"></a>from skimage.transform import resize</span>
<span id="cb112-5"><a href="unet.html#cb112-5"></a></span>
<span id="cb112-6"><a href="unet.html#cb112-6"></a>def <span class="kw">crop_sample</span>(x)<span class="op">:</span></span>
<span id="cb112-7"><a href="unet.html#cb112-7"></a><span class="st">    </span>volume, mask =<span class="st"> </span>x</span>
<span id="cb112-8"><a href="unet.html#cb112-8"></a>    volume[volume <span class="op">&lt;</span><span class="st"> </span><span class="kw">np.max</span>(volume) <span class="op">*</span><span class="st"> </span><span class="fl">0.1</span>] =<span class="st"> </span><span class="dv">0</span></span>
<span id="cb112-9"><a href="unet.html#cb112-9"></a>    z_projection =<span class="st"> </span><span class="kw">np.max</span>(<span class="kw">np.max</span>(<span class="kw">np.max</span>(volume, <span class="dt">axis=</span><span class="op">-</span><span class="dv">1</span>), <span class="dt">axis=</span><span class="op">-</span><span class="dv">1</span>), <span class="dt">axis=</span><span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb112-10"><a href="unet.html#cb112-10"></a>    z_nonzero =<span class="st"> </span><span class="kw">np.nonzero</span>(z_projection)</span>
<span id="cb112-11"><a href="unet.html#cb112-11"></a>    z_min =<span class="st"> </span><span class="kw">np.min</span>(z_nonzero)</span>
<span id="cb112-12"><a href="unet.html#cb112-12"></a>    z_max =<span class="st"> </span><span class="kw">np.max</span>(z_nonzero) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb112-13"><a href="unet.html#cb112-13"></a>    y_projection =<span class="st"> </span><span class="kw">np.max</span>(<span class="kw">np.max</span>(<span class="kw">np.max</span>(volume, <span class="dt">axis=</span><span class="dv">0</span>), <span class="dt">axis=</span><span class="op">-</span><span class="dv">1</span>), <span class="dt">axis=</span><span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb112-14"><a href="unet.html#cb112-14"></a>    y_nonzero =<span class="st"> </span><span class="kw">np.nonzero</span>(y_projection)</span>
<span id="cb112-15"><a href="unet.html#cb112-15"></a>    y_min =<span class="st"> </span><span class="kw">np.min</span>(y_nonzero)</span>
<span id="cb112-16"><a href="unet.html#cb112-16"></a>    y_max =<span class="st"> </span><span class="kw">np.max</span>(y_nonzero) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb112-17"><a href="unet.html#cb112-17"></a>    x_projection =<span class="st"> </span><span class="kw">np.max</span>(<span class="kw">np.max</span>(<span class="kw">np.max</span>(volume, <span class="dt">axis=</span><span class="dv">0</span>), <span class="dt">axis=</span><span class="dv">0</span>), <span class="dt">axis=</span><span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb112-18"><a href="unet.html#cb112-18"></a>    x_nonzero =<span class="st"> </span><span class="kw">np.nonzero</span>(x_projection)</span>
<span id="cb112-19"><a href="unet.html#cb112-19"></a>    x_min =<span class="st"> </span><span class="kw">np.min</span>(x_nonzero)</span>
<span id="cb112-20"><a href="unet.html#cb112-20"></a>    x_max =<span class="st"> </span><span class="kw">np.max</span>(x_nonzero) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb112-21"><a href="unet.html#cb112-21"></a>    <span class="kw">return</span> (</span>
<span id="cb112-22"><a href="unet.html#cb112-22"></a>        volume[z_min<span class="op">:</span>z_max, y_min<span class="op">:</span>y_max, x_min<span class="op">:</span>x_max],</span>
<span id="cb112-23"><a href="unet.html#cb112-23"></a>        mask[z_min<span class="op">:</span>z_max, y_min<span class="op">:</span>y_max, x_min<span class="op">:</span>x_max],</span>
<span id="cb112-24"><a href="unet.html#cb112-24"></a>    )</span>
<span id="cb112-25"><a href="unet.html#cb112-25"></a></span>
<span id="cb112-26"><a href="unet.html#cb112-26"></a></span>
<span id="cb112-27"><a href="unet.html#cb112-27"></a>def <span class="kw">pad_sample</span>(x)<span class="op">:</span></span>
<span id="cb112-28"><a href="unet.html#cb112-28"></a><span class="st">    </span>volume, mask =<span class="st"> </span>x</span>
<span id="cb112-29"><a href="unet.html#cb112-29"></a>    a =<span class="st"> </span>volume.shape[<span class="dv">1</span>]</span>
<span id="cb112-30"><a href="unet.html#cb112-30"></a>    b =<span class="st"> </span>volume.shape[<span class="dv">2</span>]</span>
<span id="cb112-31"><a href="unet.html#cb112-31"></a>    <span class="cf">if</span> a <span class="op">==</span><span class="st"> </span>b<span class="op">:</span></span>
<span id="cb112-32"><a href="unet.html#cb112-32"></a><span class="st">        </span>return volume, mask</span>
<span id="cb112-33"><a href="unet.html#cb112-33"></a>    diff =<span class="st"> </span>(<span class="kw">max</span>(a, b) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(a, b)) <span class="op">/</span><span class="st"> </span><span class="fl">2.0</span></span>
<span id="cb112-34"><a href="unet.html#cb112-34"></a>    <span class="cf">if</span> a <span class="op">&gt;</span><span class="st"> </span>b<span class="op">:</span></span>
<span id="cb112-35"><a href="unet.html#cb112-35"></a><span class="st">        </span>padding =<span class="st"> </span>((<span class="dv">0</span>, <span class="dv">0</span>), (<span class="dv">0</span>, <span class="dv">0</span>), (<span class="kw">int</span>(<span class="kw">np.floor</span>(diff)), <span class="kw">int</span>(<span class="kw">np.ceil</span>(diff))))</span>
<span id="cb112-36"><a href="unet.html#cb112-36"></a>    <span class="cf">else</span><span class="op">:</span></span>
<span id="cb112-37"><a href="unet.html#cb112-37"></a><span class="st">        </span>padding =<span class="st"> </span>((<span class="dv">0</span>, <span class="dv">0</span>), (<span class="kw">int</span>(<span class="kw">np.floor</span>(diff)), <span class="kw">int</span>(<span class="kw">np.ceil</span>(diff))), (<span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb112-38"><a href="unet.html#cb112-38"></a>    mask =<span class="st"> </span><span class="kw">np.pad</span>(mask, padding, <span class="dt">mode=</span><span class="st">&quot;constant&quot;</span>, <span class="dt">constant_values=</span><span class="dv">0</span>)</span>
<span id="cb112-39"><a href="unet.html#cb112-39"></a>    padding =<span class="st"> </span>padding <span class="op">+</span><span class="st"> </span>((<span class="dv">0</span>, <span class="dv">0</span>),)</span>
<span id="cb112-40"><a href="unet.html#cb112-40"></a>    volume =<span class="st"> </span><span class="kw">np.pad</span>(volume, padding, <span class="dt">mode=</span><span class="st">&quot;constant&quot;</span>, <span class="dt">constant_values=</span><span class="dv">0</span>)</span>
<span id="cb112-41"><a href="unet.html#cb112-41"></a>    return volume, mask</span>
<span id="cb112-42"><a href="unet.html#cb112-42"></a></span>
<span id="cb112-43"><a href="unet.html#cb112-43"></a></span>
<span id="cb112-44"><a href="unet.html#cb112-44"></a>def <span class="kw">resize_sample</span>(x, <span class="dt">size=</span><span class="dv">256</span>)<span class="op">:</span></span>
<span id="cb112-45"><a href="unet.html#cb112-45"></a><span class="st">    </span>volume, mask =<span class="st"> </span>x</span>
<span id="cb112-46"><a href="unet.html#cb112-46"></a>    v_shape =<span class="st"> </span>volume.shape</span>
<span id="cb112-47"><a href="unet.html#cb112-47"></a>    out_shape =<span class="st"> </span>(v_shape[<span class="dv">0</span>], size, size)</span>
<span id="cb112-48"><a href="unet.html#cb112-48"></a>    mask =<span class="st"> </span><span class="kw">resize</span>(</span>
<span id="cb112-49"><a href="unet.html#cb112-49"></a>        mask,</span>
<span id="cb112-50"><a href="unet.html#cb112-50"></a>        <span class="dt">output_shape=</span>out_shape,</span>
<span id="cb112-51"><a href="unet.html#cb112-51"></a>        <span class="dt">order=</span><span class="dv">0</span>,</span>
<span id="cb112-52"><a href="unet.html#cb112-52"></a>        <span class="dt">mode=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb112-53"><a href="unet.html#cb112-53"></a>        <span class="dt">cval=</span><span class="dv">0</span>,</span>
<span id="cb112-54"><a href="unet.html#cb112-54"></a>        <span class="dt">anti_aliasing=</span>False,</span>
<span id="cb112-55"><a href="unet.html#cb112-55"></a>    )</span>
<span id="cb112-56"><a href="unet.html#cb112-56"></a>    out_shape =<span class="st"> </span>out_shape <span class="op">+</span><span class="st"> </span>(v_shape[<span class="dv">3</span>],)</span>
<span id="cb112-57"><a href="unet.html#cb112-57"></a>    volume =<span class="st"> </span><span class="kw">resize</span>(</span>
<span id="cb112-58"><a href="unet.html#cb112-58"></a>        volume,</span>
<span id="cb112-59"><a href="unet.html#cb112-59"></a>        <span class="dt">output_shape=</span>out_shape,</span>
<span id="cb112-60"><a href="unet.html#cb112-60"></a>        <span class="dt">order=</span><span class="dv">2</span>,</span>
<span id="cb112-61"><a href="unet.html#cb112-61"></a>        <span class="dt">mode=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb112-62"><a href="unet.html#cb112-62"></a>        <span class="dt">cval=</span><span class="dv">0</span>,</span>
<span id="cb112-63"><a href="unet.html#cb112-63"></a>        <span class="dt">anti_aliasing=</span>False,</span>
<span id="cb112-64"><a href="unet.html#cb112-64"></a>    )</span>
<span id="cb112-65"><a href="unet.html#cb112-65"></a>    return volume, mask</span>
<span id="cb112-66"><a href="unet.html#cb112-66"></a></span>
<span id="cb112-67"><a href="unet.html#cb112-67"></a></span>
<span id="cb112-68"><a href="unet.html#cb112-68"></a>def <span class="kw">normalize_volume</span>(volume)<span class="op">:</span></span>
<span id="cb112-69"><a href="unet.html#cb112-69"></a><span class="st">    </span>p10 =<span class="st"> </span><span class="kw">np.percentile</span>(volume, <span class="dv">10</span>)</span>
<span id="cb112-70"><a href="unet.html#cb112-70"></a>    p99 =<span class="st"> </span><span class="kw">np.percentile</span>(volume, <span class="dv">99</span>)</span>
<span id="cb112-71"><a href="unet.html#cb112-71"></a>    volume =<span class="st"> </span><span class="kw">rescale_intensity</span>(volume, <span class="dt">in_range=</span>(p10, p99))</span>
<span id="cb112-72"><a href="unet.html#cb112-72"></a>    m =<span class="st"> </span><span class="kw">np.mean</span>(volume, <span class="dt">axis=</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb112-73"><a href="unet.html#cb112-73"></a>    s =<span class="st"> </span><span class="kw">np.std</span>(volume, <span class="dt">axis=</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb112-74"><a href="unet.html#cb112-74"></a>    volume =<span class="st"> </span>(volume <span class="op">-</span><span class="st"> </span>m) <span class="op">/</span><span class="st"> </span>s</span>
<span id="cb112-75"><a href="unet.html#cb112-75"></a>    return volume</span></code></pre></div>
<p>On the training set, we’ll also want to use data augmentation. Here are the relative <code>Transform</code>s:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="unet.html#cb113-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb113-2"><a href="unet.html#cb113-2"></a><span class="im">from</span> skimage.transform <span class="im">import</span> rescale, rotate</span>
<span id="cb113-3"><a href="unet.html#cb113-3"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> Compose</span>
<span id="cb113-4"><a href="unet.html#cb113-4"></a></span>
<span id="cb113-5"><a href="unet.html#cb113-5"></a></span>
<span id="cb113-6"><a href="unet.html#cb113-6"></a><span class="kw">def</span> transforms(scale<span class="op">=</span><span class="va">None</span>, angle<span class="op">=</span><span class="va">None</span>, flip_prob<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb113-7"><a href="unet.html#cb113-7"></a>    transform_list <span class="op">=</span> []</span>
<span id="cb113-8"><a href="unet.html#cb113-8"></a></span>
<span id="cb113-9"><a href="unet.html#cb113-9"></a>    <span class="cf">if</span> scale <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb113-10"><a href="unet.html#cb113-10"></a>        transform_list.append(Scale(scale))</span>
<span id="cb113-11"><a href="unet.html#cb113-11"></a>    <span class="cf">if</span> angle <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb113-12"><a href="unet.html#cb113-12"></a>        transform_list.append(Rotate(angle))</span>
<span id="cb113-13"><a href="unet.html#cb113-13"></a>    <span class="cf">if</span> flip_prob <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb113-14"><a href="unet.html#cb113-14"></a>        transform_list.append(HorizontalFlip(flip_prob))</span>
<span id="cb113-15"><a href="unet.html#cb113-15"></a></span>
<span id="cb113-16"><a href="unet.html#cb113-16"></a>    <span class="cf">return</span> Compose(transform_list)</span>
<span id="cb113-17"><a href="unet.html#cb113-17"></a></span>
<span id="cb113-18"><a href="unet.html#cb113-18"></a></span>
<span id="cb113-19"><a href="unet.html#cb113-19"></a><span class="kw">class</span> Scale(<span class="bu">object</span>):</span>
<span id="cb113-20"><a href="unet.html#cb113-20"></a></span>
<span id="cb113-21"><a href="unet.html#cb113-21"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, scale):</span>
<span id="cb113-22"><a href="unet.html#cb113-22"></a>        <span class="va">self</span>.scale <span class="op">=</span> scale</span>
<span id="cb113-23"><a href="unet.html#cb113-23"></a></span>
<span id="cb113-24"><a href="unet.html#cb113-24"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, sample):</span>
<span id="cb113-25"><a href="unet.html#cb113-25"></a>        image, mask <span class="op">=</span> sample</span>
<span id="cb113-26"><a href="unet.html#cb113-26"></a></span>
<span id="cb113-27"><a href="unet.html#cb113-27"></a>        img_size <span class="op">=</span> image.shape[<span class="dv">0</span>]</span>
<span id="cb113-28"><a href="unet.html#cb113-28"></a></span>
<span id="cb113-29"><a href="unet.html#cb113-29"></a>        scale <span class="op">=</span> np.random.uniform(low<span class="op">=</span><span class="fl">1.0</span> <span class="op">-</span> <span class="va">self</span>.scale, high<span class="op">=</span><span class="fl">1.0</span> <span class="op">+</span> <span class="va">self</span>.scale)</span>
<span id="cb113-30"><a href="unet.html#cb113-30"></a></span>
<span id="cb113-31"><a href="unet.html#cb113-31"></a>        image <span class="op">=</span> rescale(</span>
<span id="cb113-32"><a href="unet.html#cb113-32"></a>            image,</span>
<span id="cb113-33"><a href="unet.html#cb113-33"></a>            (scale, scale),</span>
<span id="cb113-34"><a href="unet.html#cb113-34"></a>            multichannel<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb113-35"><a href="unet.html#cb113-35"></a>            preserve_range<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb113-36"><a href="unet.html#cb113-36"></a>            mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb113-37"><a href="unet.html#cb113-37"></a>            anti_aliasing<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb113-38"><a href="unet.html#cb113-38"></a>        )</span>
<span id="cb113-39"><a href="unet.html#cb113-39"></a>        mask <span class="op">=</span> rescale(</span>
<span id="cb113-40"><a href="unet.html#cb113-40"></a>            mask,</span>
<span id="cb113-41"><a href="unet.html#cb113-41"></a>            (scale, scale),</span>
<span id="cb113-42"><a href="unet.html#cb113-42"></a>            order<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb113-43"><a href="unet.html#cb113-43"></a>            multichannel<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb113-44"><a href="unet.html#cb113-44"></a>            preserve_range<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb113-45"><a href="unet.html#cb113-45"></a>            mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>,</span>
<span id="cb113-46"><a href="unet.html#cb113-46"></a>            anti_aliasing<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb113-47"><a href="unet.html#cb113-47"></a>        )</span>
<span id="cb113-48"><a href="unet.html#cb113-48"></a></span>
<span id="cb113-49"><a href="unet.html#cb113-49"></a>        <span class="cf">if</span> scale <span class="op">&lt;</span> <span class="fl">1.0</span>:</span>
<span id="cb113-50"><a href="unet.html#cb113-50"></a>            diff <span class="op">=</span> (img_size <span class="op">-</span> image.shape[<span class="dv">0</span>]) <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb113-51"><a href="unet.html#cb113-51"></a>            padding <span class="op">=</span> ((<span class="bu">int</span>(np.floor(diff)), <span class="bu">int</span>(np.ceil(diff))),) <span class="op">*</span> <span class="dv">2</span> <span class="op">+</span> ((<span class="dv">0</span>, <span class="dv">0</span>),)</span>
<span id="cb113-52"><a href="unet.html#cb113-52"></a>            image <span class="op">=</span> np.pad(image, padding, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>, constant_values<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb113-53"><a href="unet.html#cb113-53"></a>            mask <span class="op">=</span> np.pad(mask, padding, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>, constant_values<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb113-54"><a href="unet.html#cb113-54"></a>        <span class="cf">else</span>:</span>
<span id="cb113-55"><a href="unet.html#cb113-55"></a>            x_min <span class="op">=</span> (image.shape[<span class="dv">0</span>] <span class="op">-</span> img_size) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb113-56"><a href="unet.html#cb113-56"></a>            x_max <span class="op">=</span> x_min <span class="op">+</span> img_size</span>
<span id="cb113-57"><a href="unet.html#cb113-57"></a>            image <span class="op">=</span> image[x_min:x_max, x_min:x_max, ...]</span>
<span id="cb113-58"><a href="unet.html#cb113-58"></a>            mask <span class="op">=</span> mask[x_min:x_max, x_min:x_max, ...]</span>
<span id="cb113-59"><a href="unet.html#cb113-59"></a></span>
<span id="cb113-60"><a href="unet.html#cb113-60"></a>        <span class="cf">return</span> image, mask</span>
<span id="cb113-61"><a href="unet.html#cb113-61"></a></span>
<span id="cb113-62"><a href="unet.html#cb113-62"></a></span>
<span id="cb113-63"><a href="unet.html#cb113-63"></a><span class="kw">class</span> Rotate(<span class="bu">object</span>):</span>
<span id="cb113-64"><a href="unet.html#cb113-64"></a></span>
<span id="cb113-65"><a href="unet.html#cb113-65"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, angle):</span>
<span id="cb113-66"><a href="unet.html#cb113-66"></a>        <span class="va">self</span>.angle <span class="op">=</span> angle</span>
<span id="cb113-67"><a href="unet.html#cb113-67"></a></span>
<span id="cb113-68"><a href="unet.html#cb113-68"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, sample):</span>
<span id="cb113-69"><a href="unet.html#cb113-69"></a>        image, mask <span class="op">=</span> sample</span>
<span id="cb113-70"><a href="unet.html#cb113-70"></a></span>
<span id="cb113-71"><a href="unet.html#cb113-71"></a>        angle <span class="op">=</span> np.random.uniform(low<span class="op">=-</span><span class="va">self</span>.angle, high<span class="op">=</span><span class="va">self</span>.angle)</span>
<span id="cb113-72"><a href="unet.html#cb113-72"></a>        image <span class="op">=</span> rotate(image, angle, resize<span class="op">=</span><span class="va">False</span>, preserve_range<span class="op">=</span><span class="va">True</span>, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span>)</span>
<span id="cb113-73"><a href="unet.html#cb113-73"></a>        mask <span class="op">=</span> rotate(</span>
<span id="cb113-74"><a href="unet.html#cb113-74"></a>            mask, angle, resize<span class="op">=</span><span class="va">False</span>, order<span class="op">=</span><span class="dv">0</span>, preserve_range<span class="op">=</span><span class="va">True</span>, mode<span class="op">=</span><span class="st">&quot;constant&quot;</span></span>
<span id="cb113-75"><a href="unet.html#cb113-75"></a>        )</span>
<span id="cb113-76"><a href="unet.html#cb113-76"></a>        <span class="cf">return</span> image, mask</span>
<span id="cb113-77"><a href="unet.html#cb113-77"></a></span>
<span id="cb113-78"><a href="unet.html#cb113-78"></a></span>
<span id="cb113-79"><a href="unet.html#cb113-79"></a><span class="kw">class</span> HorizontalFlip(<span class="bu">object</span>):</span>
<span id="cb113-80"><a href="unet.html#cb113-80"></a></span>
<span id="cb113-81"><a href="unet.html#cb113-81"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, flip_prob):</span>
<span id="cb113-82"><a href="unet.html#cb113-82"></a>        <span class="va">self</span>.flip_prob <span class="op">=</span> flip_prob</span>
<span id="cb113-83"><a href="unet.html#cb113-83"></a></span>
<span id="cb113-84"><a href="unet.html#cb113-84"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, sample):</span>
<span id="cb113-85"><a href="unet.html#cb113-85"></a>        image, mask <span class="op">=</span> sample</span>
<span id="cb113-86"><a href="unet.html#cb113-86"></a></span>
<span id="cb113-87"><a href="unet.html#cb113-87"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&gt;</span> <span class="va">self</span>.flip_prob:</span>
<span id="cb113-88"><a href="unet.html#cb113-88"></a>            <span class="cf">return</span> image, mask</span>
<span id="cb113-89"><a href="unet.html#cb113-89"></a></span>
<span id="cb113-90"><a href="unet.html#cb113-90"></a>        image <span class="op">=</span> np.fliplr(image).copy()</span>
<span id="cb113-91"><a href="unet.html#cb113-91"></a>        mask <span class="op">=</span> np.fliplr(mask).copy()</span>
<span id="cb113-92"><a href="unet.html#cb113-92"></a></span>
<span id="cb113-93"><a href="unet.html#cb113-93"></a>        <span class="cf">return</span> image, mask</span></code></pre></div>
</div>
<div id="brainsegmentationdataset" class="section level4" number="8.4.0.2">
<h4><span class="header-section-number">8.4.0.2</span> BrainSegmentationDataset</h4>
<p>The <code>BrainSegmentationDataset</code> walks through a given directory, applies preprocessing and - possibly – transformations, and
returns batches of tensors as requested. Through the <code>init</code> method’s <code>random_sampling</code> parameter, you can control whether
<em>weighted sampling</em> should be applied to counter class imbalance: If set to true, FLAIR-mask pairs will be sampled in
proportion to lesion size. From our experiments, training on this dataset is sped up by using weighted sampling, but final
training performance is not much affected, and neither is performance on the validation set.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="unet.html#cb114-1"></a><span class="kw">class</span> BrainSegmentationDataset(Dataset):</span>
<span id="cb114-2"><a href="unet.html#cb114-2"></a>    <span class="co">&quot;&quot;&quot;Brain MRI dataset for FLAIR abnormality segmentation&quot;&quot;&quot;</span></span>
<span id="cb114-3"><a href="unet.html#cb114-3"></a>    in_channels <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb114-4"><a href="unet.html#cb114-4"></a>    out_channels <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb114-5"><a href="unet.html#cb114-5"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb114-6"><a href="unet.html#cb114-6"></a>        <span class="va">self</span>,</span>
<span id="cb114-7"><a href="unet.html#cb114-7"></a>        images_dir,</span>
<span id="cb114-8"><a href="unet.html#cb114-8"></a>        transform <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb114-9"><a href="unet.html#cb114-9"></a>        image_size <span class="op">=</span> <span class="dv">256</span>,</span>
<span id="cb114-10"><a href="unet.html#cb114-10"></a>        random_sampling <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb114-11"><a href="unet.html#cb114-11"></a>    ):</span>
<span id="cb114-12"><a href="unet.html#cb114-12"></a>        volumes <span class="op">=</span> {}</span>
<span id="cb114-13"><a href="unet.html#cb114-13"></a>        masks <span class="op">=</span> {}</span>
<span id="cb114-14"><a href="unet.html#cb114-14"></a>        <span class="bu">print</span>(<span class="st">&quot;reading images...&quot;</span>)</span>
<span id="cb114-15"><a href="unet.html#cb114-15"></a>        <span class="cf">for</span> (dirpath, dirnames, filenames) <span class="kw">in</span> os.walk(images_dir):</span>
<span id="cb114-16"><a href="unet.html#cb114-16"></a>            image_slices <span class="op">=</span> []</span>
<span id="cb114-17"><a href="unet.html#cb114-17"></a>            mask_slices <span class="op">=</span> []</span>
<span id="cb114-18"><a href="unet.html#cb114-18"></a>            <span class="cf">for</span> filename <span class="kw">in</span> <span class="bu">sorted</span>(</span>
<span id="cb114-19"><a href="unet.html#cb114-19"></a>                <span class="bu">filter</span>(<span class="kw">lambda</span> f: <span class="st">&quot;.tif&quot;</span> <span class="kw">in</span> f, filenames),</span>
<span id="cb114-20"><a href="unet.html#cb114-20"></a>                key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">int</span>(x.split(<span class="st">&quot;.&quot;</span>)[<span class="op">-</span><span class="dv">2</span>].split(<span class="st">&quot;_&quot;</span>)[<span class="dv">4</span>]),</span>
<span id="cb114-21"><a href="unet.html#cb114-21"></a>            ):</span>
<span id="cb114-22"><a href="unet.html#cb114-22"></a>                filepath <span class="op">=</span> os.path.join(dirpath, filename)</span>
<span id="cb114-23"><a href="unet.html#cb114-23"></a>                <span class="cf">if</span> <span class="st">&quot;mask&quot;</span> <span class="kw">in</span> filename:</span>
<span id="cb114-24"><a href="unet.html#cb114-24"></a>                    mask_slices.append(imread(filepath, as_gray<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb114-25"><a href="unet.html#cb114-25"></a>                <span class="cf">else</span>:</span>
<span id="cb114-26"><a href="unet.html#cb114-26"></a>                    image_slices.append(imread(filepath))</span>
<span id="cb114-27"><a href="unet.html#cb114-27"></a>            <span class="cf">if</span> <span class="bu">len</span>(image_slices) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb114-28"><a href="unet.html#cb114-28"></a>                patient_id <span class="op">=</span> dirpath.split(<span class="st">&quot;/&quot;</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb114-29"><a href="unet.html#cb114-29"></a>                volumes[patient_id] <span class="op">=</span> np.array(image_slices[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb114-30"><a href="unet.html#cb114-30"></a>                masks[patient_id] <span class="op">=</span> np.array(mask_slices[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb114-31"><a href="unet.html#cb114-31"></a>        <span class="va">self</span>.patients <span class="op">=</span> <span class="bu">sorted</span>(volumes)</span>
<span id="cb114-32"><a href="unet.html#cb114-32"></a>        <span class="bu">print</span>(<span class="st">&quot;preprocessing volumes...&quot;</span>)</span>
<span id="cb114-33"><a href="unet.html#cb114-33"></a>        <span class="co"># create list of tuples (volume, mask)</span></span>
<span id="cb114-34"><a href="unet.html#cb114-34"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [(volumes[k], masks[k]) <span class="cf">for</span> k <span class="kw">in</span> <span class="va">self</span>.patients]</span>
<span id="cb114-35"><a href="unet.html#cb114-35"></a>        <span class="bu">print</span>(<span class="st">&quot;cropping volumes...&quot;</span>)</span>
<span id="cb114-36"><a href="unet.html#cb114-36"></a>        <span class="co"># crop to smallest enclosing volume</span></span>
<span id="cb114-37"><a href="unet.html#cb114-37"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [crop_sample(v) <span class="cf">for</span> v <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb114-38"><a href="unet.html#cb114-38"></a>        <span class="bu">print</span>(<span class="st">&quot;padding volumes...&quot;</span>)</span>
<span id="cb114-39"><a href="unet.html#cb114-39"></a>        <span class="co"># pad to square</span></span>
<span id="cb114-40"><a href="unet.html#cb114-40"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [pad_sample(v) <span class="cf">for</span> v <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb114-41"><a href="unet.html#cb114-41"></a>        <span class="bu">print</span>(<span class="st">&quot;resizing volumes...&quot;</span>)</span>
<span id="cb114-42"><a href="unet.html#cb114-42"></a>        <span class="co"># resize</span></span>
<span id="cb114-43"><a href="unet.html#cb114-43"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [resize_sample(v, size<span class="op">=</span>image_size) <span class="cf">for</span> v <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb114-44"><a href="unet.html#cb114-44"></a>        <span class="bu">print</span>(<span class="st">&quot;normalizing volumes...&quot;</span>)</span>
<span id="cb114-45"><a href="unet.html#cb114-45"></a>        <span class="co"># normalize channel-wise</span></span>
<span id="cb114-46"><a href="unet.html#cb114-46"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [(normalize_volume(v), m) <span class="cf">for</span> v, m <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb114-47"><a href="unet.html#cb114-47"></a>        <span class="co"># probabilities for sampling slices based on masks</span></span>
<span id="cb114-48"><a href="unet.html#cb114-48"></a>        <span class="va">self</span>.slice_weights <span class="op">=</span> [m.<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>).<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>) <span class="cf">for</span> v, m <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb114-49"><a href="unet.html#cb114-49"></a>        <span class="va">self</span>.slice_weights <span class="op">=</span> [</span>
<span id="cb114-50"><a href="unet.html#cb114-50"></a>            (s <span class="op">+</span> (s.<span class="bu">sum</span>() <span class="op">*</span> <span class="fl">0.1</span> <span class="op">/</span> <span class="bu">len</span>(s))) <span class="op">/</span> (s.<span class="bu">sum</span>() <span class="op">*</span> <span class="fl">1.1</span>) <span class="cf">for</span> s <span class="kw">in</span> <span class="va">self</span>.slice_weights</span>
<span id="cb114-51"><a href="unet.html#cb114-51"></a>        ]</span>
<span id="cb114-52"><a href="unet.html#cb114-52"></a>        <span class="co"># add channel dimension to masks</span></span>
<span id="cb114-53"><a href="unet.html#cb114-53"></a>        <span class="va">self</span>.volumes <span class="op">=</span> [(v, m[..., np.newaxis]) <span class="cf">for</span> (v, m) <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb114-54"><a href="unet.html#cb114-54"></a>        <span class="bu">print</span>(<span class="st">&quot;done creating dataset&quot;</span>)</span>
<span id="cb114-55"><a href="unet.html#cb114-55"></a>        <span class="co"># create global index for patient and slice (idx -&gt; (p_idx, s_idx))</span></span>
<span id="cb114-56"><a href="unet.html#cb114-56"></a>        num_slices <span class="op">=</span> [v.shape[<span class="dv">0</span>] <span class="cf">for</span> v, m <span class="kw">in</span> <span class="va">self</span>.volumes]</span>
<span id="cb114-57"><a href="unet.html#cb114-57"></a>        <span class="va">self</span>.patient_slice_index <span class="op">=</span> <span class="bu">list</span>(</span>
<span id="cb114-58"><a href="unet.html#cb114-58"></a>            <span class="bu">zip</span>(</span>
<span id="cb114-59"><a href="unet.html#cb114-59"></a>                <span class="bu">sum</span>([[i] <span class="op">*</span> num_slices[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(num_slices))], []),</span>
<span id="cb114-60"><a href="unet.html#cb114-60"></a>                <span class="bu">sum</span>([<span class="bu">list</span>(<span class="bu">range</span>(x)) <span class="cf">for</span> x <span class="kw">in</span> num_slices], []),</span>
<span id="cb114-61"><a href="unet.html#cb114-61"></a>            )</span>
<span id="cb114-62"><a href="unet.html#cb114-62"></a>        )</span>
<span id="cb114-63"><a href="unet.html#cb114-63"></a>        <span class="va">self</span>.random_sampling <span class="op">=</span> random_sampling</span>
<span id="cb114-64"><a href="unet.html#cb114-64"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb114-65"><a href="unet.html#cb114-65"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb114-66"><a href="unet.html#cb114-66"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.patient_slice_index)</span>
<span id="cb114-67"><a href="unet.html#cb114-67"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb114-68"><a href="unet.html#cb114-68"></a>        patient <span class="op">=</span> <span class="va">self</span>.patient_slice_index[idx][<span class="dv">0</span>]</span>
<span id="cb114-69"><a href="unet.html#cb114-69"></a>        slice_n <span class="op">=</span> <span class="va">self</span>.patient_slice_index[idx][<span class="dv">1</span>]</span>
<span id="cb114-70"><a href="unet.html#cb114-70"></a>        <span class="cf">if</span> <span class="va">self</span>.random_sampling:</span>
<span id="cb114-71"><a href="unet.html#cb114-71"></a>            patient <span class="op">=</span> np.random.randint(<span class="bu">len</span>(<span class="va">self</span>.volumes))</span>
<span id="cb114-72"><a href="unet.html#cb114-72"></a>            slice_n <span class="op">=</span> np.random.choice(</span>
<span id="cb114-73"><a href="unet.html#cb114-73"></a>                <span class="bu">range</span>(<span class="va">self</span>.volumes[patient][<span class="dv">0</span>].shape[<span class="dv">0</span>]), p<span class="op">=</span><span class="va">self</span>.slice_weights[patient]</span>
<span id="cb114-74"><a href="unet.html#cb114-74"></a>            )</span>
<span id="cb114-75"><a href="unet.html#cb114-75"></a>        v, m <span class="op">=</span> <span class="va">self</span>.volumes[patient]</span>
<span id="cb114-76"><a href="unet.html#cb114-76"></a>        image <span class="op">=</span> v[slice_n]</span>
<span id="cb114-77"><a href="unet.html#cb114-77"></a>        mask <span class="op">=</span> m[slice_n]</span>
<span id="cb114-78"><a href="unet.html#cb114-78"></a>        <span class="cf">if</span> <span class="va">self</span>.transform <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb114-79"><a href="unet.html#cb114-79"></a>            image, mask <span class="op">=</span> <span class="va">self</span>.transform((image, mask))</span>
<span id="cb114-80"><a href="unet.html#cb114-80"></a>        <span class="co"># fix dimensions (C, H, W)</span></span>
<span id="cb114-81"><a href="unet.html#cb114-81"></a>        image <span class="op">=</span> image.transpose(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb114-82"><a href="unet.html#cb114-82"></a>        mask <span class="op">=</span> mask.transpose(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb114-83"><a href="unet.html#cb114-83"></a>        image_tensor <span class="op">=</span> torch.from_numpy(image.astype(np.float32))</span>
<span id="cb114-84"><a href="unet.html#cb114-84"></a>        mask_tensor <span class="op">=</span> torch.from_numpy(mask.astype(np.float32))</span>
<span id="cb114-85"><a href="unet.html#cb114-85"></a>        <span class="co"># return tensors</span></span>
<span id="cb114-86"><a href="unet.html#cb114-86"></a>        <span class="cf">return</span> image_tensor, mask_tensor</span></code></pre></div>
</div>
<div id="loading-the-data" class="section level4" number="8.4.0.3">
<h4><span class="header-section-number">8.4.0.3</span> Loading the data</h4>
<p>We use data augmentation and shuffling on the training set, and none of those on the validation set:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="unet.html#cb115-1"></a>image_size <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb115-2"><a href="unet.html#cb115-2"></a>aug_scale <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb115-3"><a href="unet.html#cb115-3"></a>aug_angle <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb115-4"><a href="unet.html#cb115-4"></a>flip_prob <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb115-5"><a href="unet.html#cb115-5"></a></span>
<span id="cb115-6"><a href="unet.html#cb115-6"></a>train_ds <span class="op">=</span> BrainSegmentationDataset(</span>
<span id="cb115-7"><a href="unet.html#cb115-7"></a>        images_dir <span class="op">=</span> train_dir,</span>
<span id="cb115-8"><a href="unet.html#cb115-8"></a>        image_size <span class="op">=</span> image_size,</span>
<span id="cb115-9"><a href="unet.html#cb115-9"></a>        transform <span class="op">=</span> transforms(scale <span class="op">=</span> aug_scale, angle <span class="op">=</span> aug_angle, flip_prob<span class="op">=</span><span class="fl">0.5</span>),</span>
<span id="cb115-10"><a href="unet.html#cb115-10"></a>        random_sampling <span class="op">=</span> <span class="va">True</span></span>
<span id="cb115-11"><a href="unet.html#cb115-11"></a>)</span>
<span id="cb115-12"><a href="unet.html#cb115-12"></a></span>
<span id="cb115-13"><a href="unet.html#cb115-13"></a>valid_ds <span class="op">=</span> BrainSegmentationDataset(</span>
<span id="cb115-14"><a href="unet.html#cb115-14"></a>        images_dir <span class="op">=</span> valid_dir,</span>
<span id="cb115-15"><a href="unet.html#cb115-15"></a>        image_size <span class="op">=</span> image_size,</span>
<span id="cb115-16"><a href="unet.html#cb115-16"></a>        random_sampling<span class="op">=</span><span class="va">False</span></span>
<span id="cb115-17"><a href="unet.html#cb115-17"></a>)</span>
<span id="cb115-18"><a href="unet.html#cb115-18"></a></span>
<span id="cb115-19"><a href="unet.html#cb115-19"></a>batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb115-20"><a href="unet.html#cb115-20"></a></span>
<span id="cb115-21"><a href="unet.html#cb115-21"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb115-22"><a href="unet.html#cb115-22"></a>        train_ds,</span>
<span id="cb115-23"><a href="unet.html#cb115-23"></a>        batch_size <span class="op">=</span> batch_size,</span>
<span id="cb115-24"><a href="unet.html#cb115-24"></a>        shuffle <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb115-25"><a href="unet.html#cb115-25"></a>        drop_last <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb115-26"><a href="unet.html#cb115-26"></a>        num_workers <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb115-27"><a href="unet.html#cb115-27"></a>)</span>
<span id="cb115-28"><a href="unet.html#cb115-28"></a></span>
<span id="cb115-29"><a href="unet.html#cb115-29"></a>valid_loader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb115-30"><a href="unet.html#cb115-30"></a>        valid_ds,</span>
<span id="cb115-31"><a href="unet.html#cb115-31"></a>        batch_size <span class="op">=</span> batch_size,</span>
<span id="cb115-32"><a href="unet.html#cb115-32"></a>        drop_last <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb115-33"><a href="unet.html#cb115-33"></a>)</span>
<span id="cb115-34"><a href="unet.html#cb115-34"></a></span>
<span id="cb115-35"><a href="unet.html#cb115-35"></a>dataloaders <span class="op">=</span> {<span class="st">&quot;train&quot;</span>: train_loader, <span class="st">&quot;valid&quot;</span>: valid_loader}</span>
<span id="cb115-36"><a href="unet.html#cb115-36"></a>dataset_sizes <span class="op">=</span> {x: <span class="bu">len</span>(dataloaders[x]) <span class="cf">for</span> x <span class="kw">in</span> [<span class="st">&#39;train&#39;</span>, <span class="st">&#39;valid&#39;</span>]}</span></code></pre></div>
<p>On to the model.</p>
</div>
</div>
<div id="u-net-model" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> U-Net model</h2>
<p>We formulate the model in a generic way: The layers for the <em>up</em> and <em>down</em> paths are kept in lists. During the downward pass,
the model saves away the intermediate activations, and during the upward phase, passes them on for concatenation (and thus,
use in upsampling) as required.</p>
<p>Model depth is configurable (<code>depth</code>), as is a starting point for the number of filters (<code>n_filters</code>): The first downward
convolution block will have <code>2^n_filters</code> channels, and in every successive convolution block the exponent will be incremented
by one.</p>
<p>tbd other args</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="unet.html#cb116-1"></a><span class="kw">class</span> UNet(nn.Module):</span>
<span id="cb116-2"><a href="unet.html#cb116-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb116-3"><a href="unet.html#cb116-3"></a>        <span class="va">self</span>,</span>
<span id="cb116-4"><a href="unet.html#cb116-4"></a>        channels_in <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb116-5"><a href="unet.html#cb116-5"></a>        n_classes <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb116-6"><a href="unet.html#cb116-6"></a>        depth <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb116-7"><a href="unet.html#cb116-7"></a>        n_filters <span class="op">=</span> <span class="dv">6</span>, </span>
<span id="cb116-8"><a href="unet.html#cb116-8"></a>    ):</span>
<span id="cb116-9"><a href="unet.html#cb116-9"></a>        <span class="bu">super</span>(UNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb116-10"><a href="unet.html#cb116-10"></a>        <span class="va">self</span>.depth <span class="op">=</span> depth</span>
<span id="cb116-11"><a href="unet.html#cb116-11"></a>        prev_channels <span class="op">=</span> channels_in</span>
<span id="cb116-12"><a href="unet.html#cb116-12"></a>        <span class="va">self</span>.down_path <span class="op">=</span> nn.ModuleList()</span>
<span id="cb116-13"><a href="unet.html#cb116-13"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(depth):</span>
<span id="cb116-14"><a href="unet.html#cb116-14"></a>            <span class="va">self</span>.down_path.append(</span>
<span id="cb116-15"><a href="unet.html#cb116-15"></a>                DownBlock(prev_channels, <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i))</span>
<span id="cb116-16"><a href="unet.html#cb116-16"></a>            )</span>
<span id="cb116-17"><a href="unet.html#cb116-17"></a>            prev_channels <span class="op">=</span> <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i)</span>
<span id="cb116-18"><a href="unet.html#cb116-18"></a>        <span class="va">self</span>.up_path <span class="op">=</span> nn.ModuleList()</span>
<span id="cb116-19"><a href="unet.html#cb116-19"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(depth <span class="op">-</span> <span class="dv">1</span>)):</span>
<span id="cb116-20"><a href="unet.html#cb116-20"></a>            <span class="va">self</span>.up_path.append(</span>
<span id="cb116-21"><a href="unet.html#cb116-21"></a>                UpBlock(prev_channels, <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i))</span>
<span id="cb116-22"><a href="unet.html#cb116-22"></a>            )</span>
<span id="cb116-23"><a href="unet.html#cb116-23"></a>            prev_channels <span class="op">=</span> <span class="dv">2</span> <span class="op">**</span> (n_filters <span class="op">+</span> i)</span>
<span id="cb116-24"><a href="unet.html#cb116-24"></a>        <span class="va">self</span>.last <span class="op">=</span> nn.Conv2d(prev_channels, n_classes, kernel_size <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb116-25"><a href="unet.html#cb116-25"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb116-26"><a href="unet.html#cb116-26"></a>        blocks <span class="op">=</span> []</span>
<span id="cb116-27"><a href="unet.html#cb116-27"></a>        <span class="cf">for</span> i, down <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.down_path):</span>
<span id="cb116-28"><a href="unet.html#cb116-28"></a>            x <span class="op">=</span> down(x)</span>
<span id="cb116-29"><a href="unet.html#cb116-29"></a>            <span class="cf">if</span> i <span class="op">!=</span> <span class="bu">len</span>(<span class="va">self</span>.down_path) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb116-30"><a href="unet.html#cb116-30"></a>                blocks.append(x)</span>
<span id="cb116-31"><a href="unet.html#cb116-31"></a>                x <span class="op">=</span> F.max_pool2d(x, <span class="dv">2</span>)</span>
<span id="cb116-32"><a href="unet.html#cb116-32"></a>        <span class="cf">for</span> i, up <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.up_path):</span>
<span id="cb116-33"><a href="unet.html#cb116-33"></a>            x <span class="op">=</span> up(x, blocks[<span class="op">-</span>i <span class="op">-</span> <span class="dv">1</span>])</span>
<span id="cb116-34"><a href="unet.html#cb116-34"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.last(x))</span>
<span id="cb116-35"><a href="unet.html#cb116-35"></a>{r}</span></code></pre></div>
<div id="heading" class="section level3" number="8.5.1">
<h3><span class="header-section-number">8.5.1</span> heading</h3>
<p>text</p>
<table>
<thead>
<tr class="header">
<th>down</th>
<th></th>
<th>up</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>channels x width x height</td>
<td></td>
<td>channels x width x height</td>
</tr>
<tr class="even">
<td>3 x 256 x 256 (input)</td>
<td></td>
<td>1 x 256 x 256 (1 x1 conv)</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>64 x 256 x 256 (conv)</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>128 x 256 x 256 (concat)</td>
</tr>
<tr class="odd">
<td>64 x 256 x 256 (conv)</td>
<td>CONCAT</td>
<td>64 x 256 x 256 (conv + deconv)</td>
</tr>
<tr class="even">
<td>64 x 128 x 128 (pool)</td>
<td></td>
<td>256 x 128 x 128 (concat)</td>
</tr>
<tr class="odd">
<td>128 x 128 x 128 (conv)</td>
<td>CONCAT</td>
<td>128 x 128 x 128 (conv + deconv)</td>
</tr>
<tr class="even">
<td>128 x 64 x 64 (pool)</td>
<td></td>
<td>512 x 64 x 64 (concat)</td>
</tr>
<tr class="odd">
<td>256 x 64 x 64 (conv)</td>
<td>CONCAT</td>
<td>256 x 64 x 64 (conv + deconv)</td>
</tr>
<tr class="even">
<td>256 x 32 x 32 (pool)</td>
<td></td>
<td>1024 x 32 x 32 (concat)</td>
</tr>
<tr class="odd">
<td>512 x 32 x 32 (conv)</td>
<td>CONCAT</td>
<td>512 x 32 x 32 (deconv)</td>
</tr>
<tr class="even">
<td>512 x 16 x 16 (pool)</td>
<td></td>
<td>1024 x 16 x 16 (conv)</td>
</tr>
</tbody>
</table>
<p>Number of channels goes up due to convolution layers; spatial downsizing occurs due to max pooling. (There is no max pooling
at the “inflection point”.)</p>

</div>
</div>
</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-BUDA2019218">
<p>Buda, Mateusz, Ashirbani Saha, and Maciej A. Mazurowski. 2019. “Association of Genomic Subtypes of Lower-Grade Gliomas with Shape Features Automatically Extracted by a Deep Learning Algorithm.” <em>Computers in Biology and Medicine</em> 109: 218–25. <a href="https://doi.org/https://doi.org/10.1016/j.compbiomed.2019.05.002">https://doi.org/https://doi.org/10.1016/j.compbiomed.2019.05.002</a>.</p>
</div>
<div id="ref-RonnebergerFB15">
<p>Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. “U-Net: Convolutional Networks for Biomedical Image Segmentation.” <em>CoRR</em> abs/1505.04597. <a href="http://arxiv.org/abs/1505.04597">http://arxiv.org/abs/1505.04597</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="image-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="NLP-intro.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
