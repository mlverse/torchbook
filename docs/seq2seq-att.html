<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Sequence-to-sequence models with attention | Applied deep learning with torch from R</title>
  <meta name="description" content="tbd" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Sequence-to-sequence models with attention | Applied deep learning with torch from R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="tbd" />
  <meta property="og:image" content="tbdcover.png" />
  <meta property="og:description" content="tbd" />
  <meta name="github-repo" content="tbd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Sequence-to-sequence models with attention | Applied deep learning with torch from R" />
  
  <meta name="twitter:description" content="tbd" />
  <meta name="twitter:image" content="tbdcover.png" />

<meta name="author" content="tbd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="NLP-intro.html"/>
<link rel="next" href="transformer.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>I Using Torch</b></span></li>
<li class="chapter" data-level="" data-path="using-torch-intro.html"><a href="using-torch-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="2" data-path="simple-net-R.html"><a href="simple-net-R.html"><i class="fa fa-check"></i><b>2</b> A simple neural network in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#whats-in-a-network"><i class="fa fa-check"></i><b>2.1</b> What’s in a network?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="simple-net-R.html"><a href="simple-net-R.html#gradient-descent"><i class="fa fa-check"></i><b>2.1.1</b> Gradient descent</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-net-R.html"><a href="simple-net-R.html#from-linear-regression-to-a-simple-network"><i class="fa fa-check"></i><b>2.1.2</b> From linear regression to a simple network</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#a-simple-network"><i class="fa fa-check"></i><b>2.2</b> A simple network</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="simple-net-R.html"><a href="simple-net-R.html#simulate-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulate data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-net-R.html"><a href="simple-net-R.html#initialize-weights-and-biases"><i class="fa fa-check"></i><b>2.2.2</b> Initialize weights and biases</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>2.2.3</b> Training loop</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-net-R.html"><a href="simple-net-R.html#complete-code"><i class="fa fa-check"></i><b>2.2.4</b> Complete code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html"><i class="fa fa-check"></i><b>3</b> Modifying the simple network to use torch tensors</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#tensors"><i class="fa fa-check"></i><b>3.1</b> Tensors</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#creation"><i class="fa fa-check"></i><b>3.1.1</b> Creation</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#conversion-to-built-in-r-data-types"><i class="fa fa-check"></i><b>3.1.2</b> Conversion to built-in R data types</a></li>
<li class="chapter" data-level="3.1.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#indexing-and-slicing-tensors"><i class="fa fa-check"></i><b>3.1.3</b> Indexing and slicing tensors</a></li>
<li class="chapter" data-level="3.1.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#reshaping-tensors"><i class="fa fa-check"></i><b>3.1.4</b> Reshaping tensors</a></li>
<li class="chapter" data-level="3.1.5" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#operations-on-tensors"><i class="fa fa-check"></i><b>3.1.5</b> Operations on tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#running-on-gpu"><i class="fa fa-check"></i><b>3.2</b> Running on GPU</a></li>
<li class="chapter" data-level="3.3" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#broadcasting"><i class="fa fa-check"></i><b>3.3</b> Broadcasting</a></li>
<li class="chapter" data-level="3.4" data-path="simple-net-tensors.html"><a href="simple-net-tensors.html#simple-neural-network-using-torch-tensors"><i class="fa fa-check"></i><b>3.4</b> Simple neural network using <code>torch</code> tensors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html"><i class="fa fa-check"></i><b>4</b> Using autograd</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#automatic-differentiation-with-autograd"><i class="fa fa-check"></i><b>4.1</b> Automatic differentiation with <em>autograd</em></a></li>
<li class="chapter" data-level="4.2" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#the-simple-network-now-using-autograd"><i class="fa fa-check"></i><b>4.2</b> The simple network, now using <em>autograd</em></a></li>
<li class="chapter" data-level="4.3" data-path="simple-net-autograd.html"><a href="simple-net-autograd.html#outlook"><i class="fa fa-check"></i><b>4.3</b> Outlook</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-net-modules.html"><a href="simple-net-modules.html"><i class="fa fa-check"></i><b>5</b> Using torch modules</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#modules"><i class="fa fa-check"></i><b>5.1</b> Modules</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="simple-net-modules.html"><a href="simple-net-modules.html#layers-as-modules"><i class="fa fa-check"></i><b>5.1.1</b> Layers as modules</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#models-as-modules"><i class="fa fa-check"></i><b>5.1.2</b> Models as modules</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-net-modules.html"><a href="simple-net-modules.html#simple-network-using-modules"><i class="fa fa-check"></i><b>5.2</b> Simple network using modules</a></li>
<li class="chapter" data-level="5.3" data-path="simple-net-modules.html"><a href="simple-net-modules.html#appendix-python-code"><i class="fa fa-check"></i><b>5.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-net-optim.html"><a href="simple-net-optim.html"><i class="fa fa-check"></i><b>6</b> Using <code>torch</code> optimizers</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple-net-optim.html"><a href="simple-net-optim.html#torch-optimizers"><i class="fa fa-check"></i><b>6.1</b> Torch optimizers</a></li>
<li class="chapter" data-level="6.2" data-path="simple-net-optim.html"><a href="simple-net-optim.html#simple-net-with-optim"><i class="fa fa-check"></i><b>6.2</b> Simple net with <code>optim</code></a></li>
<li class="chapter" data-level="6.3" data-path="simple-net-modules.html"><a href="simple-net-modules.html#appendix-python-code"><i class="fa fa-check"></i><b>6.3</b> Appendix: Python code</a></li>
</ul></li>
<li class="part"><span><b>II Image Recognition</b></span></li>
<li class="chapter" data-level="" data-path="image-recognition-intro.html"><a href="image-recognition-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="7" data-path="image-classification.html"><a href="image-classification.html"><i class="fa fa-check"></i><b>7</b> Classifying images</a>
<ul>
<li class="chapter" data-level="7.1" data-path="image-classification.html"><a href="image-classification.html#data-loading-and-transformation"><i class="fa fa-check"></i><b>7.1</b> Data loading and transformation</a></li>
<li class="chapter" data-level="7.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>7.2</b> Model</a></li>
<li class="chapter" data-level="7.3" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>7.3</b> Training</a></li>
<li class="chapter" data-level="7.4" data-path="image-classification.html"><a href="image-classification.html#performance-on-the-test-set"><i class="fa fa-check"></i><b>7.4</b> Performance on the test set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unet.html"><a href="unet.html"><i class="fa fa-check"></i><b>8</b> Brain Image Segmentation with U-Net</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unet.html"><a href="unet.html#image-segmentation-in-a-nutshell"><i class="fa fa-check"></i><b>8.1</b> Image segmentation in a nutshell</a></li>
<li class="chapter" data-level="8.2" data-path="unet.html"><a href="unet.html#u-net"><i class="fa fa-check"></i><b>8.2</b> U-Net</a></li>
<li class="chapter" data-level="8.3" data-path="unet.html"><a href="unet.html#example-application-mri-images"><i class="fa fa-check"></i><b>8.3</b> Example application: MRI images</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="unet.html"><a href="unet.html#preprocessing"><i class="fa fa-check"></i><b>8.3.1</b> Preprocessing</a></li>
<li class="chapter" data-level="8.3.2" data-path="unet.html"><a href="unet.html#u-net-model"><i class="fa fa-check"></i><b>8.3.2</b> U-Net model</a></li>
<li class="chapter" data-level="8.3.3" data-path="unet.html"><a href="unet.html#loss"><i class="fa fa-check"></i><b>8.3.3</b> Loss</a></li>
<li class="chapter" data-level="8.3.4" data-path="image-classification.html"><a href="image-classification.html#training"><i class="fa fa-check"></i><b>8.3.4</b> Training</a></li>
<li class="chapter" data-level="8.3.5" data-path="unet.html"><a href="unet.html#predictions"><i class="fa fa-check"></i><b>8.3.5</b> Predictions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Natural language processing</b></span></li>
<li class="chapter" data-level="" data-path="NLP-intro.html"><a href="NLP-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="9" data-path="seq2seq-att.html"><a href="seq2seq-att.html"><i class="fa fa-check"></i><b>9</b> Sequence-to-sequence models with attention</a>
<ul>
<li class="chapter" data-level="9.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#why-attention"><i class="fa fa-check"></i><b>9.1</b> Why attention?</a></li>
<li class="chapter" data-level="9.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#preprocessing-with-torchtext"><i class="fa fa-check"></i><b>9.2</b> Preprocessing with <code>torchtext</code></a></li>
<li class="chapter" data-level="9.3" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>9.3</b> Model</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>9.3.1</b> Encoder</a></li>
<li class="chapter" data-level="9.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#attention-module"><i class="fa fa-check"></i><b>9.3.2</b> Attention module</a></li>
<li class="chapter" data-level="9.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>9.3.3</b> Decoder</a></li>
<li class="chapter" data-level="9.3.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#seq2seq-module"><i class="fa fa-check"></i><b>9.3.4</b> Seq2seq module</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#training-and-evaluation"><i class="fa fa-check"></i><b>9.4</b> Training and evaluation</a></li>
<li class="chapter" data-level="9.5" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>9.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="transformer.html"><a href="transformer.html"><i class="fa fa-check"></i><b>10</b> Torch transformer modules</a>
<ul>
<li class="chapter" data-level="10.1" data-path="transformer.html"><a href="transformer.html#attention-is-all-you-need"><i class="fa fa-check"></i><b>10.1</b> “Attention is all you need”</a></li>
<li class="chapter" data-level="10.2" data-path="transformer.html"><a href="transformer.html#implementation-building-blocks"><i class="fa fa-check"></i><b>10.2</b> Implementation: building blocks</a></li>
<li class="chapter" data-level="10.3" data-path="transformer.html"><a href="transformer.html#a-transformer-for-natural-language-translation"><i class="fa fa-check"></i><b>10.3</b> A Transformer for natural language translation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="transformer.html"><a href="transformer.html#load-data"><i class="fa fa-check"></i><b>10.3.1</b> Load data</a></li>
<li class="chapter" data-level="10.3.2" data-path="seq2seq-att.html"><a href="seq2seq-att.html#encoder"><i class="fa fa-check"></i><b>10.3.2</b> Encoder</a></li>
<li class="chapter" data-level="10.3.3" data-path="seq2seq-att.html"><a href="seq2seq-att.html#decoder"><i class="fa fa-check"></i><b>10.3.3</b> Decoder</a></li>
<li class="chapter" data-level="10.3.4" data-path="transformer.html"><a href="transformer.html#overall-model"><i class="fa fa-check"></i><b>10.3.4</b> Overall model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="seq2seq-att.html"><a href="seq2seq-att.html#results"><i class="fa fa-check"></i><b>10.4</b> Results</a></li>
</ul></li>
<li class="part"><span><b>IV Deep learning for tabular data</b></span></li>
<li class="chapter" data-level="" data-path="tabular-intro.html"><a href="tabular-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V Time series</b></span></li>
<li class="chapter" data-level="" data-path="timeseries-intro.html"><a href="timeseries-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VI Generative deep learning</b></span></li>
<li class="chapter" data-level="" data-path="generative-intro.html"><a href="generative-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="11" data-path="gans.html"><a href="gans.html"><i class="fa fa-check"></i><b>11</b> Generative adversarial networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>11.1</b> Dataset</a></li>
<li class="chapter" data-level="11.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>11.2</b> Model</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="gans.html"><a href="gans.html#generator"><i class="fa fa-check"></i><b>11.2.1</b> Generator</a></li>
<li class="chapter" data-level="11.2.2" data-path="gans.html"><a href="gans.html#discriminator"><i class="fa fa-check"></i><b>11.2.2</b> Discriminator</a></li>
<li class="chapter" data-level="11.2.3" data-path="gans.html"><a href="gans.html#optimizers-and-loss-function"><i class="fa fa-check"></i><b>11.2.3</b> Optimizers and loss function</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="simple-net-R.html"><a href="simple-net-R.html#training-loop"><i class="fa fa-check"></i><b>11.3</b> Training loop</a></li>
<li class="chapter" data-level="11.4" data-path="gans.html"><a href="gans.html#artifacts"><i class="fa fa-check"></i><b>11.4</b> Artifacts</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="vaes.html"><a href="vaes.html"><i class="fa fa-check"></i><b>12</b> Variational autoencoders</a>
<ul>
<li class="chapter" data-level="12.1" data-path="gans.html"><a href="gans.html#dataset"><i class="fa fa-check"></i><b>12.1</b> Dataset</a></li>
<li class="chapter" data-level="12.2" data-path="image-classification.html"><a href="image-classification.html#model"><i class="fa fa-check"></i><b>12.2</b> Model</a></li>
<li class="chapter" data-level="12.3" data-path="vaes.html"><a href="vaes.html#training-the-vae"><i class="fa fa-check"></i><b>12.3</b> Training the VAE</a></li>
<li class="chapter" data-level="12.4" data-path="vaes.html"><a href="vaes.html#latent-space"><i class="fa fa-check"></i><b>12.4</b> Latent space</a></li>
</ul></li>
<li class="part"><span><b>VII Deep learning on graphs</b></span></li>
<li class="chapter" data-level="" data-path="graph-intro.html"><a href="graph-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>VIII Probabilistic deep learning</b></span></li>
<li class="chapter" data-level="" data-path="probabilistic-intro.html"><a href="probabilistic-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>IX Private and secure deep learning</b></span></li>
<li class="chapter" data-level="" data-path="private-secure-intro.html"><a href="private-secure-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>X Research topics</b></span></li>
<li class="chapter" data-level="" data-path="research-intro.html"><a href="research-intro.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied deep learning with torch from R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="seq2seq_att" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Sequence-to-sequence models with attention</h1>
<p>As we write this, many state-of- the-art models used in natural language processing are based on the <em>Transformer</em>
<span class="citation">(Vaswani et al. <a href="#ref-VaswaniSPUJGKP17" role="doc-biblioref">2017</a>)</span> idea (see e.g., BERT [@abs-1810-04805], the OpenAI Transformer <span class="citation">(Radford <a href="#ref-Radford2018ImprovingLU" role="doc-biblioref">2018</a>)</span>, GPT-2
<span class="citation">(Radford <a href="#ref-Radford2018ImprovingLU" role="doc-biblioref">2018</a>)</span>).</p>
<p>The “shocking” thing about the original <em>Transformer</em> was that it did not use recurrent neural networks to process sequential
data, but mainly relied on the guiding power of <em>attention</em> to tackle the challenges inherent in – multiple, sometimes –
sequentiality. The concept of <em>attention</em> is so central to current deep learning that we want to introduce it independently of
how it is used in <em>Transformer</em>-based models. In this chapter, thus, we show an example of neural machine translation built
“classically”, that is, using recurrent neural networks (RNNs), but with the crucial addition of <em>attention</em>.</p>
<div id="why-attention" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Why attention?</h2>
<p>Translation is a prototypical example of sequence-to-sequence processing: sequence in, sequence out. The natural architectural
choice are RNNs, for they carry a hidden state through computations. The first RNN would <em>encode</em> the source sentence, at each
time taking in a token and the last hidden state. When it is done, it delivers the final state to the second RNN, the
<em>decoder</em>, which now starts generating token after token, based on what it got from the encoder and its own hidden states, as
they get updated over time. This is sufficient to produce a coherent output; but otherwise, the decoder’s job is really hard:
All it gets from the encoder is a single compressed code where all sequentiality is lost.</p>
<p>It’s here that <em>attention</em> comes in: What if the decoder had access to the encoder state <em>over time</em>, and could decide, when
generating tokens, what encoder states to preferentially look at <em>at a given step</em>? For that to happen, we need, at each
decoder time step, to compare somehow the current decoder hidden state to all encoder hidden states produced while encoding.
How this is accomplished technically may vary – see e.g. <span class="citation">(Luong, Pham, and Manning <a href="#ref-LuongPM15" role="doc-biblioref">2015</a>)</span> for a concise overview – but the idea is always the
same. Our example will use Bahdanau-style <span class="citation">(Bahdanau, Cho, and Bengio <a href="#ref-2014arXiv1409.0473B" role="doc-biblioref">2014</a>)</span> additive attention.</p>
</div>
<div id="preprocessing-with-torchtext" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Preprocessing with <code>torchtext</code></h2>
<p>Conveniently, we can make use of <code>torchtext</code> to handle preprocessing. A <code>Field</code> holds a specification of how to tokenize the
input and how to transform it to a tensor.</p>
<p>In our example, the source language will be English, and the target will be French. Here, we ask torch to use Spacy as a
tokenizer for both languages, and what tokens to use to mark sentence beginnings and endings:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="seq2seq-att.html#cb201-1"></a><span class="im">import</span> torch</span>
<span id="cb201-2"><a href="seq2seq-att.html#cb201-2"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb201-3"><a href="seq2seq-att.html#cb201-3"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb201-4"><a href="seq2seq-att.html#cb201-4"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb201-5"><a href="seq2seq-att.html#cb201-5"></a></span>
<span id="cb201-6"><a href="seq2seq-att.html#cb201-6"></a><span class="im">from</span> torchtext.data <span class="im">import</span> Field, BucketIterator</span>
<span id="cb201-7"><a href="seq2seq-att.html#cb201-7"></a><span class="im">from</span> torchtext.datasets <span class="im">import</span> IWSLT</span>
<span id="cb201-8"><a href="seq2seq-att.html#cb201-8"></a></span>
<span id="cb201-9"><a href="seq2seq-att.html#cb201-9"></a><span class="im">import</span> random</span>
<span id="cb201-10"><a href="seq2seq-att.html#cb201-10"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb201-11"><a href="seq2seq-att.html#cb201-11"></a><span class="im">import</span> math</span>
<span id="cb201-12"><a href="seq2seq-att.html#cb201-12"></a></span>
<span id="cb201-13"><a href="seq2seq-att.html#cb201-13"></a>src_spec <span class="op">=</span> Field(</span>
<span id="cb201-14"><a href="seq2seq-att.html#cb201-14"></a>  tokenize <span class="op">=</span> <span class="st">&quot;spacy&quot;</span>,</span>
<span id="cb201-15"><a href="seq2seq-att.html#cb201-15"></a>  tokenizer_language<span class="op">=</span><span class="st">&quot;en&quot;</span>,</span>
<span id="cb201-16"><a href="seq2seq-att.html#cb201-16"></a>  init_token <span class="op">=</span> <span class="st">&#39;&lt;sos&gt;&#39;</span>,</span>
<span id="cb201-17"><a href="seq2seq-att.html#cb201-17"></a>  eos_token <span class="op">=</span> <span class="st">&#39;&lt;eos&gt;&#39;</span>,</span>
<span id="cb201-18"><a href="seq2seq-att.html#cb201-18"></a>  lower <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb201-19"><a href="seq2seq-att.html#cb201-19"></a></span>
<span id="cb201-20"><a href="seq2seq-att.html#cb201-20"></a>trg_spec <span class="op">=</span> Field(</span>
<span id="cb201-21"><a href="seq2seq-att.html#cb201-21"></a>  tokenize <span class="op">=</span> <span class="st">&quot;spacy&quot;</span>,</span>
<span id="cb201-22"><a href="seq2seq-att.html#cb201-22"></a>  tokenizer_language<span class="op">=</span><span class="st">&quot;fr&quot;</span>,</span>
<span id="cb201-23"><a href="seq2seq-att.html#cb201-23"></a>  init_token <span class="op">=</span> <span class="st">&#39;&lt;sos&gt;&#39;</span>,</span>
<span id="cb201-24"><a href="seq2seq-att.html#cb201-24"></a>  eos_token <span class="op">=</span> <span class="st">&#39;&lt;eos&gt;&#39;</span>,</span>
<span id="cb201-25"><a href="seq2seq-att.html#cb201-25"></a>  lower <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div>
<p>These <code>Field</code>s will soon be used to store the <em>vocabularies</em> for both languages, that is, the mappings from words to integers.
But first, we need a dataset. We use the data from the 2016 IWSLT TED talk translation contest, nicely downloadable, and
already split into training, validation and testing subsets by torch:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb202-1"><a href="seq2seq-att.html#cb202-1"></a>train_data, valid_data, test_data <span class="op">=</span> IWSLT.splits(exts <span class="op">=</span> (<span class="st">&#39;.en&#39;</span>, <span class="st">&#39;.fr&#39;</span>), fields <span class="op">=</span> (src_spec, trg_spec))</span>
<span id="cb202-2"><a href="seq2seq-att.html#cb202-2"></a></span>
<span id="cb202-3"><a href="seq2seq-att.html#cb202-3"></a><span class="bu">len</span>(train_data.examples), <span class="bu">len</span>(valid_data.examples), <span class="bu">len</span>(test_data.examples)</span></code></pre></div>
<pre><code>{(220400, 1026, 1305)}</code></pre>
<p>As you see, the training set is gigantic, so one epoch of training will take some time even on a decent GPU. Let’s see a few
examples:</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb204-1"><a href="seq2seq-att.html#cb204-1"></a><span class="bu">vars</span>(train_data.examples[<span class="dv">111</span>])</span>
<span id="cb204-2"><a href="seq2seq-att.html#cb204-2"></a><span class="bu">vars</span>(train_data.examples[<span class="dv">11111</span>])</span>
<span id="cb204-3"><a href="seq2seq-att.html#cb204-3"></a><span class="bu">vars</span>(train_data.examples[<span class="dv">111111</span>])</span></code></pre></div>
<pre><code>{&#39;src&#39;: [&#39;on&#39;, &#39;one&#39;, &#39;of&#39;, &#39;the&#39;, &#39;last&#39;, &#39;dive&#39;, &#39;series&#39;, &#39;,&#39;, &#39;we&#39;, &#39;counted&#39;, &#39;200&#39;, &#39;species&#39;, &#39;in&#39;, &#39;these&#39;, &#39;areas&#39;, &#39;--&#39;, &#39;198&#39;, &#39;were&#39;, &#39;new&#39;, &#39;,&#39;, &#39;new&#39;, &#39;species&#39;, &#39;.&#39;], &#39;trg&#39;: [&#39;dans&#39;, &#39;une&#39;, &#39;des&#39;, &#39;plus&#39;, &#39;récentes&#39;, &#39;plongées&#39;, &#39;on&#39;, &#39;a&#39;, &#39;compté&#39;, &#39;200&#39;, &#39;espèces&#39;, &#39;dans&#39;, &#39;ces&#39;, &#39;régions&#39;, &#39;.&#39;, &#39;198&#39;, &#39;étaient&#39;, &#39;nouvelles&#39;, &#39;-&#39;, &#39;de&#39;, &#39;nouvelles&#39;, &#39;espèces&#39;, &#39;.&#39;]}

{&#39;src&#39;: [&#39;this&#39;, &#39;is&#39;, &#39;one&#39;, &#39;of&#39;, &#39;the&#39;, &#39;true&#39;, &#39;masterpieces&#39;, &#39;in&#39;, &#39;puzzle&#39;, &#39;design&#39;, &#39;besides&#39;, &#39;rubik&#39;, &quot;&#39;s&quot;, &#39;cube&#39;, &#39;.&#39;], &#39;trg&#39;: [&quot;c&#39;&quot;, &#39;est&#39;, &#39;un&#39;, &#39;des&#39;, &#39;véritables&#39;, &#39;chefs&#39;, &#39;-&#39;, &quot;d&#39;&quot;, &#39;œuvre&#39;, &#39;en&#39;, &#39;terme&#39;, &#39;de&#39;, &#39;casse-tête&#39;, &#39;,&#39;, &#39;avec&#39;, &#39;le&#39;, &quot;rubik&#39;&quot;, &#39;s&#39;, &#39;cube&#39;, &#39;.&#39;]}

{&#39;src&#39;: [&#39;i&#39;, &#39;sat&#39;, &#39;him&#39;, &#39;down&#39;, &#39;,&#39;, &#39;i&#39;, &#39;caricatured&#39;, &#39;him&#39;, &#39;,&#39;, &#39;and&#39;, &#39;since&#39;, &#39;then&#39;, &#39;i&#39;, &quot;&#39;ve&quot;, &#39;caricatured&#39;, &#39;hundreds&#39;, &#39;of&#39;, &#39;celebrities&#39;, &#39;.&#39;], &#39;trg&#39;: [&#39;je&#39;, &#39;me&#39;, &#39;suis&#39;, &#39;assis&#39;, &#39;,&#39;, &#39;je&#39;, &quot;l&#39;&quot;, &#39;ai&#39;, &#39;caricaturé&#39;, &#39;,&#39;, &#39;et&#39;, &#39;vu&#39;, &#39;que&#39;, &quot;j&#39;&quot;, &#39;avais&#39;, &#39;caricaturé&#39;, &#39;des&#39;, &#39;centaines&#39;, &#39;de&#39;, &#39;célébrités&#39;, &#39;.&#39;]}</code></pre>
<p>Now we can build the vocabularies on the source and target, respectively.</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb206-1"><a href="seq2seq-att.html#cb206-1"></a>src_spec.build_vocab(train_data, min_freq <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb206-2"><a href="seq2seq-att.html#cb206-2"></a></span>
<span id="cb206-3"><a href="seq2seq-att.html#cb206-3"></a>trg_spec.build_vocab(train_data, min_freq <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb206-4"><a href="seq2seq-att.html#cb206-4"></a></span>
<span id="cb206-5"><a href="seq2seq-att.html#cb206-5"></a><span class="bu">len</span>(src_spec.vocab), <span class="bu">len</span>(trg_spec.vocab)</span></code></pre></div>
<pre><code>(34948, 45032)</code></pre>
<p><code>vocab</code> is a dictionary, with tokens as keys and integers as values:</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb208-1"><a href="seq2seq-att.html#cb208-1"></a>src_spec.vocab.stoi[<span class="st">&quot;cat&quot;</span>], trg_spec.vocab.stoi[<span class="st">&quot;chat&quot;</span>]</span></code></pre></div>
<pre><code>(2036, 2424)</code></pre>
<p>In locations 1-4, we have the special tokens indicating unknown input, padding, start of sentence and end of sentence.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb210-1"><a href="seq2seq-att.html#cb210-1"></a>src_spec.vocab.itos[<span class="dv">0</span>], src_spec.vocab.itos[<span class="dv">1</span>], src_spec.vocab.itos[<span class="dv">2</span>], src_spec.vocab.itos[<span class="dv">3</span>]</span></code></pre></div>
<pre><code>(&#39;&lt;unk&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;sos&gt;&#39;, &#39;&lt;eos&gt;&#39;)</code></pre>
<p>Preprocessing-wise, that’s already it. All that remains to be done before proceeding to model definition is to create
iterators for the training, validation and testing sets. The <code>BucketIterator</code> class will assemble batches so that sentences of
similar length go together:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb212-1"><a href="seq2seq-att.html#cb212-1"></a>device <span class="op">=</span> torch.device(<span class="st">&#39;cuda&#39;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb212-2"><a href="seq2seq-att.html#cb212-2"></a></span>
<span id="cb212-3"><a href="seq2seq-att.html#cb212-3"></a>batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb212-4"><a href="seq2seq-att.html#cb212-4"></a></span>
<span id="cb212-5"><a href="seq2seq-att.html#cb212-5"></a>train_iterator, valid_iterator, test_iterator <span class="op">=</span> BucketIterator.splits(</span>
<span id="cb212-6"><a href="seq2seq-att.html#cb212-6"></a>    (train_data, valid_data, test_data),</span>
<span id="cb212-7"><a href="seq2seq-att.html#cb212-7"></a>    batch_size <span class="op">=</span> batch_size,</span>
<span id="cb212-8"><a href="seq2seq-att.html#cb212-8"></a>    device <span class="op">=</span> device)</span></code></pre></div>
<p>Let’s inspect the first batch.</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="seq2seq-att.html#cb213-1"></a>batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_iterator))</span>
<span id="cb213-2"><a href="seq2seq-att.html#cb213-2"></a>batch.src.shape, batch.trg.shape</span></code></pre></div>
<pre><code>(torch.Size([26, 8]), torch.Size([34, 8]))</code></pre>
<p>If you’ve been working with Keras / TensorFlow, you may be surprised to see the batch dimension winding up in second place.
This is due to a default setting of <code>torchtext</code> <code>Field</code>s (which we could have changed had we wanted to):</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb215-1"><a href="seq2seq-att.html#cb215-1"></a>train_data.fields[<span class="st">&quot;src&quot;</span>]._batch_first</span></code></pre></div>
<pre><code>False</code></pre>
<p>Another interesting observation, especially if you come from Keras: Every batch really is of (potentially) different sentence
length, keeping the amount of padding minimal:</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="seq2seq-att.html#cb217-1"></a>batch.src[ :, <span class="dv">0</span>]</span></code></pre></div>
<pre><code>tensor([    2,    59,    10, 15954,     0,    64,     4,    15,   242,    42,
          690,     4,    28,    14,    18,     6,  1239, 17430,    13,   445,
            5,     3,     1,     1,     1,     1], device=&#39;cuda:0&#39;)</code></pre>
</div>
<div id="model" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Model</h2>
<p>The model is a hierarchical composition of <em>modules</em>. We start with the encoder.</p>
<div id="encoder" class="section level3" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Encoder</h3>
<p>The encoder embeds its input, runs it through a bidirectional RNN (a GRU, to be precise), and returns the GRU’s outputs as
well as a processed version of the final hidden states (the plural – outputs, states – being due to the RNN’s
bidirectionality).</p>
<p>For Keras users, it makes sense to pay special attention to the tensor shapes returned by the GRU (the same would hold were we
using an LSTM instead): The respective tensors are</p>
<ul>
<li>the outputs from all time steps (corresponding to what you’d get from Keras if you specified <code>return_sequences = True</code>),
and</li>
<li>the last hidden state (available from Keras using <code>return_state = True</code>)</li>
</ul>
<div class="sourceCode" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="seq2seq-att.html#cb219-1"></a>num_input_features <span class="op">=</span> <span class="bu">len</span>(src_spec.vocab)</span>
<span id="cb219-2"><a href="seq2seq-att.html#cb219-2"></a></span>
<span id="cb219-3"><a href="seq2seq-att.html#cb219-3"></a>encoder_embedding_dim <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb219-4"><a href="seq2seq-att.html#cb219-4"></a>encoder_hidden_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb219-5"><a href="seq2seq-att.html#cb219-5"></a></span>
<span id="cb219-6"><a href="seq2seq-att.html#cb219-6"></a>decoder_hidden_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb219-7"><a href="seq2seq-att.html#cb219-7"></a></span>
<span id="cb219-8"><a href="seq2seq-att.html#cb219-8"></a>encoder_dropout <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb219-9"><a href="seq2seq-att.html#cb219-9"></a></span>
<span id="cb219-10"><a href="seq2seq-att.html#cb219-10"></a></span>
<span id="cb219-11"><a href="seq2seq-att.html#cb219-11"></a><span class="kw">class</span> Encoder(nn.Module):</span>
<span id="cb219-12"><a href="seq2seq-att.html#cb219-12"></a>  </span>
<span id="cb219-13"><a href="seq2seq-att.html#cb219-13"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_input_features, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout):</span>
<span id="cb219-14"><a href="seq2seq-att.html#cb219-14"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb219-15"><a href="seq2seq-att.html#cb219-15"></a>        <span class="va">self</span>.num_input_features <span class="op">=</span> num_input_features</span>
<span id="cb219-16"><a href="seq2seq-att.html#cb219-16"></a>        <span class="va">self</span>.embedding_dim <span class="op">=</span> embedding_dim</span>
<span id="cb219-17"><a href="seq2seq-att.html#cb219-17"></a>        <span class="va">self</span>.encoder_hidden_dim <span class="op">=</span> encoder_hidden_dim</span>
<span id="cb219-18"><a href="seq2seq-att.html#cb219-18"></a>        <span class="va">self</span>.decoder_hidden_dim <span class="op">=</span> decoder_hidden_dim</span>
<span id="cb219-19"><a href="seq2seq-att.html#cb219-19"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb219-20"><a href="seq2seq-att.html#cb219-20"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(num_input_features, embedding_dim)</span>
<span id="cb219-21"><a href="seq2seq-att.html#cb219-21"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb219-22"><a href="seq2seq-att.html#cb219-22"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(encoder_hidden_dim <span class="op">*</span> <span class="dv">2</span>, decoder_hidden_dim)</span>
<span id="cb219-23"><a href="seq2seq-att.html#cb219-23"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb219-24"><a href="seq2seq-att.html#cb219-24"></a>    </span>
<span id="cb219-25"><a href="seq2seq-att.html#cb219-25"></a>    <span class="co"># src: seq_len * bs</span></span>
<span id="cb219-26"><a href="seq2seq-att.html#cb219-26"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, src):</span>
<span id="cb219-27"><a href="seq2seq-att.html#cb219-27"></a>        </span>
<span id="cb219-28"><a href="seq2seq-att.html#cb219-28"></a>        <span class="co"># embedded: seq_len * bs * embedding_dim</span></span>
<span id="cb219-29"><a href="seq2seq-att.html#cb219-29"></a>        <span class="co"># each input token gets embedded to degree embedding_dim</span></span>
<span id="cb219-30"><a href="seq2seq-att.html#cb219-30"></a>        embedded <span class="op">=</span> <span class="va">self</span>.dropout(<span class="va">self</span>.embedding(src))</span>
<span id="cb219-31"><a href="seq2seq-att.html#cb219-31"></a>        <span class="co"># output: seq_len * bs * (2 * hidden_size)</span></span>
<span id="cb219-32"><a href="seq2seq-att.html#cb219-32"></a>        <span class="co">#  =&gt; tensor containing the output features h_t for each t (!)</span></span>
<span id="cb219-33"><a href="seq2seq-att.html#cb219-33"></a>        <span class="co"># hidden: 2 * bs * hidden_size</span></span>
<span id="cb219-34"><a href="seq2seq-att.html#cb219-34"></a>        <span class="co">#  =&gt; tensor containing the hidden state for t = seq_len</span></span>
<span id="cb219-35"><a href="seq2seq-att.html#cb219-35"></a>        outputs, hidden <span class="op">=</span> <span class="va">self</span>.rnn(embedded)</span>
<span id="cb219-36"><a href="seq2seq-att.html#cb219-36"></a>        <span class="co"># concatenate last state from both directions</span></span>
<span id="cb219-37"><a href="seq2seq-att.html#cb219-37"></a>        <span class="co"># input size to fc then is bs * 2 * hidden_size</span></span>
<span id="cb219-38"><a href="seq2seq-att.html#cb219-38"></a>        hidden <span class="op">=</span> torch.tanh(<span class="va">self</span>.fc(torch.cat((hidden[<span class="op">-</span><span class="dv">2</span>,:,:], hidden[<span class="op">-</span><span class="dv">1</span>,:,:]), dim <span class="op">=</span> <span class="dv">1</span>)))</span>
<span id="cb219-39"><a href="seq2seq-att.html#cb219-39"></a>        <span class="co"># hidden is now bs * decoder_hidden_dim</span></span>
<span id="cb219-40"><a href="seq2seq-att.html#cb219-40"></a>        <span class="cf">return</span> outputs, hidden</span>
<span id="cb219-41"><a href="seq2seq-att.html#cb219-41"></a></span>
<span id="cb219-42"><a href="seq2seq-att.html#cb219-42"></a>encoder <span class="op">=</span> Encoder(num_input_features, encoder_embedding_dim, encoder_hidden_dim, decoder_hidden_dim, encoder_dropout).to(device)</span></code></pre></div>
<p>As a quick check, let’s call the encoder on the first batch’s input sentence:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="seq2seq-att.html#cb220-1"></a>encoder_output <span class="op">=</span> encoder.forward(batch.src)</span>
<span id="cb220-2"><a href="seq2seq-att.html#cb220-2"></a>encoder_outputs <span class="op">=</span> encoder_output[<span class="dv">0</span>]</span>
<span id="cb220-3"><a href="seq2seq-att.html#cb220-3"></a>decoder_hidden <span class="op">=</span> encoder_output[<span class="dv">1</span>]</span>
<span id="cb220-4"><a href="seq2seq-att.html#cb220-4"></a>encoder_outputs.size(), decoder_hidden.size()</span></code></pre></div>
<pre><code># output is seq_len * bs * (2 * hidden_size)
# hidden is bs * decoder_hidden_dim
(torch.Size([26, 8, 128]), torch.Size([8, 64]))</code></pre>
<p>Next, we create the attention module, to be used by the decoder.</p>
</div>
<div id="attention-module" class="section level3" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Attention module</h3>
<p>Every time it is called to generate a single target token, the decoder will ask the attention module to <em>score</em> every token in
the input sequence as to its relevance in the current context. To this end, it will need to know about the current decoder
state as well the whole of the input sequence:</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb222-1"><a href="seq2seq-att.html#cb222-1"></a>a <span class="op">=</span> <span class="va">self</span>.attention(decoder_hidden, encoder_outputs)</span></code></pre></div>
<p>The attention module correlates decoder hidden state with all input tokens in the sequence (line 22) and returns a normalized
relevance score for each of them (lines 25/26). Like we said above, different ways exist to calculate the scores – this one
concatenates the things to be correlated and passes them through a linear layer; one popular alternative would be to multiply
them.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb223-1"><a href="seq2seq-att.html#cb223-1"></a>attention_dim <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb223-2"><a href="seq2seq-att.html#cb223-2"></a></span>
<span id="cb223-3"><a href="seq2seq-att.html#cb223-3"></a><span class="kw">class</span> Attention(nn.Module):</span>
<span id="cb223-4"><a href="seq2seq-att.html#cb223-4"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoder_hidden_dim, decoder_hidden_dim, attention_dim):</span>
<span id="cb223-5"><a href="seq2seq-att.html#cb223-5"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb223-6"><a href="seq2seq-att.html#cb223-6"></a>        <span class="va">self</span>.encoder_hidden_dim <span class="op">=</span> encoder_hidden_dim</span>
<span id="cb223-7"><a href="seq2seq-att.html#cb223-7"></a>        <span class="va">self</span>.decoder_hidden_dim <span class="op">=</span> decoder_hidden_dim</span>
<span id="cb223-8"><a href="seq2seq-att.html#cb223-8"></a>        <span class="va">self</span>.attention_in <span class="op">=</span> (encoder_hidden_dim <span class="op">*</span> <span class="dv">2</span>) <span class="op">+</span> decoder_hidden_dim</span>
<span id="cb223-9"><a href="seq2seq-att.html#cb223-9"></a>        <span class="va">self</span>.attention <span class="op">=</span> nn.Linear(<span class="va">self</span>.attention_in, attention_dim)</span>
<span id="cb223-10"><a href="seq2seq-att.html#cb223-10"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, decoder_hidden, encoder_outputs):</span>
<span id="cb223-11"><a href="seq2seq-att.html#cb223-11"></a>        src_len <span class="op">=</span> encoder_outputs.shape[<span class="dv">0</span>]</span>
<span id="cb223-12"><a href="seq2seq-att.html#cb223-12"></a>        <span class="co"># bs * decoder_hidden_dim -&gt;  bs * 1 * decoder_hidden_dim -&gt; bs * seq_len * decoder_hidden_dim</span></span>
<span id="cb223-13"><a href="seq2seq-att.html#cb223-13"></a>        <span class="co"># repeats hidden for every source token</span></span>
<span id="cb223-14"><a href="seq2seq-att.html#cb223-14"></a>        repeated_decoder_hidden <span class="op">=</span> decoder_hidden.unsqueeze(<span class="dv">1</span>).repeat(<span class="dv">1</span>, src_len, <span class="dv">1</span>)</span>
<span id="cb223-15"><a href="seq2seq-att.html#cb223-15"></a>        <span class="co"># bs * seq_len * (2 * hidden)</span></span>
<span id="cb223-16"><a href="seq2seq-att.html#cb223-16"></a>        encoder_outputs <span class="op">=</span> encoder_outputs.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb223-17"><a href="seq2seq-att.html#cb223-17"></a>        <span class="co"># after cat: bs * seq_len * (hidden + 2 * hidden)</span></span>
<span id="cb223-18"><a href="seq2seq-att.html#cb223-18"></a>        <span class="co"># =&gt; concatenates, for every batch item and source token, hidden state from decoder</span></span>
<span id="cb223-19"><a href="seq2seq-att.html#cb223-19"></a>        <span class="co"># (encoder, initially) and encoder output</span></span>
<span id="cb223-20"><a href="seq2seq-att.html#cb223-20"></a>        <span class="co"># energy then is bs * seq_len * attention_dim</span></span>
<span id="cb223-21"><a href="seq2seq-att.html#cb223-21"></a>        energy <span class="op">=</span> torch.tanh(<span class="va">self</span>.attention(torch.cat((repeated_decoder_hidden, encoder_outputs), dim <span class="op">=</span> <span class="dv">2</span>)))</span>
<span id="cb223-22"><a href="seq2seq-att.html#cb223-22"></a>        <span class="co"># bs * seq_len </span></span>
<span id="cb223-23"><a href="seq2seq-att.html#cb223-23"></a>        <span class="co"># a score for every source token</span></span>
<span id="cb223-24"><a href="seq2seq-att.html#cb223-24"></a>        attention <span class="op">=</span> torch.<span class="bu">sum</span>(energy, dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb223-25"><a href="seq2seq-att.html#cb223-25"></a>        <span class="cf">return</span> F.softmax(attention, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb223-26"><a href="seq2seq-att.html#cb223-26"></a></span>
<span id="cb223-27"><a href="seq2seq-att.html#cb223-27"></a>attention <span class="op">=</span> Attention(encoder_hidden_dim, decoder_hidden_dim, attention_dim).to(device)</span></code></pre></div>
<p>As we know how this module will be called, we can try it, too, in isolation:</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb224-1"><a href="seq2seq-att.html#cb224-1"></a>a <span class="op">=</span> attention(decoder_hidden, encoder_outputs)</span>
<span id="cb224-2"><a href="seq2seq-att.html#cb224-2"></a><span class="co"># will be bs * seq_len</span></span>
<span id="cb224-3"><a href="seq2seq-att.html#cb224-3"></a>a.size()</span></code></pre></div>
<p>Now to the place where it gets used, the decoder.</p>
</div>
<div id="decoder" class="section level3" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> Decoder</h3>
<p>To translate one sentence, the decoder will be called in a loop, each time generating one token based on three things:</p>
<ul>
<li>The previous token. In inference mode, this will be the token it has just generated, in the previous loop iteration;
however in training mode, this is often chosen to be the “correct” answer – the thing it <em>should</em> have chosen. This
technique is called <em>teacher forcing</em>; the below implementation applies it randomly in 50% of loop iterations. (Don’t look
for it here, in the decoder; we’ll see it in the top-level <code>Seq2Seq</code> module.)</li>
<li>The hidden state. This will be the <em>encoder</em>’s hidden state on the very first call, and the <em>decoder'</em>s own on every
subsequent one.</li>
<li>The complete output (at all timesteps) from the encoder. We already know we always need the complete output so we can
compute the attention weights.</li>
</ul>
<p>The decoder calls the attention module to obtain the attention weights, and multiplies these with the encoder outputs to
obtain what is sometimes called the <em>attention vector</em> (line 26). This is then passed to an RNN, together with the embedded
input data. A processed version of the RNN’s output, as well as the last hidden state, are returned, ready for use in
generating the next token.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="seq2seq-att.html#cb225-1"></a>num_output_features <span class="op">=</span> <span class="bu">len</span>(trg_spec.vocab)</span>
<span id="cb225-2"><a href="seq2seq-att.html#cb225-2"></a>decoder_embedding_dim <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb225-3"><a href="seq2seq-att.html#cb225-3"></a>decoder_dropout <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb225-4"><a href="seq2seq-att.html#cb225-4"></a></span>
<span id="cb225-5"><a href="seq2seq-att.html#cb225-5"></a><span class="kw">class</span> Decoder(nn.Module):</span>
<span id="cb225-6"><a href="seq2seq-att.html#cb225-6"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_output_features, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout, attention):</span>
<span id="cb225-7"><a href="seq2seq-att.html#cb225-7"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb225-8"><a href="seq2seq-att.html#cb225-8"></a>        <span class="va">self</span>.embedding_dim <span class="op">=</span> embedding_dim</span>
<span id="cb225-9"><a href="seq2seq-att.html#cb225-9"></a>        <span class="va">self</span>.encoder_hidden_dim <span class="op">=</span> encoder_hidden_dim</span>
<span id="cb225-10"><a href="seq2seq-att.html#cb225-10"></a>        <span class="va">self</span>.decoder_hidden_dim <span class="op">=</span> decoder_hidden_dim</span>
<span id="cb225-11"><a href="seq2seq-att.html#cb225-11"></a>        <span class="va">self</span>.num_output_features <span class="op">=</span> num_output_features</span>
<span id="cb225-12"><a href="seq2seq-att.html#cb225-12"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb225-13"><a href="seq2seq-att.html#cb225-13"></a>        <span class="va">self</span>.attention <span class="op">=</span> attention</span>
<span id="cb225-14"><a href="seq2seq-att.html#cb225-14"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(num_output_features, embedding_dim)</span>
<span id="cb225-15"><a href="seq2seq-att.html#cb225-15"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.GRU((encoder_hidden_dim <span class="op">*</span> <span class="dv">2</span>) <span class="op">+</span> embedding_dim, decoder_hidden_dim)</span>
<span id="cb225-16"><a href="seq2seq-att.html#cb225-16"></a>        <span class="va">self</span>.out <span class="op">=</span> nn.Linear(<span class="va">self</span>.attention.attention_in <span class="op">+</span> embedding_dim, num_output_features)</span>
<span id="cb225-17"><a href="seq2seq-att.html#cb225-17"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb225-18"><a href="seq2seq-att.html#cb225-18"></a>    <span class="kw">def</span> _weighted_encoder_rep(<span class="va">self</span>, decoder_hidden, encoder_outputs):</span>
<span id="cb225-19"><a href="seq2seq-att.html#cb225-19"></a>        <span class="co"># bs * seq_len</span></span>
<span id="cb225-20"><a href="seq2seq-att.html#cb225-20"></a>        a <span class="op">=</span> <span class="va">self</span>.attention(decoder_hidden, encoder_outputs)</span>
<span id="cb225-21"><a href="seq2seq-att.html#cb225-21"></a>        <span class="co"># bs * 1 * seq_len</span></span>
<span id="cb225-22"><a href="seq2seq-att.html#cb225-22"></a>        a <span class="op">=</span> a.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb225-23"><a href="seq2seq-att.html#cb225-23"></a>        <span class="co"># bs * seq_len * (2 * hidden_size)</span></span>
<span id="cb225-24"><a href="seq2seq-att.html#cb225-24"></a>        encoder_outputs <span class="op">=</span> encoder_outputs.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb225-25"><a href="seq2seq-att.html#cb225-25"></a>        <span class="co"># bs * 1 * (2 * hidden_size)</span></span>
<span id="cb225-26"><a href="seq2seq-att.html#cb225-26"></a>        weighted_encoder_rep <span class="op">=</span> torch.bmm(a, encoder_outputs)</span>
<span id="cb225-27"><a href="seq2seq-att.html#cb225-27"></a>        <span class="co"># 1 * bs * (2 * hidden_size)</span></span>
<span id="cb225-28"><a href="seq2seq-att.html#cb225-28"></a>        weighted_encoder_rep <span class="op">=</span> weighted_encoder_rep.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb225-29"><a href="seq2seq-att.html#cb225-29"></a>        <span class="cf">return</span> weighted_encoder_rep</span>
<span id="cb225-30"><a href="seq2seq-att.html#cb225-30"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>, decoder_hidden, encoder_outputs):</span>
<span id="cb225-31"><a href="seq2seq-att.html#cb225-31"></a>        <span class="co"># 1 * bs</span></span>
<span id="cb225-32"><a href="seq2seq-att.html#cb225-32"></a>        <span class="bu">input</span> <span class="op">=</span> <span class="bu">input</span>.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb225-33"><a href="seq2seq-att.html#cb225-33"></a>        <span class="co"># 1 * bs * decoder_embedding_dim</span></span>
<span id="cb225-34"><a href="seq2seq-att.html#cb225-34"></a>        embedded <span class="op">=</span> <span class="va">self</span>.dropout(<span class="va">self</span>.embedding(<span class="bu">input</span>))</span>
<span id="cb225-35"><a href="seq2seq-att.html#cb225-35"></a>        <span class="co"># 1 * bs * (2 * hidden_size)</span></span>
<span id="cb225-36"><a href="seq2seq-att.html#cb225-36"></a>        weighted_encoder_rep <span class="op">=</span> <span class="va">self</span>._weighted_encoder_rep(decoder_hidden, encoder_outputs)</span>
<span id="cb225-37"><a href="seq2seq-att.html#cb225-37"></a>        <span class="co"># concatenate input embedding and score from attention module</span></span>
<span id="cb225-38"><a href="seq2seq-att.html#cb225-38"></a>        <span class="co"># embedded: 1 * bs * decoder_embedding_dim</span></span>
<span id="cb225-39"><a href="seq2seq-att.html#cb225-39"></a>        <span class="co"># weighted_encoder_rep: 1 * bs * (2 * hidden_size)</span></span>
<span id="cb225-40"><a href="seq2seq-att.html#cb225-40"></a>        <span class="co"># rnn_input: 1 * bs * (decoder_embedding_dim + (2 * hidden_size))</span></span>
<span id="cb225-41"><a href="seq2seq-att.html#cb225-41"></a>        rnn_input <span class="op">=</span> torch.cat((embedded, weighted_encoder_rep), dim <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb225-42"><a href="seq2seq-att.html#cb225-42"></a>        <span class="co"># output: 1 * bs * decoder_hidden_dim</span></span>
<span id="cb225-43"><a href="seq2seq-att.html#cb225-43"></a>        <span class="co"># decoder_hidden: 1 * bs * decoder_hidden_dim (after unsqueeze)</span></span>
<span id="cb225-44"><a href="seq2seq-att.html#cb225-44"></a>        output, decoder_hidden <span class="op">=</span> <span class="va">self</span>.rnn(rnn_input, decoder_hidden.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb225-45"><a href="seq2seq-att.html#cb225-45"></a>        embedded <span class="op">=</span> embedded.squeeze(<span class="dv">0</span>)</span>
<span id="cb225-46"><a href="seq2seq-att.html#cb225-46"></a>        output <span class="op">=</span> output.squeeze(<span class="dv">0</span>)</span>
<span id="cb225-47"><a href="seq2seq-att.html#cb225-47"></a>        weighted_encoder_rep <span class="op">=</span> weighted_encoder_rep.squeeze(<span class="dv">0</span>)</span>
<span id="cb225-48"><a href="seq2seq-att.html#cb225-48"></a>        output <span class="op">=</span> <span class="va">self</span>.out(torch.cat((output, weighted_encoder_rep, embedded), dim <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb225-49"><a href="seq2seq-att.html#cb225-49"></a>        <span class="co"># output is bs * num_output_features</span></span>
<span id="cb225-50"><a href="seq2seq-att.html#cb225-50"></a>        <span class="cf">return</span> output, decoder_hidden.squeeze(<span class="dv">0</span>)</span></code></pre></div>
<p>Now we put it all together.</p>
</div>
<div id="seq2seq-module" class="section level3" number="9.3.4">
<h3><span class="header-section-number">9.3.4</span> Seq2seq module</h3>
<p>A single call of the top-level <code>Seq2Seq</code> module will translate a single sentence – or a batch of sentences, rather –,
calling the encoder just once and the decoder, in a loop.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="seq2seq-att.html#cb226-1"></a><span class="kw">class</span> Seq2Seq(nn.Module):</span>
<span id="cb226-2"><a href="seq2seq-att.html#cb226-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoder, decoder, device):</span>
<span id="cb226-3"><a href="seq2seq-att.html#cb226-3"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb226-4"><a href="seq2seq-att.html#cb226-4"></a>        <span class="va">self</span>.encoder <span class="op">=</span> encoder</span>
<span id="cb226-5"><a href="seq2seq-att.html#cb226-5"></a>        <span class="va">self</span>.decoder <span class="op">=</span> decoder</span>
<span id="cb226-6"><a href="seq2seq-att.html#cb226-6"></a>        <span class="va">self</span>.device <span class="op">=</span> device</span>
<span id="cb226-7"><a href="seq2seq-att.html#cb226-7"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, src, trg, teacher_forcing_ratio <span class="op">=</span> <span class="fl">0.5</span>):</span>
<span id="cb226-8"><a href="seq2seq-att.html#cb226-8"></a>        batch_size <span class="op">=</span> src.shape[<span class="dv">1</span>]</span>
<span id="cb226-9"><a href="seq2seq-att.html#cb226-9"></a>        max_len <span class="op">=</span> trg.shape[<span class="dv">0</span>]</span>
<span id="cb226-10"><a href="seq2seq-att.html#cb226-10"></a>        trg_vocab_size <span class="op">=</span> <span class="va">self</span>.decoder.num_output_features</span>
<span id="cb226-11"><a href="seq2seq-att.html#cb226-11"></a>        outputs <span class="op">=</span> torch.zeros(max_len, batch_size, trg_vocab_size).to(<span class="va">self</span>.device)</span>
<span id="cb226-12"><a href="seq2seq-att.html#cb226-12"></a>        encoder_outputs, hidden <span class="op">=</span> <span class="va">self</span>.encoder(src)</span>
<span id="cb226-13"><a href="seq2seq-att.html#cb226-13"></a>        <span class="co"># first input to the decoder is the &lt;sos&gt; token</span></span>
<span id="cb226-14"><a href="seq2seq-att.html#cb226-14"></a>        output <span class="op">=</span> trg[<span class="dv">0</span>,:]</span>
<span id="cb226-15"><a href="seq2seq-att.html#cb226-15"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, max_len):</span>
<span id="cb226-16"><a href="seq2seq-att.html#cb226-16"></a>            output, hidden <span class="op">=</span> <span class="va">self</span>.decoder(output, hidden, encoder_outputs)</span>
<span id="cb226-17"><a href="seq2seq-att.html#cb226-17"></a>            outputs[t] <span class="op">=</span> output</span>
<span id="cb226-18"><a href="seq2seq-att.html#cb226-18"></a>            teacher_force <span class="op">=</span> random.random() <span class="op">&lt;</span> teacher_forcing_ratio</span>
<span id="cb226-19"><a href="seq2seq-att.html#cb226-19"></a>            top1 <span class="op">=</span> output.<span class="bu">max</span>(<span class="dv">1</span>)[<span class="dv">1</span>]</span>
<span id="cb226-20"><a href="seq2seq-att.html#cb226-20"></a>            output <span class="op">=</span> (trg[t] <span class="cf">if</span> teacher_force <span class="cf">else</span> top1)</span>
<span id="cb226-21"><a href="seq2seq-att.html#cb226-21"></a>        <span class="cf">return</span> outputs</span>
<span id="cb226-22"><a href="seq2seq-att.html#cb226-22"></a></span>
<span id="cb226-23"><a href="seq2seq-att.html#cb226-23"></a>model <span class="op">=</span> Seq2Seq(encoder, decoder, device).to(device)</span>
<span id="cb226-24"><a href="seq2seq-att.html#cb226-24"></a></span>
<span id="cb226-25"><a href="seq2seq-att.html#cb226-25"></a></span>
<span id="cb226-26"><a href="seq2seq-att.html#cb226-26"></a><span class="kw">def</span> init_weights(m):</span>
<span id="cb226-27"><a href="seq2seq-att.html#cb226-27"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> m.named_parameters():</span>
<span id="cb226-28"><a href="seq2seq-att.html#cb226-28"></a>        <span class="cf">if</span> <span class="st">&#39;weight&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb226-29"><a href="seq2seq-att.html#cb226-29"></a>            nn.init.normal_(param.data, mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb226-30"><a href="seq2seq-att.html#cb226-30"></a>        <span class="cf">else</span>:</span>
<span id="cb226-31"><a href="seq2seq-att.html#cb226-31"></a>            nn.init.constant_(param.data, <span class="dv">0</span>)</span>
<span id="cb226-32"><a href="seq2seq-att.html#cb226-32"></a>model.<span class="bu">apply</span>(init_weights)</span></code></pre></div>
<p>Now we’re ready to train.</p>
</div>
</div>
<div id="training-and-evaluation" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Training and evaluation</h2>
<p>All logic being contained in the modules, the training loop is concise:</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="seq2seq-att.html#cb227-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters())</span>
<span id="cb227-2"><a href="seq2seq-att.html#cb227-2"></a>pad_idx <span class="op">=</span> trg_spec.vocab.stoi[<span class="st">&#39;&lt;pad&gt;&#39;</span>]</span>
<span id="cb227-3"><a href="seq2seq-att.html#cb227-3"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss(ignore_index <span class="op">=</span> pad_idx)</span>
<span id="cb227-4"><a href="seq2seq-att.html#cb227-4"></a></span>
<span id="cb227-5"><a href="seq2seq-att.html#cb227-5"></a><span class="kw">def</span> train(model, iterator, optimizer, criterion, clip):</span>
<span id="cb227-6"><a href="seq2seq-att.html#cb227-6"></a>    model.train()</span>
<span id="cb227-7"><a href="seq2seq-att.html#cb227-7"></a>    epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb227-8"><a href="seq2seq-att.html#cb227-8"></a>    <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(iterator):</span>
<span id="cb227-9"><a href="seq2seq-att.html#cb227-9"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(i, end <span class="op">=</span> <span class="st">&quot; &quot;</span>, flush<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb227-10"><a href="seq2seq-att.html#cb227-10"></a>        src <span class="op">=</span> batch.src</span>
<span id="cb227-11"><a href="seq2seq-att.html#cb227-11"></a>        trg <span class="op">=</span> batch.trg</span>
<span id="cb227-12"><a href="seq2seq-att.html#cb227-12"></a>        optimizer.zero_grad()</span>
<span id="cb227-13"><a href="seq2seq-att.html#cb227-13"></a>        <span class="co"># seq_len * bs * num_output_features</span></span>
<span id="cb227-14"><a href="seq2seq-att.html#cb227-14"></a>        output <span class="op">=</span> model(src, trg)</span>
<span id="cb227-15"><a href="seq2seq-att.html#cb227-15"></a>        <span class="co"># ((seq_len - 1) * bs) * num_output_features (output[1:] is (seq_len - 1) * bs * num_output_features))</span></span>
<span id="cb227-16"><a href="seq2seq-att.html#cb227-16"></a>        output <span class="op">=</span> output[<span class="dv">1</span>:].view(<span class="op">-</span><span class="dv">1</span>, output.shape[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb227-17"><a href="seq2seq-att.html#cb227-17"></a>        <span class="co"># (trg_len - 1) </span></span>
<span id="cb227-18"><a href="seq2seq-att.html#cb227-18"></a>        trg <span class="op">=</span> trg[<span class="dv">1</span>:].view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb227-19"><a href="seq2seq-att.html#cb227-19"></a>        loss <span class="op">=</span> criterion(output, trg)</span>
<span id="cb227-20"><a href="seq2seq-att.html#cb227-20"></a>        loss.backward()</span>
<span id="cb227-21"><a href="seq2seq-att.html#cb227-21"></a>        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)</span>
<span id="cb227-22"><a href="seq2seq-att.html#cb227-22"></a>        optimizer.step()</span>
<span id="cb227-23"><a href="seq2seq-att.html#cb227-23"></a>        epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb227-24"><a href="seq2seq-att.html#cb227-24"></a>    <span class="bu">print</span>()</span>
<span id="cb227-25"><a href="seq2seq-att.html#cb227-25"></a>    <span class="cf">return</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(iterator)</span></code></pre></div>
<p>We will want to monitor performance while training, so here is a helper function that sets the model to evaluation mode, turns
off teacher forcing and computes the loss:</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb228-1"><a href="seq2seq-att.html#cb228-1"></a><span class="kw">def</span> evaluate(model, iterator, criterion):</span>
<span id="cb228-2"><a href="seq2seq-att.html#cb228-2"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb228-3"><a href="seq2seq-att.html#cb228-3"></a>    epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb228-4"><a href="seq2seq-att.html#cb228-4"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb228-5"><a href="seq2seq-att.html#cb228-5"></a>        <span class="cf">for</span> _, batch <span class="kw">in</span> <span class="bu">enumerate</span>(iterator):</span>
<span id="cb228-6"><a href="seq2seq-att.html#cb228-6"></a>            src <span class="op">=</span> batch.src</span>
<span id="cb228-7"><a href="seq2seq-att.html#cb228-7"></a>            trg <span class="op">=</span> batch.trg</span>
<span id="cb228-8"><a href="seq2seq-att.html#cb228-8"></a>            output <span class="op">=</span> model(src, trg, <span class="dv">0</span>) </span>
<span id="cb228-9"><a href="seq2seq-att.html#cb228-9"></a>            output <span class="op">=</span> output[<span class="dv">1</span>:].view(<span class="op">-</span><span class="dv">1</span>, output.shape[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb228-10"><a href="seq2seq-att.html#cb228-10"></a>            trg <span class="op">=</span> trg[<span class="dv">1</span>:].view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb228-11"><a href="seq2seq-att.html#cb228-11"></a>            loss <span class="op">=</span> criterion(output, trg)</span>
<span id="cb228-12"><a href="seq2seq-att.html#cb228-12"></a>            epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb228-13"><a href="seq2seq-att.html#cb228-13"></a>    <span class="cf">return</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(iterator)</span></code></pre></div>
<p>Of course, what we really are interested in is how the translations look to us humans; here is a function that translates
whatever we pass it:</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb229-1"><a href="seq2seq-att.html#cb229-1"></a><span class="kw">def</span> translate_sentence(sentence, src_field, trg_field, model, device, max_len <span class="op">=</span> <span class="dv">50</span>):</span>
<span id="cb229-2"><a href="seq2seq-att.html#cb229-2"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb229-3"><a href="seq2seq-att.html#cb229-3"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(sentence, <span class="bu">str</span>):</span>
<span id="cb229-4"><a href="seq2seq-att.html#cb229-4"></a>        nlp <span class="op">=</span> spacy.load(<span class="st">&#39;en&#39;</span>)</span>
<span id="cb229-5"><a href="seq2seq-att.html#cb229-5"></a>        tokens <span class="op">=</span> [token.text.lower() <span class="cf">for</span> token <span class="kw">in</span> nlp(sentence)]</span>
<span id="cb229-6"><a href="seq2seq-att.html#cb229-6"></a>    <span class="cf">else</span>:</span>
<span id="cb229-7"><a href="seq2seq-att.html#cb229-7"></a>        tokens <span class="op">=</span> [token.lower() <span class="cf">for</span> token <span class="kw">in</span> sentence]</span>
<span id="cb229-8"><a href="seq2seq-att.html#cb229-8"></a>    tokens <span class="op">=</span> [src_field.init_token] <span class="op">+</span> tokens <span class="op">+</span> [src_field.eos_token]</span>
<span id="cb229-9"><a href="seq2seq-att.html#cb229-9"></a>    src_indexes <span class="op">=</span> [src_field.vocab.stoi[token] <span class="cf">for</span> token <span class="kw">in</span> tokens]</span>
<span id="cb229-10"><a href="seq2seq-att.html#cb229-10"></a>    src_tensor <span class="op">=</span> torch.LongTensor(src_indexes).unsqueeze(<span class="dv">1</span>).to(device)</span>
<span id="cb229-11"><a href="seq2seq-att.html#cb229-11"></a>    src_len <span class="op">=</span> torch.LongTensor([<span class="bu">len</span>(src_indexes)]).to(device)</span>
<span id="cb229-12"><a href="seq2seq-att.html#cb229-12"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb229-13"><a href="seq2seq-att.html#cb229-13"></a>        encoder_outputs, hidden <span class="op">=</span> model.encoder(src_tensor)</span>
<span id="cb229-14"><a href="seq2seq-att.html#cb229-14"></a>    trg_indexes <span class="op">=</span> [trg_field.vocab.stoi[trg_field.init_token]]</span>
<span id="cb229-15"><a href="seq2seq-att.html#cb229-15"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_len):</span>
<span id="cb229-16"><a href="seq2seq-att.html#cb229-16"></a>        trg_tensor <span class="op">=</span> torch.LongTensor([trg_indexes[<span class="op">-</span><span class="dv">1</span>]]).to(device)</span>
<span id="cb229-17"><a href="seq2seq-att.html#cb229-17"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb229-18"><a href="seq2seq-att.html#cb229-18"></a>            output, hidden <span class="op">=</span> model.decoder(trg_tensor, hidden, encoder_outputs)</span>
<span id="cb229-19"><a href="seq2seq-att.html#cb229-19"></a>            pred_token <span class="op">=</span> output.argmax(<span class="dv">1</span>).item()</span>
<span id="cb229-20"><a href="seq2seq-att.html#cb229-20"></a>            trg_indexes.append(pred_token)</span>
<span id="cb229-21"><a href="seq2seq-att.html#cb229-21"></a>            <span class="cf">if</span> pred_token <span class="op">==</span> trg_field.vocab.stoi[trg_field.eos_token]: <span class="cf">break</span></span>
<span id="cb229-22"><a href="seq2seq-att.html#cb229-22"></a>    trg_tokens <span class="op">=</span> [trg_field.vocab.itos[i] <span class="cf">for</span> i <span class="kw">in</span> trg_indexes]</span>
<span id="cb229-23"><a href="seq2seq-att.html#cb229-23"></a>    <span class="cf">return</span> trg_tokens[<span class="dv">1</span>:]</span></code></pre></div>
<p>Now here is the training loop. Every epoch, we print the translations of eight sentences, picked at random from the training
set:</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="seq2seq-att.html#cb230-1"></a>n_epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb230-2"><a href="seq2seq-att.html#cb230-2"></a>clip <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb230-3"><a href="seq2seq-att.html#cb230-3"></a></span>
<span id="cb230-4"><a href="seq2seq-att.html#cb230-4"></a>example_idx <span class="op">=</span> [<span class="dv">11</span>, <span class="dv">77</span>, <span class="dv">133</span>, <span class="dv">241</span>, <span class="dv">333</span>, <span class="dv">477</span>, <span class="dv">555</span>, <span class="dv">777</span>]</span>
<span id="cb230-5"><a href="seq2seq-att.html#cb230-5"></a></span>
<span id="cb230-6"><a href="seq2seq-att.html#cb230-6"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb230-7"><a href="seq2seq-att.html#cb230-7"></a>    train_loss <span class="op">=</span> train(model, train_iterator, optimizer, criterion, clip)</span>
<span id="cb230-8"><a href="seq2seq-att.html#cb230-8"></a>    valid_loss <span class="op">=</span> evaluate(model, valid_iterator, criterion)</span>
<span id="cb230-9"><a href="seq2seq-att.html#cb230-9"></a>    test_loss <span class="op">=</span> evaluate(model, test_iterator, criterion)</span>
<span id="cb230-10"><a href="seq2seq-att.html#cb230-10"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:02}</span><span class="ss">&#39;</span>)</span>
<span id="cb230-11"><a href="seq2seq-att.html#cb230-11"></a>    <span class="bu">print</span>(<span class="ss">f&#39;</span><span class="ch">\t</span><span class="ss">Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.3f}</span><span class="ss"> | Train PPL: </span><span class="sc">{</span>math<span class="sc">.</span>exp(train_loss)<span class="sc">:7.3f}</span><span class="ss">&#39;</span>)</span>
<span id="cb230-12"><a href="seq2seq-att.html#cb230-12"></a>    <span class="bu">print</span>(<span class="ss">f&#39;</span><span class="ch">\t</span><span class="ss"> Val. Loss: </span><span class="sc">{</span>valid_loss<span class="sc">:.3f}</span><span class="ss"> |  Val. PPL: </span><span class="sc">{</span>math<span class="sc">.</span>exp(valid_loss)<span class="sc">:7.3f}</span><span class="ss">&#39;</span>)</span>
<span id="cb230-13"><a href="seq2seq-att.html#cb230-13"></a>    <span class="bu">print</span>(<span class="ss">f&#39;</span><span class="ch">\t</span><span class="ss">Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.3f}</span><span class="ss"> | Test PPL: </span><span class="sc">{</span>math<span class="sc">.</span>exp(test_loss)<span class="sc">:7.3f}</span><span class="ss"> |&#39;</span>)</span>
<span id="cb230-14"><a href="seq2seq-att.html#cb230-14"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>):</span>
<span id="cb230-15"><a href="seq2seq-att.html#cb230-15"></a>        example_src <span class="op">=</span> <span class="bu">vars</span>(train_data.examples[example_idx[i]])[<span class="st">&#39;src&#39;</span>]</span>
<span id="cb230-16"><a href="seq2seq-att.html#cb230-16"></a>        example_trg <span class="op">=</span> <span class="bu">vars</span>(train_data.examples[example_idx[i]])[<span class="st">&#39;trg&#39;</span>]</span>
<span id="cb230-17"><a href="seq2seq-att.html#cb230-17"></a>        translation <span class="op">=</span> translate_sentence(example_src, src_spec, trg_spec, model, device)</span>
<span id="cb230-18"><a href="seq2seq-att.html#cb230-18"></a>        src_sentence <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(i <span class="cf">for</span> i <span class="kw">in</span> example_src)</span>
<span id="cb230-19"><a href="seq2seq-att.html#cb230-19"></a>        target_sentence <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(i <span class="cf">for</span> i <span class="kw">in</span> example_trg)</span>
<span id="cb230-20"><a href="seq2seq-att.html#cb230-20"></a>        translated_sentence <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(i <span class="cf">for</span> i <span class="kw">in</span> translation)</span>
<span id="cb230-21"><a href="seq2seq-att.html#cb230-21"></a>        <span class="bu">print</span>(<span class="st">&quot;Source: &quot;</span> <span class="op">+</span> src_sentence)</span>
<span id="cb230-22"><a href="seq2seq-att.html#cb230-22"></a>        <span class="bu">print</span>(<span class="st">&quot;Target: &quot;</span> <span class="op">+</span> target_sentence)</span>
<span id="cb230-23"><a href="seq2seq-att.html#cb230-23"></a>        <span class="bu">print</span>(<span class="st">&quot;Predicted: &quot;</span> <span class="op">+</span> translated_sentence <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p>You may be curious to see the output - right?</p>
</div>
<div id="results" class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Results</h2>
<p>We show losses and translations after epochs 1, 5, and 9. From how training progresses, we don’t expect this model to result
in perfect translations for the given dataset. Remember, this is a real-world dataset, unlike the toy datasets often used in
deep learning tutorials – model architecture may well be far too unsophisticated under these circumstances.</p>
<p>We’ll see a <em>Transformer</em>-based model in the next chapter – feel free to compare both models on the same task!</p>
<pre><code>Epoch: 01
    Train Loss: 5.252 | Train PPL: 190.952
    Val. Loss: 4.944  |  Val. PPL: 140.359
    Test Loss: 4.951  | Test PPL: 141.259 


Epoch: 05
    Train Loss: 4.153 | Train PPL:  63.636
    Val. Loss: 4.559  |  Val. PPL:  95.500
    Test Loss: 4.555  | Test PPL:  95.071 

Epoch: 09
      Train Loss: 4.005 | Train PPL:  54.870
      Val. Loss: 4.551  |  Val. PPL:  94.684
    Test Loss: 4.530  | Test PPL:  92.792 </code></pre>
<table>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Source</td>
<td>most of the earthquakes and volcanoes are in the sea , at the bottom of the sea .</td>
</tr>
<tr class="even">
<td>Target</td>
<td>la plupart des tremblements de terre et de volcans se produisent dans la mer - au fond de la mer .</td>
</tr>
<tr class="odd">
<td>Epoch 1</td>
<td>la plupart des les et les les dans la eau , la eau .</td>
</tr>
<tr class="even">
<td>Epoch 5</td>
<td>la plupart des les et les des sont dans la mer , au sommet de la mer .</td>
</tr>
<tr class="odd">
<td>Epoch 9</td>
<td>la plupart des terres et les volcans sont dans la mer , au fond de la mer .</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="5%" />
<col width="94%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>S o u r c e</td>
<td>and then we had some hint that these things existed all along the axis of it , because if you ’ve got volcanism , water ’s going to get down from the sea into cracks in the sea floor , come in contact with magma , and come shooting out hot .</td>
</tr>
<tr class="even">
<td>T a r g e t</td>
<td>nous avions une idée que ces choses existaient tout au long de cet axe , car s’ il y a du volcanisme , l´eau va descendre de la mer dans les fentes du sol marin , se mettre en contact avec le magma , et jaillir avec de hautes températures .</td>
</tr>
<tr class="odd">
<td>E p o c h 1</td>
<td>let nous avons eu beaucoup de ces ces ces choses qui sont en fait , parce que si vous avez , , , , , , à la , dans la eau dans dans la eau , dans le sol , , , avec les &lt;unk&gt; , et , et</td>
</tr>
<tr class="even">
<td>E p o c h 5</td>
<td>et puis nous avons eu une chose que ces choses ont été l’ axe de l’ , , parce que si vous avez &lt;unk&gt; &lt;unk&gt; , eau eau , la mer dans les dans dans la mer dans la mer , et avec son contact avec la . et et</td>
</tr>
<tr class="odd">
<td>E p o c h 9</td>
<td>et puis nous avons eu un idée que ces choses ont tous les axe de , , parce que si vous avez &lt;unk&gt; , eau , l’ eau va descendre dans la mer dans dans dans mer dans la mer , dans la pluie , et de la de de</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Source</td>
<td>they do n’t need the sun at all .</td>
</tr>
<tr class="even">
<td>Target</td>
<td>ils n´ont pas du tout besoin de soleil .</td>
</tr>
<tr class="odd">
<td>Epoch 1</td>
<td>ils n’ ont pas besoin de la terre .</td>
</tr>
<tr class="even">
<td>Epoch 5</td>
<td>ls n’ ont pas besoin de soleil .</td>
</tr>
<tr class="odd">
<td>Epoch 9</td>
<td>ils ne ont pas besoin de soleil soleil tout tout .</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="5%" />
<col width="94%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>So ur ce</td>
<td>because it ’s shown the way we apply , generate and use knowledge is affected by our social and institutional context , which told us what in communism ?</td>
</tr>
<tr class="even">
<td>Ta rg et</td>
<td>parce qu’ il est démontré que la façon dont nous appliquons , générons , et utilisons les connaissances est affectée par notre contexte social et institutionnel , qui nous a dit quoi pendant le communisme ?</td>
</tr>
<tr class="odd">
<td>E po ch 1</td>
<td>parce que c’ est que nous nous nous , , , , , et de l’ information , , et notre , , et , et , ce qui a ce que ?</td>
</tr>
<tr class="even">
<td>E po ch 5</td>
<td>parce que c’ est la façon dont nous on , , et et et la connaissance , et et et et et le contexte , qui nous nous demandé ce qu’ il est ?</td>
</tr>
<tr class="odd">
<td>E po ch 9</td>
<td>parce que c’ est montré comment nous nous , , et et et connaissances et et le monde social et et et nous nous a demandé à le ? ?</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="6%" />
<col width="93%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>S ource</td>
<td>it ’s not fiction , it ’s not story tales , it ’s not make - believe ; it ’s cold , hard science .</td>
</tr>
<tr class="even">
<td>T arget</td>
<td>ce n’ est pas de la fiction , ce n’ est pas des histoires , ce n’ est pas des fadaises ; c’ est de la science pure .</td>
</tr>
<tr class="odd">
<td>Epoch 1</td>
<td>ce n’ est pas pas , , n’ n’ est pas de de , , n’ est pas pas , , c’ est , , .</td>
</tr>
<tr class="even">
<td>Epoch 5</td>
<td>c’ n’ est pas pas la fiction , c’ n’ est pas pas de histoires , ça ne est pas pas croire , c’ est extrêmement difficile .</td>
</tr>
<tr class="odd">
<td>Epoch 9</td>
<td>c’ n’ est pas pas fiction , c’ n’ est pas pas de histoires , c’ est est pas facile . c’ est froid , la science .</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="6%" />
<col width="93%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>So urce</td>
<td>we all want to be there , in the upper right quadrant , where performance is strong and learning opportunities are equally distributed .</td>
</tr>
<tr class="even">
<td>Ta rget</td>
<td>on veut tous être dans le quadrant supérieur droit , où les performances sont remarquables et les opportunités d’ apprentissage sont égales .</td>
</tr>
<tr class="odd">
<td>E poch 1</td>
<td>nous voulons tous seulement , , dans le cas , , où les les sont et et les les les sont . .</td>
</tr>
<tr class="even">
<td>E poch 5</td>
<td>nous voulons voulons être être , dans dans le coin droite , où où la est est est des opportunités et des apprentissage sont des .</td>
</tr>
<tr class="odd">
<td>E poch 9</td>
<td>ous voulons voulons être là , dans le haut , , où les performances est plus et et les opportunités sont sont .</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="4%" />
<col width="95%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>S o u r c e</td>
<td>those are the critical questions , and what we have learned from pisa is that , in high - performing education systems , the leaders have convinced their citizens to make choices that value education , their future , more than consumption today .</td>
</tr>
<tr class="even">
<td>T a r g e t</td>
<td>ce sont là les questions importantes , et ce qu’ on a appris de pisa est que dans les systèmes éducatifs très performants les dirigeants ont aujourd’hui convaincu leurs citoyens de faire des choix qui font valoir leur éducation , leur avenir , plus que la consommation .</td>
</tr>
<tr class="odd">
<td>E p o c h 1</td>
<td>ces sont des idées , et ce que nous avons avons appris à l’ de de , , , dans les des de des , , les les les les les pour les les de la santé , les les , , , , , , ,</td>
</tr>
<tr class="even">
<td>E p o c h 5</td>
<td>ces sont questions questions et et ce nous nous avons appris à l’ , c’ est dans les systèmes de systèmes , , les organisations qui ont des citoyens de leur pour les choix , des systèmes , , , , , , , plus de énergie aujourd’hui .</td>
</tr>
<tr class="odd">
<td>E p o c h 9</td>
<td>ces sont questions questions questions et et ce dont nous avons appris à l’ est est , , dans les systèmes de systèmes de , , les dirigeants ont citoyens leurs citoyens pour faire les choix , les futur , , futur , plus de consommation de plus .</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="6%" />
<col width="93%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>So urce</td>
<td>when the sailors mutinied at sea in a demand for humane conditions , it was these teenagers that fed the crew .</td>
</tr>
<tr class="even">
<td>Ta rget</td>
<td>quand les marins se sont mutinés en mer pour exiger des conditions plus humaines , ce sont ces adolescents qui ont nourri l’ équipage .</td>
</tr>
<tr class="odd">
<td>E poch 1</td>
<td>quand les &lt;unk&gt; de l’ eau dans dans la de de pour les les , , , ces ces qui ont été été .</td>
</tr>
<tr class="even">
<td>E poch 5</td>
<td>quand les &lt;unk&gt; &lt;unk&gt; dans la mer dans une vie avec la conditions conditions , les parents , c’ était ces adolescents qui ont été équipe .</td>
</tr>
<tr class="odd">
<td>E poch 9</td>
<td>quand les marins &lt;unk&gt; dans la mer dans une demande de la nature , , c’ était ces adolescents qui qui l’ équipe .</td>
</tr>
</tbody>
</table>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-2014arXiv1409.0473B">
<p>Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2014. “Neural Machine Translation by Jointly Learning to Align and Translate.” <em>arXiv E-Prints</em>, September, arXiv:1409.0473. <a href="http://arxiv.org/abs/1409.0473">http://arxiv.org/abs/1409.0473</a>.</p>
</div>
<div id="ref-LuongPM15">
<p>Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. 2015. “Effective Approaches to Attention-Based Neural Machine Translation.” <em>CoRR</em> abs/1508.04025. <a href="http://arxiv.org/abs/1508.04025">http://arxiv.org/abs/1508.04025</a>.</p>
</div>
<div id="ref-Radford2018ImprovingLU">
<p>Radford, Alec. 2018. “Improving Language Understanding by Generative Pre-Training.” In.</p>
</div>
<div id="ref-VaswaniSPUJGKP17">
<p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” <em>CoRR</em> abs/1706.03762. <a href="http://arxiv.org/abs/1706.03762">http://arxiv.org/abs/1706.03762</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="NLP-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="transformer.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
